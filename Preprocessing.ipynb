{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSCGMxajRC9R"
   },
   "source": [
    "## **ACL-BioNLP'19 - MEDIQA 2019 Shared Task**\n",
    "\n",
    "**Task 3: Question Answering (QA): **\n",
    "Filter and improve the ranking of automatically retrieved answers from CHiQA \n",
    "\n",
    "*   Filter and improve the ranking of automatically retrieved answers from CHiQA system (https://chiqa.nlm.nih.gov/)\n",
    "*   CHiQA is an experimental AI system that is learning how to answer health-related questions using reliable sources for patients.\n",
    "\n",
    "\n",
    "Authors: Gonzalo Recio and Jana Reventós \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuaOUX1l3Vsf"
   },
   "source": [
    "Connect with MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2JJ1uKBRBnw",
    "outputId": "a4debbbd-fb40-44ee-825e-c514bd629059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'My Drive/HLE Final Project': No such file or directory\n",
      "[Errno 2] No such file or directory: 'My Drive/HLE Final Project/data'\n",
      "/gdrive\n"
     ]
    }
   ],
   "source": [
    "! ls \"My Drive/HLE Final Project\"\n",
    "%cd \"My Drive/HLE Final Project/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjNf-ELN4GVi",
    "outputId": "03b53629-8a92-4840-d3d0-059100e5f378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biobert\n",
      "MEDIQA2019-Task3-QA-TestSet-wLabels.xml\n",
      "MEDIQA2019-Task3-QA-TrainingSet1-LiveQAMed.xml\n",
      "MEDIQA2019-Task3-QA-TrainingSet2-Alexa.xml\n",
      "MEDIQA2019-Task3-QA-ValidationSet.xml\n",
      "MEDIQA_Task3_QA_TestSet.xml\n",
      "QA_Task3_README.txt\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'MEDIQA2019_datasets/MEDIQA_Task3_QA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rDyHrqdYSC8h"
   },
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parse, parseString\n",
    "from nltk import tokenize as tk\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qLMZaDzZCER"
   },
   "source": [
    "## Read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GCcPv2AZZIFN"
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "    return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "def get_answers(answers):\n",
    "    # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "    answs, rank, chiqa, y = [], [], [], []\n",
    "    for answer in answers:\n",
    "        ans = preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "        reference = int(answer.getAttribute('ReferenceRank'))\n",
    "        system = int(answer.getAttribute('SystemRank'))\n",
    "        label = answer.getAttribute('ReferenceScore')\n",
    "        answs.append(ans); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "    return answs, rank, chiqa, y\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCn1BpQpTOBw",
    "outputId": "4175c239-9b35-4ca0-c7ed-5038f899a019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Rapp.history\n",
      "MEDIQA2019-Task3-QA-TestSet-wLabels.xml\n",
      "MEDIQA2019-Task3-QA-TestSet.xml\n",
      "MEDIQA2019-Task3-QA-TrainingSet1-LiveQAMed.xml\n",
      "MEDIQA2019-Task3-QA-TrainingSet2-Alexa.xml\n",
      "MEDIQA2019-Task3-QA-ValidationSet.xml\n",
      "Task3_README.txt\n",
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "indx2id = []\n",
    "QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "for filename in os.listdir(PATH + '/'):\n",
    "    # i += 1\n",
    "    print(filename)\n",
    "    if not filename.endswith('.xml') or 'Training' not in filename: continue\n",
    "    fullname = os.path.join('data/Train', filename)\n",
    "    tree = parse(PATH + '/' + filename)\n",
    "    questions = tree.getElementsByTagName('Question')\n",
    "    for question in questions:\n",
    "        qelem = question.getElementsByTagName('QuestionText')\n",
    "        q, qid = preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "        # print(q) # --> questions\n",
    "        answers = question.getElementsByTagName('Answer')\n",
    "        answers_list, rank, system, labels = get_answers(answers)\n",
    "        QA.append([q,answers_list, rank, labels])\n",
    "        QA2.append([q,answers_list, rank, system, labels])\n",
    "        indx2id.append(qid); i+=1;\n",
    "        # break\n",
    "print(i)\n",
    "print(len(QA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahRCulfbzw_r"
   },
   "source": [
    "QA is an array of tuples <Question, [Answers], [Ranking], [Labels] >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dgcg2QEzYNAv",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1475672f-33be-4f5a-bd76-f69fbdcfd0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what are the symptoms of ovarian cancer?\n",
      "1 - ovarian cancer (symptoms): early-stage ovarian cancer rarely causes any symptoms. advanced-stage ovarian cancer may cause few and nonspecific symptoms that are often mistaken for more common benign conditions. signs and symptoms of ovarian cancer may include: - abdominal bloating or swelling - quickly feeling full when eating - weight loss - discomfort in the pelvis area - changes in bowel habits, such as constipation - a frequent need to urinate when to see a doctor make an appointment with your doctor if you have any signs or symptoms that worry you. if you have a family history of ovarian cancer or breast cancer, talk to your doctor about your risk of ovarian cancer. your doctor may refer you to a genetic counselor to discuss testing for certain gene mutations that increase your risk of breast and ovarian cancers.\n",
      "2 - ovarian cancer (symptoms): many people with early ovarian cancer have no signs or symptoms of the condition. when present, symptoms are often nonspecific and blamed on other, more common conditions. some people with ovarian cancer may experience the following:   bloating difficulty eating or early satiety pelvic or lower abdominal pain back pain abnormal vaginal bleeding digestive symptoms such as nausea and vomiting; constipation; indigestion; and/or acid reflux weight loss or weight gain increased urinary frequency or urgency tiredness shortness of breath the human phenotype ontology (hpo) provides the following list of features that have been reported in people with this condition. much of the information in the hpo comes from orphanet, a european rare disease database. if available, the list includes a rough estimate of how common a feature is (its frequency). frequencies are based on a specific study and may not be representative of all studies. you can use the medlineplus medical dictionary for definitions of the terms below. signs and symptoms approximate number of patients (when available) abnormality of metabolism/homeostasis - autosomal dominant inheritance - breast carcinoma - dysgerminoma - ovarian papillary adenocarcinoma -\n",
      "3 - ovarian cancer (what are the symptoms of ovarian cancer?): the following may be symptoms of ovarian cancer if they continue or get worse over time: if you have any of these symptoms, talk to your doctor. he or she can determine if the cause is cancer or something else. your doctor also may ask you to visit a gynecologic oncologist. this is a doctor who focuses on cancers of the female pelvis.\n",
      "4 - ovarian epithelial cancer (symptoms): the human phenotype ontology (hpo) provides the following list of features that have been reported in people with this condition. much of the information in the hpo comes from orphanet, a european rare disease database. if available, the list includes a rough estimate of how common a feature is (its frequency). frequencies are based on a specific study and may not be representative of all studies. you can use the medlineplus medical dictionary for definitions of the terms below. signs and symptoms approximate number of patients (when available) autosomal dominant inheritance - breast carcinoma - multifactorial inheritance -\n",
      "5 - ovarian cancer: ovarian cancer is cancer that begins in the ovaries. the ovaries make female hormones and produce a woman's eggs. ovarian cancer is a serious cancer that is more common in older women. treatment is most effective when the cancer is found early. screening for ovarian cancer is not recommended for most women. learn more about ovarian cancer at the national cancer institute. ovarian cancer forms in tissues of the ovary. (an ovary is one of a pair of female reproductive glands in which the ova, or eggs, are formed.) tumors in the ovaries can be benign, which means they are not cancer, or they can be malignant, which means they are cancer. cancers that start in the ovaries can spread to other parts of the body. this is called metastasis. cancer that starts in the ovaries and spreads to other parts of the body is still called ovarian cancer. around one in every 60 women in the united states will develop ovarian cancer. most ovarian cancers are diagnosed in women over 60, but this disease can also affect younger women. among women in the united states, ovarian cancer is rare. most ovarian cancers are diagnosed among women ages 55 to 64, but ovarian cancer can also affect younger women. women with a high risk of ovarian cancer are those with a harmful mutation on the brca1 or brca2 genes. these mutations can be found with a blood test. women with a family or personal history of breast or ovarian cancer also have a higher risk of ovarian cancer. if you have family members in multiple generations with breast cancer or ovarian cancer, see your doctor to learn more about your risk of ovarian cancer. research shows that certain steps, such as surgery to remove the ovaries and the fallopian tubes, may help prevent ovarian cancer in women who are at high risk. the sooner ovarian cancer is found and treated, the better your chance for recovery. but ovarian cancer is hard to detect early, because its symptoms are also the symptoms of many other illnesses. the following may be symptoms of ovarian cancer if they continue or get worse over time: if you have any of these symptoms, talk to your doctor. he or she can determine if the cause is cancer or something else. your doctor also may ask you to visit a gynecologic oncologist. this is a doctor who focuses on cancers of the female pelvis. the u.s. preventive services task force (uspstf) recommends against screening women who are not at high risk for ovarian cancer. the uspstf found that testing for ovarian cancer may do more harm than good. current testing methods, like pelvic exams, ultrasound, and blood tests, can lead to \"false positives\" (results that say a woman has ovarian cancer when she really does not have ovarian cancer). these incorrect results can lead to surgeries that are not needed and that can be risky. some women, like those who are at high risk, can talk to their doctor about their risk and what they can do to help prevent ovarian cancer. for more information about ovarian cancer, call the owh helpline at 1-800-994-9662 or contact the following organizations:\n",
      "6 - ovarian cancer (exams and tests): a physical exam is often normal. with advanced ovarian cancer, the doctor may find a swollen abdomen often due to accumulation of fluid (ascites). a pelvic examination may reveal an ovarian or abdominal mass. a ca-125 blood test is not considered a good screening test for ovarian cancer. but, it may be done if a woman has: - symptoms of ovarian cancer - already been diagnosed with ovarian cancer to determine how well treatment is working other tests that may be done include: - complete blood count and blood chemistry - pregnancy test (serum hcg) - ct or mri of the pelvis or abdomen - ultrasound of the pelvis surgery, such as a pelvic laparoscopy or exploratory laparotomy, is often done to find the cause of symptoms. a biopsy will be done to help make the diagnosis. no lab or imaging test has ever been shown to be able to successfully screen for or diagnose ovarian cancer in its early stages, so no standard screening tests are recommended at this time.\n",
      "7 - ovarian cancer (diagnosis): if ovarian cancer is suspected based on the presence of certain signs and symptoms, the following tests and procedures may be recommended:   physical evaluation and pelvic exam to check for signs of ovarian cancer (i.e. lumps or swelling) and to examine the size, shape and location of the ovaries ultrasound and other imaging studies to look for abnormal growths blood tests such as a ca-125 assay which may be elevated in people with ovarian cancer a biopsy of the tumor is the only way to confirm a diagnosis of ovarian cancer the national cancer institute offers more detailed information regarding the tests used to diagnose ovarian cancer. to access this resource, please click here. testing resources the genetic testing registry (gtr) provides information about the genetic tests for this condition. the intended audience for the gtr is health care providers and researchers. patients and consumers with specific questions about a genetic test should contact a health care provider or a genetics professional.\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "#s=QA[201][1][0]\n",
    "ranked_answ = []\n",
    "print('Question:',QA[201][0])\n",
    "for i in range(len(QA[201][1])):\n",
    "    answ = QA[201][1]\n",
    "    rank = QA[201][2]\n",
    "    ranked_answ.append((int(rank[i]),answ[i]))\n",
    "\n",
    "ranked_answ = sorted(ranked_answ, key=lambda x: x[0])\n",
    "for i in range(len(ranked_answ)):\n",
    "    print(ranked_answ[i][0],'-',unicodedata.normalize(\"NFKD\", ranked_answ[i][1]))\n",
    "\n",
    "#s=unicodedata.normalize(\"NFKD\", s)\n",
    "#re.sub(r'\\[\\d\\]', '', s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "147abfcfb0ac497a9736336ecf1a5c7a",
      "ff0c4714c57f4cc697301ef2bf58eb28",
      "2441cd058509472ea3fef74f72b3ba0f",
      "ab9fea5b4c2f4426827ecfbd711097a9",
      "5493bc3fc0704e3e8ea055de72f52367",
      "71fb84f8487542429fa488d0c6fef2a6",
      "1398398f8aef4f27b93bc85edacdd770",
      "e9b952cefb264ce28c1988a5d0652459"
     ]
    },
    "id": "_8OBtYhoELGw",
    "outputId": "dcfb4d41-073b-41c9-fe0b-78f321b95e71"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0k52YvadUR_q",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ab41e625-ad5b-436a-962b-dd163a86c979"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what are the treatments of prostate cancer?',\n",
       " ['cryotherapy for prostate cancer (when cryosurgery is used to treat prostate cancer): this therapy is not as commonly used and is not as well accepted as other treatments for prostate cancer. doctors do not know for certain how well cryosurgery works over time. there is not enough data to compare it with standard prostatectomy, radiation treatment, or brachytherapy. it can only treat prostate cancer that has not spread beyond the prostate. men who cannot have surgery because of their age or other health problems may have cryosurgery instead. it also may be used if cancer comes back after other treatments. it is generally not helpful for men with very large prostate glands.',\n",
       "  'what are the treatments for prostate cancer?: these resources address the diagnosis or management of prostate cancer: - american college of radiology: prostate cancer radiation treatment - genetic testing registry: familial prostate cancer - genetic testing registry: prostate cancer, hereditary, 2 - medlineplus encyclopedia: prostate brachytherapy - medlineplus encyclopedia: prostate cancer staging - medlineplus encyclopedia: prostate cancer treatment - medlineplus encyclopedia: prostate-specific antigen (psa) blood test - medlineplus encyclopedia: radical prostatectomy - medlineplus health topic: prostate cancer screening - national cancer institute: prostate-specific antigen (psa) test - u.s. preventive services task force these resources from medlineplus offer information about the diagnosis and management of various health conditions: - diagnostic tests - drug therapy - surgery and rehabilitation - genetic counseling - palliative care',\n",
       "  \"prostate cancer (treatment): your prostate cancer treatment options depend on several factors, such as how fast your cancer is growing, how much it has spread and your overall health, as well as the potential benefits or side effects of the treatment. immediate treatment may not be necessary for men diagnosed with low-risk prostate cancer, treatment may not be necessary right away. some men may never need treatment. instead, doctors sometimes recommend active surveillance. in active surveillance, regular follow-up blood tests, rectal exams and possibly biopsies may be performed to monitor progression of your cancer. if tests show your cancer is progressing, you may opt for a prostate cancer treatment such as surgery or radiation. active surveillance may be an option for cancer that isn't causing symptoms, is expected to grow very slowly and is confined to a small area of the prostate. active surveillance may also be considered for someone who has another serious health condition or who is of an advanced age that makes cancer treatment more difficult. active surveillance carries a risk that the cancer may grow and spread between checkups, making the cancer less likely to be cured. surgery to remove the prostate surgery for prostate cancer involves removing the prostate gland (radical prostatectomy), some surrounding tissue and a few lymph nodes. radical prostatectomy can be performed in several ways: - using a robot to assist with surgery. during robot-assisted surgery, the instruments are attached to a mechanical device (robot) and inserted into your abdomen through several small incisions. the surgeon sits at a console and uses hand controls to guide the robot to move the instruments. robotic prostatectomy may allow the surgeon to make more-precise movements with surgical tools than is possible with traditional minimally invasive surgery. - making an incision in your abdomen. during retropubic surgery, the prostate gland is taken out through an incision in your lower abdomen. discuss with your doctor which type of surgery is best for your specific situation. radical prostatectomy carries a risk of urinary incontinence and erectile dysfunction. ask your doctor to explain the risks you may face based on your situation, the type of procedure you select, your age, your body type and your overall health. radiation therapy radiation therapy uses high-powered energy to kill cancer cells. prostate cancer radiation therapy can be delivered in two ways: - radiation that comes from outside of your body (external beam radiation). during external beam radiation therapy, you lie on a table while a machine moves around your body, directing high-powered energy beams, such as x-rays or protons, to your prostate cancer. you typically undergo external beam radiation treatments five days a week for several weeks. - radiation placed inside your body (brachytherapy). brachytherapy involves placing many rice-sized radioactive seeds in your prostate tissue. the radioactive seeds deliver a low dose of radiation over a long period of time. your doctor implants the radioactive seeds in your prostate using a needle guided by ultrasound images. the implanted seeds eventually stop emitting radiation and don't need to be removed. side effects of radiation therapy can include painful, frequent or urgent urination, as well as rectal symptoms such as loose stools or pain when passing stools. erectile dysfunction can also occur. hormone therapy hormone therapy is treatment to stop your body from producing the male hormone testosterone. prostate cancer cells rely on testosterone to help them grow. cutting off the supply of testosterone may cause cancer cells to die or to grow more slowly. hormone therapy options include: - medications that stop your body from producing testosterone. medications known as luteinizing hormone-releasing hormone (lh-rh) agonists prevent the testicles from receiving messages to make testosterone. drugs typically used in this type of hormone therapy include leuprolide (lupron, eligard), goserelin (zoladex), triptorelin (trelstar) and histrelin (vantas). other drugs sometimes used include ketoconazole and abiraterone (zytiga). - medications that block testosterone from reaching cancer cells. medications known as anti-androgens prevent testosterone from reaching your cancer cells. examples include bicalutamide (casodex), nilutamide (nilandron) and flutamide. the drug enzalutamide (xtandi) may be an option when other hormone therapies are no longer effective. - surgery to remove the testicles (orchiectomy). removing your testicles reduces testosterone levels in your body. hormone therapy is used in men with advanced prostate cancer to shrink the cancer and slow the growth of tumors. in men with early-stage prostate cancer, hormone therapy may be used to shrink tumors before radiation therapy, which can increase the likelihood that radiation therapy will be successful. side effects of hormone therapy may include erectile dysfunction, hot flashes, loss of bone mass, reduced sex drive and weight gain. freezing prostate tissue cryosurgery or cryoablation involves freezing tissue to kill cancer cells. during cryosurgery for prostate cancer, small needles are inserted in the prostate using ultrasound images as guidance. a very cold gas is placed in the needles, which causes the surrounding tissue to freeze. a second gas is then placed in the needles to reheat the tissue. the cycles of freezing and thawing kill the cancer cells and some surrounding healthy tissue. initial attempts to use cryosurgery for prostate cancer resulted in high complication rates and unacceptable side effects. however, newer technologies have lowered complication rates, improved cancer control and made the procedure easier to tolerate. cryosurgery is more frequently used as a salvage therapy for men who haven't been helped by radiation therapy. chemotherapy chemotherapy uses drugs to kill rapidly growing cells, including cancer cells. chemotherapy can be administered through a vein in your arm, in pill form or both. chemotherapy may be a treatment option for men with prostate cancer that has spread to remote body locations. chemotherapy may also be an option for cancers that don't respond to hormone therapy. biological therapy biological therapy (immunotherapy) uses your body's immune system to fight cancer cells. one type of biological therapy called sipuleucel-t (provenge) has been developed to treat advanced, recurrent prostate cancer. this treatment takes some of your own immune cells, genetically engineers them in a laboratory to fight prostate cancer, then injects the cells back into your body through a vein. some men do respond to this therapy with some improvement in their cancer, but the treatment is very expensive and requires multiple treatments.\",\n",
       "  'prostate cancer (treatment option overview): - there are different types of treatment for patients with prostate cancer. - seven types of standard treatment are used: - watchful waiting or active surveillance - surgery - radiation therapy and radiopharmaceutical therapy - hormone therapy - chemotherapy - biologic therapy - bisphosphonate therapy - there are treatments for bone pain caused by bone metastases or hormone therapy. - new types of treatment are being tested in clinical trials. - cryosurgery - high-intensity-focused ultrasound therapy - proton beam radiation therapy - patients may want to think about taking part in a clinical trial. - patients can enter clinical trials before, during, or after starting their cancer treatment. - follow-up tests may be needed.',\n",
       "  'familial prostate cancer (treatment): fda-approved treatments the medication(s) listed below have been approved by the food and drug administration (fda) as orphan products for treatment of this condition. learn more orphan products. national library of medicine drug information portal',\n",
       "  'familial prostate cancer: familial prostate cancer is a cluster of prostate cancer within a family. most cases of prostate cancer occur sporadically in people with no family history of the condition. however, approximately 5% to 10% of prostate cancer cases are believed to be primarily caused by a genetic predisposition to the condition.  in many families, the underlying genetic cause is unknown; however, some of these cases are caused by changes ( mutations ) in the brca1 , brca2, hoxb13, or several other genes . other cases are likely due to a combination of gene(s) and other shared factors such as environment and lifestyle.  high-risk cancer screening at an earlier age is typically recommended in men who have an increased risk for prostate cancer based on personal and/or family histories. the human phenotype ontology (hpo) provides the following list of features that have been reported in people with this condition. much of the information in the hpo comes from orphanet, a european rare disease database. if available, the list includes a rough estimate of how common a feature is (its frequency). frequencies are based on a specific study and may not be representative of all studies. you can use the medlineplus medical dictionary for definitions of the terms below. signs and symptoms approximate number of patients (when available) autosomal dominant inheritance - neoplasm - prostate cancer - making a diagnosis for a genetic or rare disease can often be challenging. healthcare professionals typically look at a person’s medical history, symptoms, physical exam, and laboratory test results in order to make a diagnosis. the following resources provide information relating to diagnosis and testing for this condition. if you have questions about getting a diagnosis, you should contact a healthcare professional. testing resources the genetic testing registry (gtr) provides information about the genetic tests for this condition. the intended audience for the gtr is health care providers and researchers. patients and consumers with specific questions about a genetic test should contact a health care provider or a genetics professional. fda-approved treatments the medication(s) listed below have been approved by the food and drug administration (fda) as orphan products for treatment of this condition. learn more orphan products. national library of medicine drug information portal',\n",
       "  'cryotherapy for prostate cancer: cryotherapy uses very cold temperatures to freeze and kill prostate cancer cells. the goal of cryosurgery is to destroy the entire prostate gland and possibly surrounding tissue. cryosurgery is generally not used as a first treatment for prostate cancer. before the procedure, you will be given medicine so that you do not feel pain. you may receive: - a sedative to make you drowsy and numbing medicine on your perineum. this is the area between the anus and scrotum. - anesthesia. with spinal anesthesia, you will be drowsy but awake, and numb below the waist. with general anesthesia, you will be asleep and pain-free. first, you will get a catheter that will stay in place for about 3 weeks after the procedure. then, the doctor makes small cuts to place several hollow needles into your perineum. - ultrasound is used to guide the needles to the prostate gland. - then, very cold gas passes through the needles, creating ice balls that destroy the prostate gland. - warm salt water will flow through the catheter to keep your urethra (the tube from the bladder to outside the body) from freezing. cryosurgery is most often a 2-hour outpatient procedure. some people may need to stay in the hospital overnight. this therapy is not as commonly used and is not as well accepted as other treatments for prostate cancer. doctors do not know for certain how well cryosurgery works over time. there is not enough data to compare it with standard prostatectomy, radiation treatment, or brachytherapy. it can only treat prostate cancer that has not spread beyond the prostate. men who cannot have surgery because of their age or other health problems may have cryosurgery instead. it also may be used if cancer comes back after other treatments. it is generally not helpful for men with very large prostate glands. possible short-term side effects of cryotherapy for prostate cancer include: - blood in the urine - trouble passing urine - swelling of the penis or scrotum - problems controlling your bladder (more likely if you have had radiation therapy also) possible long-term problems include: - erection problems in nearly all people - damage to the rectum - a tube that forms between the rectum and the bladder, called a fistula (this is very rare) - problems with passing or controlling urine. updated by: todd gersten, md, hematology/oncology, florida cancer specialists and research institute, wellington, fl. review provided by verimed healthcare network. also reviewed by david zieve, md, mha, isla ogilvie, phd, and the a.d.a.m. editorial team.'],\n",
       " [3, 6, 1, 4, 2, 7, 5],\n",
       " [1, 0, 1, 1, 1, 0, 1]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QA[13][0]\n",
    "QA[207]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yrbouUBaSoqL"
   },
   "outputs": [],
   "source": [
    "text = \"Here is the sentence I want embeddings for.\"\n",
    "text = QA[13][0]\n",
    "marked_text = \"[CLS] \" + text #+ \" [SEP]\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "U37tJBtGS4UH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3ea03b59-d771-44da-cfee-8d07f79ad58e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'va',\n",
       " '##sc',\n",
       " '##uli',\n",
       " '##tis',\n",
       " '.',\n",
       " 'yes',\n",
       " 'my',\n",
       " 'wife',\n",
       " 'has',\n",
       " 'been',\n",
       " 'dian',\n",
       " '##ose',\n",
       " '##d',\n",
       " 'with',\n",
       " 'giant',\n",
       " 'cell',\n",
       " 'va',\n",
       " '##sc',\n",
       " '##uli',\n",
       " '##tis',\n",
       " 'our',\n",
       " 'doctors',\n",
       " 'are',\n",
       " 'not',\n",
       " 'clear',\n",
       " 'about',\n",
       " 'this',\n",
       " 'so',\n",
       " 'im',\n",
       " 'asking',\n",
       " 'for',\n",
       " 'help',\n",
       " 'from',\n",
       " 'you',\n",
       " '.',\n",
       " 'she',\n",
       " 'has',\n",
       " 'vomit',\n",
       " '##ed',\n",
       " 'something',\n",
       " 'like',\n",
       " 'coffee',\n",
       " 'grounds',\n",
       " 'and',\n",
       " 'swelling',\n",
       " 'in',\n",
       " 'her',\n",
       " 'feet',\n",
       " 'and',\n",
       " 'legs',\n",
       " 'is',\n",
       " 'really',\n",
       " 'bad',\n",
       " '.',\n",
       " 'mig',\n",
       " '##rane',\n",
       " '##s',\n",
       " 'and',\n",
       " 'face',\n",
       " 'swelling',\n",
       " 'to',\n",
       " '.',\n",
       " 'no',\n",
       " 'blood',\n",
       " 'cl',\n",
       " '##ots',\n",
       " 'but',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'so',\n",
       " 'please',\n",
       " 'help',\n",
       " 'if',\n",
       " 'u',\n",
       " 'can',\n",
       " 'thank',\n",
       " 'u']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b4961a103212423296653018838aaa87",
      "10eb159905cb4da881e506bea7ef3bf7",
      "1a0d610808c54752a01d8fafe188c6a5",
      "98128371afc04f1495643f1524b95c7a",
      "ff2c3058101f4d7b8ec7e6b479ab5924",
      "3a3968f8f4114cbcbd04edb27c82717e",
      "4080dd44dc56497eb9585b20104cf45a",
      "e40dd44721f5472baae808befb672eb9",
      "d8865f8d7f684edcb9c323c7b30ac7a6",
      "1f8d2fe393ea4898a5d9384974cc7e6f",
      "b97b0de7f6684d60a0744f03f63c3510",
      "e7e5210cbf89470d914f0dec74f58fc0",
      "07b7a135531e43fb8174e780bf4a54e9",
      "9c8345c9dea24483a59817527326f1ef",
      "dad2627650c6436fa21d6cf6bb1b2143",
      "85f6584af22b4a1e931aad09f7fe66b2"
     ]
    },
    "collapsed": true,
    "id": "N_VPdqqZS6KX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "92264023-b3d7-4d85-97c7-389960aae062"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7261eab4854ec392865ebe3a47fb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b8f0aa89c4ecdbf8b7ec8a4474f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9144c790c4ce49feb706b223295b2203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=289.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50315812c07c47c2a5486da4c5c854f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1461743275.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(58996, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "model = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTcax3jJT_vw",
    "outputId": "d860bef6-0f48-4341-eed8-2b35b37f094f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'va', '##sc', '##uli', '##tis', '.', 'yes', 'my', 'wife', 'has', 'been', 'dian', '##ose', '##d', 'with', 'giant', 'cell', 'va', '##sc', '##uli', '##tis', 'our', 'doctors', 'are', 'not', 'clear', 'about', 'this', 'so', 'im', 'asking', 'for', 'help', 'from', 'you', '.', 'she', 'has', 'vomit', '##ed', 'something', 'like', 'coffee', 'grounds', 'and', 'swelling', 'in', 'her', 'feet', 'and', 'legs', 'is', 'really', 'bad', '.', 'mig', '##rane', '##s', 'and', 'face', 'swelling', 'to', '.', 'no', 'blood', 'cl', '##ots', 'but', 'nothing', 'to', 'go', 'on', 'so', 'please', 'help', 'if', 'u', 'can', 'thank', 'u']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "aZ1pzp84UNqY",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f71c0e84-661b-4fec-af03-7ca80c05a55a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 36006,\n",
       " 29185,\n",
       " 15818,\n",
       " 6620,\n",
       " 119,\n",
       " 4208,\n",
       " 1139,\n",
       " 1676,\n",
       " 1144,\n",
       " 1151,\n",
       " 39765,\n",
       " 6787,\n",
       " 1181,\n",
       " 1114,\n",
       " 4994,\n",
       " 2765,\n",
       " 36006,\n",
       " 29185,\n",
       " 15818,\n",
       " 6620,\n",
       " 1412,\n",
       " 8114,\n",
       " 1132,\n",
       " 1136,\n",
       " 2330,\n",
       " 1164,\n",
       " 1142,\n",
       " 1177,\n",
       " 13280,\n",
       " 4107,\n",
       " 1111,\n",
       " 1494,\n",
       " 1121,\n",
       " 1128,\n",
       " 119,\n",
       " 1131,\n",
       " 1144,\n",
       " 26979,\n",
       " 1174,\n",
       " 1380,\n",
       " 1176,\n",
       " 3538,\n",
       " 4745,\n",
       " 1105,\n",
       " 20085,\n",
       " 1107,\n",
       " 1123,\n",
       " 1623,\n",
       " 1105,\n",
       " 2584,\n",
       " 1110,\n",
       " 1541,\n",
       " 2213,\n",
       " 119,\n",
       " 45648,\n",
       " 18194,\n",
       " 1116,\n",
       " 1105,\n",
       " 1339,\n",
       " 20085,\n",
       " 1106,\n",
       " 119,\n",
       " 1185,\n",
       " 1892,\n",
       " 29260,\n",
       " 12129,\n",
       " 1133,\n",
       " 1720,\n",
       " 1106,\n",
       " 1301,\n",
       " 1113,\n",
       " 1177,\n",
       " 4268,\n",
       " 1494,\n",
       " 1191,\n",
       " 190,\n",
       " 1169,\n",
       " 6243,\n",
       " 190]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "kLQX3ZpH7uNi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "31c8fb76-d2b0-4dbd-a438-df22a0187980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oU6Ewro4Ut6g"
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q1hzPm4aUe9M"
   },
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ePo-iN_FUpNg",
    "outputId": "654b14e7-5820-40ac-dab0-7391da27e137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 80, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zN60nnpVVpyo"
   },
   "outputs": [],
   "source": [
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bhwJLwsCWQ94"
   },
   "outputs": [],
   "source": [
    "def get_bert_sentence_embedding(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # print(len(hidden_states.shape))\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all n token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wQriO3btXAir"
   },
   "outputs": [],
   "source": [
    "q = get_bert_sentence_embedding(QA[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FrJWZ9znXJLg"
   },
   "outputs": [],
   "source": [
    "ans = [get_bert_sentence_embedding(a[:512]) for a in QA[1][1]] # 512 is the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfVYsDUDXSHZ",
    "outputId": "eb1a596c-f0e6-4bd2-85c1-12b968bb34ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n",
      "0 2 0.9360920190811157\n",
      "0 3 0.956549882888794\n",
      "0 1 0.9428353905677795\n",
      "0 10 0.9331551790237427\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "K = 7 #??\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q, a)\n",
    "    print(QA[K][3][i], QA[K][2][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6GMd3aEYlmK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nY0_lyO8KdWJ"
   },
   "source": [
    "## BIO-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgmke4dJKfID",
    "outputId": "70a22e57-1244-469c-df4b-86d825a92c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'biobert'...\n",
      "remote: Enumerating objects: 48, done.\u001b[K\n",
      "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
      "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
      "remote: Total 326 (delta 26), reused 7 (delta 3), pack-reused 278\u001b[K\n",
      "Receiving objects: 100% (326/326), 507.09 KiB | 7.14 MiB/s, done.\n",
      "Resolving deltas: 100% (188/188), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/dmis-lab/biobert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg7mA966K20W"
   },
   "outputs": [],
   "source": [
    "! cd biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlK1gBbVLC2j",
    "outputId": "69bfdc04-3d72-4049-8ec5-8f28756c3927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/biobert\n"
     ]
    }
   ],
   "source": [
    "cd biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xFaGFtvlLE0V",
    "outputId": "36400523-87bf-455b-f1f7-8063e996631e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.15.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
      "\u001b[K     |████████████████████████████████| 411.0MB 41kB/s \n",
      "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Collecting pandas==0.23\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ec/8ff0800b8594691759b78a42ccd616f81e7099ee47b167eb9bbd502c02b9/pandas-0.23.0-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7MB 51.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.15.0)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.8.1)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 43.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.1.0)\n",
      "Collecting keras-applications>=1.0.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.33.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.35.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.1.2)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 49.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23->-r requirements.txt (line 7)) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23->-r requirements.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (50.3.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.4.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=167dfff8558252f15730601c1767a1308d0dd8afd9d0bb118e1384e5b85db1a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu, pandas\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "  Found existing installation: pandas 1.1.4\n",
      "    Uninstalling pandas-1.1.4:\n",
      "      Successfully uninstalled pandas-1.1.4\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 pandas-0.23.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pandas"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install requirements\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9TqXEwRdPFzl",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e2b66df1-64cb-470e-a4b0-c885d571687f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIOBERT_DATA not set; downloading to default path ('data').\n",
      "--2020-11-22 16:26:15--  https://docs.google.com/uc?export=download&confirm=SwVU&id=1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j\n",
      "Resolving docs.google.com (docs.google.com)... 74.125.20.113, 74.125.20.139, 74.125.20.101, ...\n",
      "Connecting to docs.google.com (docs.google.com)|74.125.20.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download [following]\n",
      "--2020-11-22 16:26:15--  https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download\n",
      "Resolving doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n",
      "Connecting to doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://docs.google.com/nonceSigner?nonce=737ovtluehqrs&continue=https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e%3Ddownload&hash=5033fqhkj7uekb95mmi8rkojjo09s0bl [following]\n",
      "--2020-11-22 16:26:15--  https://docs.google.com/nonceSigner?nonce=737ovtluehqrs&continue=https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e%3Ddownload&hash=5033fqhkj7uekb95mmi8rkojjo09s0bl\n",
      "Connecting to docs.google.com (docs.google.com)|74.125.20.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download&nonce=737ovtluehqrs&user=08359205414467609423Z&hash=5rlt2i8cdjtkbodftq2ukdlp7i2ssena [following]\n",
      "--2020-11-22 16:26:15--  https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download&nonce=737ovtluehqrs&user=08359205414467609423Z&hash=5rlt2i8cdjtkbodftq2ukdlp7i2ssena\n",
      "Connecting to doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘./data.tar.gz’\n",
      "\n",
      "./data.tar.gz           [  <=>               ]  28.24M  92.9MB/s    in 0.3s    \n",
      "\n",
      "2020-11-22 16:26:16 (92.9 MB/s) - ‘./data.tar.gz’ saved [29610233]\n",
      "\n",
      "datasets/\n",
      "datasets/RE/\n",
      "datasets/RE/GAD/\n",
      "datasets/RE/GAD/6/\n",
      "datasets/RE/GAD/6/test.tsv\n",
      "datasets/RE/GAD/6/dev.tsv\n",
      "datasets/RE/GAD/6/train.tsv\n",
      "datasets/RE/GAD/7/\n",
      "datasets/RE/GAD/7/test.tsv\n",
      "datasets/RE/GAD/7/dev.tsv\n",
      "datasets/RE/GAD/7/train.tsv\n",
      "datasets/RE/GAD/5/\n",
      "datasets/RE/GAD/5/test.tsv\n",
      "datasets/RE/GAD/5/dev.tsv\n",
      "datasets/RE/GAD/5/train.tsv\n",
      "datasets/RE/GAD/8/\n",
      "datasets/RE/GAD/8/test.tsv\n",
      "datasets/RE/GAD/8/dev.tsv\n",
      "datasets/RE/GAD/8/train.tsv\n",
      "datasets/RE/GAD/4/\n",
      "datasets/RE/GAD/4/test.tsv\n",
      "datasets/RE/GAD/4/dev.tsv\n",
      "datasets/RE/GAD/4/train.tsv\n",
      "datasets/RE/GAD/1/\n",
      "datasets/RE/GAD/1/test.tsv\n",
      "datasets/RE/GAD/1/dev.tsv\n",
      "datasets/RE/GAD/1/train.tsv\n",
      "datasets/RE/GAD/2/\n",
      "datasets/RE/GAD/2/test.tsv\n",
      "datasets/RE/GAD/2/dev.tsv\n",
      "datasets/RE/GAD/2/train.tsv\n",
      "datasets/RE/GAD/3/\n",
      "datasets/RE/GAD/3/test.tsv\n",
      "datasets/RE/GAD/3/dev.tsv\n",
      "datasets/RE/GAD/3/train.tsv\n",
      "datasets/RE/GAD/9/\n",
      "datasets/RE/GAD/9/test.tsv\n",
      "datasets/RE/GAD/9/dev.tsv\n",
      "datasets/RE/GAD/9/train.tsv\n",
      "datasets/RE/GAD/10/\n",
      "datasets/RE/GAD/10/test.tsv\n",
      "datasets/RE/GAD/10/dev.tsv\n",
      "datasets/RE/GAD/10/train.tsv\n",
      "datasets/RE/euadr/\n",
      "datasets/RE/euadr/6/\n",
      "datasets/RE/euadr/6/test.tsv\n",
      "datasets/RE/euadr/6/dev.tsv\n",
      "datasets/RE/euadr/6/train.tsv\n",
      "datasets/RE/euadr/7/\n",
      "datasets/RE/euadr/7/test.tsv\n",
      "datasets/RE/euadr/7/dev.tsv\n",
      "datasets/RE/euadr/7/train.tsv\n",
      "datasets/RE/euadr/5/\n",
      "datasets/RE/euadr/5/test.tsv\n",
      "datasets/RE/euadr/5/dev.tsv\n",
      "datasets/RE/euadr/5/train.tsv\n",
      "datasets/RE/euadr/8/\n",
      "datasets/RE/euadr/8/test.tsv\n",
      "datasets/RE/euadr/8/dev.tsv\n",
      "datasets/RE/euadr/8/train.tsv\n",
      "datasets/RE/euadr/4/\n",
      "datasets/RE/euadr/4/test.tsv\n",
      "datasets/RE/euadr/4/dev.tsv\n",
      "datasets/RE/euadr/4/train.tsv\n",
      "datasets/RE/euadr/1/\n",
      "datasets/RE/euadr/1/test.tsv\n",
      "datasets/RE/euadr/1/dev.tsv\n",
      "datasets/RE/euadr/1/train.tsv\n",
      "datasets/RE/euadr/2/\n",
      "datasets/RE/euadr/2/test.tsv\n",
      "datasets/RE/euadr/2/dev.tsv\n",
      "datasets/RE/euadr/2/train.tsv\n",
      "datasets/RE/euadr/3/\n",
      "datasets/RE/euadr/3/test.tsv\n",
      "datasets/RE/euadr/3/dev.tsv\n",
      "datasets/RE/euadr/3/train.tsv\n",
      "datasets/RE/euadr/9/\n",
      "datasets/RE/euadr/9/test.tsv\n",
      "datasets/RE/euadr/9/dev.tsv\n",
      "datasets/RE/euadr/9/train.tsv\n",
      "datasets/RE/euadr/10/\n",
      "datasets/RE/euadr/10/test.tsv\n",
      "datasets/RE/euadr/10/dev.tsv\n",
      "datasets/RE/euadr/10/train.tsv\n",
      "datasets/QA/\n",
      "datasets/QA/BioASQ/\n",
      "datasets/QA/BioASQ/6B1_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-7b.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-5b-4.json\n",
      "datasets/QA/BioASQ/5B3_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-4b-2.json\n",
      "datasets/QA/BioASQ/4B1_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-train-yesno-7b.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-5b-5.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-5b-2.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-6b-2.json\n",
      "datasets/QA/BioASQ/4B4_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-6b-3.json\n",
      "datasets/QA/BioASQ/6B3_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-5b-3.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-6b-5.json\n",
      "datasets/QA/BioASQ/BioASQ-test-yesno-7b.json\n",
      "datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-4b-1.json\n",
      "datasets/QA/BioASQ/6B5_golden.json\n",
      "datasets/QA/BioASQ/5B1_golden.json\n",
      "datasets/QA/BioASQ/4B5_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-4b-3.json\n",
      "datasets/QA/BioASQ/7B_golden.json\n",
      "datasets/QA/BioASQ/5B4_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-train-factoid-6b.json\n",
      "datasets/QA/BioASQ/BioASQ-train-factoid-7b.json\n",
      "datasets/QA/BioASQ/SHA1.txt\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json\n",
      "datasets/QA/BioASQ/BioASQ-train-factoid-5b.json\n",
      "datasets/QA/BioASQ/5B2_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-6b-4.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-5b-1.json\n",
      "datasets/QA/BioASQ/4B3_golden.json\n",
      "datasets/QA/BioASQ/6B2_golden.json\n",
      "datasets/QA/BioASQ/4B2_golden.json\n",
      "datasets/QA/BioASQ/6B4_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-4b-5.json\n",
      "datasets/QA/BioASQ/5B5_golden.json\n",
      "datasets/QA/BioASQ/BioASQ-test-factoid-4b-4.json\n",
      "datasets/NER/\n",
      "datasets/NER/linnaeus/\n",
      "datasets/NER/linnaeus/devel.tsv\n",
      "datasets/NER/linnaeus/test.tsv\n",
      "datasets/NER/linnaeus/train_dev.tsv\n",
      "datasets/NER/linnaeus/train.tsv\n",
      "datasets/NER/BC2GM/\n",
      "datasets/NER/BC2GM/devel.tsv\n",
      "datasets/NER/BC2GM/test.tsv\n",
      "datasets/NER/BC2GM/train_dev.tsv\n",
      "datasets/NER/BC2GM/train.tsv\n",
      "datasets/NER/BC5CDR-disease/\n",
      "datasets/NER/BC5CDR-disease/devel.tsv\n",
      "datasets/NER/BC5CDR-disease/test.tsv\n",
      "datasets/NER/BC5CDR-disease/train_dev.tsv\n",
      "datasets/NER/BC5CDR-disease/train.tsv\n",
      "datasets/NER/NCBI-disease/\n",
      "datasets/NER/NCBI-disease/devel.tsv\n",
      "datasets/NER/NCBI-disease/test.tsv\n",
      "datasets/NER/NCBI-disease/train_dev.tsv\n",
      "datasets/NER/NCBI-disease/train.tsv\n",
      "datasets/NER/s800/\n",
      "datasets/NER/s800/devel.tsv\n",
      "datasets/NER/s800/test.tsv\n",
      "datasets/NER/s800/train_dev.tsv\n",
      "datasets/NER/s800/train.tsv\n",
      "datasets/NER/BC5CDR-chem/\n",
      "datasets/NER/BC5CDR-chem/devel.tsv\n",
      "datasets/NER/BC5CDR-chem/test.tsv\n",
      "datasets/NER/BC5CDR-chem/train_dev.tsv\n",
      "datasets/NER/BC5CDR-chem/train.tsv\n",
      "datasets/NER/JNLPBA/\n",
      "datasets/NER/JNLPBA/devel.tsv\n",
      "datasets/NER/JNLPBA/test.tsv\n",
      "datasets/NER/JNLPBA/train_dev.tsv\n",
      "datasets/NER/JNLPBA/train.tsv\n",
      "datasets/NER/BC4CHEMD/\n",
      "datasets/NER/BC4CHEMD/devel.tsv\n",
      "datasets/NER/BC4CHEMD/test.tsv\n",
      "datasets/NER/BC4CHEMD/train_dev.tsv\n",
      "datasets/NER/BC4CHEMD/train.tsv\n",
      "BioBERT dataset download done!\n"
     ]
    }
   ],
   "source": [
    "# Download datasets\n",
    "! ./download.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPLNLI1SLIj1",
    "outputId": "37662559-8ad1-41a3-f24d-f0f7afbb2cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download biobert_v1.1_pubmed and save int into the Colab Content\n",
    "! export BIOBERT_DIR=./biobert_v1.1_pubmed\n",
    "! echo $BIOBERT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKiPXyNRMbnK",
    "outputId": "e6c2db59-f93f-4028-9238-8831e72cb2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 313\n",
      " 4 drwx------ 2 root root  4096 Nov 21 17:42 biocodes\n",
      "15 -rw------- 1 root root 15237 Nov 21 17:42 create_pretraining_data.py\n",
      " 1 -rw------- 1 root root   903 Nov 21 17:42 download.sh\n",
      "14 -rw------- 1 root root 13898 Nov 21 17:42 extract_features.py\n",
      " 4 drwx------ 2 root root  4096 Nov 21 17:42 figs\n",
      " 1 -rw------- 1 root root   562 Nov 21 17:42 __init__.py\n",
      "12 -rw------- 1 root root 12060 Nov 21 17:42 LICENSE\n",
      "38 -rw------- 1 root root 38084 Nov 21 17:42 modeling.py\n",
      " 9 -rw------- 1 root root  9191 Nov 21 17:42 modeling_test.py\n",
      " 7 -rw------- 1 root root  6258 Nov 21 17:42 optimization.py\n",
      " 2 -rw------- 1 root root  1721 Nov 21 17:42 optimization_test.py\n",
      "13 -rw------- 1 root root 13150 Nov 21 17:42 README.md\n",
      " 1 -rw------- 1 root root   294 Nov 21 17:42 requirements.txt\n",
      "34 -rw------- 1 root root 34783 Nov 21 17:42 run_classifier.py\n",
      "27 -rw------- 1 root root 26953 Nov 21 17:42 run_ner.py\n",
      "19 -rw------- 1 root root 18667 Nov 21 17:42 run_pretraining.py\n",
      "46 -rw------- 1 root root 46789 Nov 21 17:42 run_qa.py\n",
      "39 -rw------- 1 root root 39145 Nov 21 17:42 run_re.py\n",
      " 5 -rw------- 1 root root  4394 Nov 21 17:42 sample_text.txt\n",
      " 9 -rw------- 1 root root  8402 Nov 21 17:42 tf_metrics.py\n",
      "12 -rw------- 1 root root 12257 Nov 21 17:42 tokenization.py\n",
      " 5 -rw------- 1 root root  4527 Nov 21 17:42 tokenization_test.py\n"
     ]
    }
   ],
   "source": [
    "! ls -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pu5wVbn8Mqq3",
    "outputId": "b29e8878-2b8c-489e-c363-00df7d16be05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioASQ\t\t\t    modeling.py\t\t  run_pretraining.py\n",
      "biocodes\t\t    modeling_test.py\t  run_qa.py\n",
      "create_pretraining_data.py  optimization.py\t  run_re.py\n",
      "download.sh\t\t    optimization_test.py  sample_text.txt\n",
      "extract_features.py\t    README.md\t\t  tf_metrics.py\n",
      "figs\t\t\t    requirements.txt\t  tokenization.py\n",
      "__init__.py\t\t    run_classifier.py\t  tokenization_test.py\n",
      "LICENSE\t\t\t    run_ner.py\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPI7ku1BMsDa"
   },
   "outputs": [],
   "source": [
    "! export QA_DIR=./BioASQ/\n",
    "! export OUTPUT_DIR=./qa_outputs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIAveURfOROs",
    "outputId": "05e677a1-162a-4538-c10e-1c326b699037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/biobert\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Crh-8eR6MxZ1",
    "outputId": "c79585ad-2c31-4dfa-fd11-2198661285a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/biobert\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGfqZ4h-M0vj"
   },
   "outputs": [],
   "source": [
    "! export OUTPUT_DIR=./qa_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asRwK7FkM6XT",
    "outputId": "3300ed96-4ef9-4ec5-ea8a-718de3abc958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: missing operand\n",
      "Try 'mkdir --help' for more information.\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vg6f5hYJM92S",
    "outputId": "0c1336e2-0106-4805-a106-9b458333c374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/biobert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From run_qa.py:1290: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From run_qa.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "W1121 09:50:52.776824 140584916920192 module_wrapper.py:139] From run_qa.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "WARNING:tensorflow:From run_qa.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1121 09:50:52.777034 140584916920192 module_wrapper.py:139] From run_qa.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1121 09:50:52.777210 140584916920192 module_wrapper.py:139] From /content/biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"run_qa.py\", line 1290, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"run_qa.py\", line 1136, in main\n",
      "    bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
      "  File \"/content/biobert/modeling.py\", line 93, in from_json_file\n",
      "    text = reader.read()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
      "    self._preread_check()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /bert_config.json; No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! python run_qa.py --do_train=True --do_predict=True --vocab_file=$BIOBERT_DIR/vocab.txt --bert_config_file=$BIOBERT_DIR/bert_config.json --init_checkpoint=$BIOBERT_DIR/model.ckpt-1000000 --max_seq_length=384 --train_batch_size=12 --learning_rate=5e-6 --doc_stride=128 --num_train_epochs=5.0 --do_lower_case=False --train_file=$QA_DIR/BioASQ-train-factoid-4b.json --predict_file=$QA_DIR/BioASQ-test-factoid-4b-1.json --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSxdmEv9NJME"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jC9ni1UU-Jp0"
   },
   "source": [
    "# Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icNdSd-e-JAa"
   },
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(rs):\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "7qQ1VttH_AfW",
    "outputId": "a9469750-2acb-428a-d38e-2f8d110a5c3d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-809cb368f981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rank, entail = QA[0][2:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreference_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQA2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msystem_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQA2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'QA2' is not defined"
     ]
    }
   ],
   "source": [
    "# rank, entail = QA[0][2:]\n",
    "reference_ranks = [np.array(q[2]) for q in QA2]\n",
    "system_ranks = [np.array(q[3]) for q in QA2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp5BylFXOX7a"
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for a, b in zip(reference_ranks, system_ranks):\n",
    "    res = np.array(a)[np.argsort(b)]\n",
    "    predicted.append([int(i==min(res)) for i in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tWYVvwfB8c5",
    "outputId": "515f1318-ce13-46f8-e8b4-f9867b78ff60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924920634920635"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reciprocal_rank(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHykldLG-6_l"
   },
   "outputs": [],
   "source": [
    "def calc_hit_rank(prediction, reference):\n",
    "    for i, p in enumerate(prediction):\n",
    "        if reference[p-1] == 1:\n",
    "            return i+1\n",
    "    print(prediction)\n",
    "    print(reference)\n",
    "    raise ValueError('No reference!')\n",
    "\n",
    "def mean_reciprocal_rank(predictions, references):\n",
    "    assert len(predictions) == len(references)\n",
    "    ranks = []\n",
    "    for p, c in zip(predictions, references):\n",
    "        rank = calc_hit_rank(p, c)\n",
    "        ranks.append(1.0 / rank)\n",
    "    return sum(ranks) * 1.0 / len(ranks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NukjYbbHP4kx",
    "outputId": "d78d92df-09de-4a99-cb7b-bcec0f8b1fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5924920634920635"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_ranks2 = [(np.array(arr) == 1).astype(np.int64) for arr in reference_ranks]\n",
    "system_ranks2 = [(np.array(arr) == 1).astype(np.int64) for arr in system_ranks]\n",
    "mean_reciprocal_rank(system_ranks, reference_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bCHtijXBvdt"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def mean_spearmanr(predictions, references):\n",
    "    count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        count += spearmanr(predictions[i], references[i])[0]\n",
    "\n",
    "    return count/len(system_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "uF0dvFdJSapo",
    "outputId": "de89796e-d3b0-4dc7-d9d6-72b12813b499"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7fa07ee02b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindx2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# QA2 has also system ranks from ChiQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# i += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "indx2id = []\n",
    "QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "for filename in os.listdir('./'):\n",
    "    # i += 1\n",
    "    print(filename)\n",
    "    if not filename.endswith('.xml') or 'Labels' not in filename: continue\n",
    "    fullname = os.path.join('data/Test', filename)\n",
    "    tree = parse(filename)\n",
    "    questions = tree.getElementsByTagName('Question')\n",
    "    for question in questions:\n",
    "        qelem = question.getElementsByTagName('QuestionText')\n",
    "        q, qid = preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "        # print(q) # --> questions\n",
    "        answers = question.getElementsByTagName('Answer')\n",
    "        answers_list, rank, system, labels = get_answers(answers)\n",
    "        QA.append([q,answers_list, rank, labels])\n",
    "        QA2.append([q,answers_list, rank, system, labels])\n",
    "        indx2id.append(qid); i+=1;\n",
    "        # break\n",
    "len(QA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEZNTT2NUHOr"
   },
   "outputs": [],
   "source": [
    "reference_ranks = [np.array(q[2]) for q in QA2]\n",
    "system_ranks = [np.array(q[3]) for q in QA2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9nTkdt4W0n1",
    "outputId": "e4758a1d-d3cc-4839-dca0-8dbe37fa8352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3631053391053391"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_spearmanr(system_ranks, reference_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrbbI8krXBVv"
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for a, b in zip(reference_ranks, system_ranks):\n",
    "    res = np.array(a)[np.argsort(b)]\n",
    "    predicted.append([int(i==min(res)) for i in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFyZJXqaXGbv",
    "outputId": "89499d2c-295e-4b53-8ed6-ed27b8812553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6025846560846562"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_reciprocal_rank(rs):\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "mean_reciprocal_rank(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9LHTsbizHboQ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class Question(object):\n",
    "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
    "        self.question_id = q_id\n",
    "        self.question = q\n",
    "        self.answer_ids = a_ids\n",
    "        self.answers = a\n",
    "        self.reference_rank = r\n",
    "        self.system_rank = s\n",
    "        self.labels = l\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class QuestionsAndAnswers(list):\n",
    "    def __init__(self, dataset='Train'):\n",
    "        ''' dataset = {Train,Test,Validation} '''\n",
    "        list.__init__(self)\n",
    "        p = self.read_dataset(dataset)\n",
    "        self.extend(self.read_dataset(dataset))\n",
    "        self.references = [np.array(q.reference_rank) for q in self]\n",
    "        self.labels = [np.array(q.labels) for q in self]\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "        return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "    def get_answers(self, answers):\n",
    "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
    "        for answer in answers:\n",
    "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "            a_id = answer.getAttribute('AID')\n",
    "            reference = int(answer.getAttribute('ReferenceRank'))\n",
    "            system = int(answer.getAttribute('SystemRank'))\n",
    "            label = answer.getAttribute('ReferenceScore')\n",
    "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "        return answs, answs_ids, rank, chiqa, y\n",
    "\n",
    "    def read_dataset(self, dataset='Train'):\n",
    "        i = 0\n",
    "        indx2id = []\n",
    "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
    "        for filename in os.listdir('./'):\n",
    "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
    "            tree = parse(filename)\n",
    "            questions = tree.getElementsByTagName('Question')\n",
    "            for question in questions:\n",
    "                qelem = question.getElementsByTagName('QuestionText')\n",
    "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "                # print(q) # --> questions\n",
    "                answers = question.getElementsByTagName('Answer')\n",
    "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
    "                QA.append([q,answers_list, rank, labels])\n",
    "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
    "                # QA2.append([q,answers_list, rank, system, labels])\n",
    "                QA2.append(question)\n",
    "                indx2id.append(q_id); i+=1;\n",
    "                # break\n",
    "        return QA2\n",
    "    \n",
    "    def output_predictions(self, predictions, labels):\n",
    "        assert len(predictions) == len(self)\n",
    "        print('question_id,answer_id,label')\n",
    "        for i, p in enumerate(predictions):\n",
    "            q_id = QA[i].question_id\n",
    "            answers = QA[i].answer_ids\n",
    "            # order = np.array(a)[np.argsort(p)]\n",
    "            order = np.array(answers)[np.array(p)-1]\n",
    "            lab = labels[i]\n",
    "            for a_id, l in zip(order,lab):\n",
    "                print(f\"{q_id},{a_id},{int(l)}\")\n",
    "            \n",
    "    def normalize_sequence(self, seq):\n",
    "        seq = np.array(seq)\n",
    "        a = np.argsort(seq)\n",
    "        seq[a] = list(range(1,len(seq)+1))\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        preds = np.concatenate(predictions)\n",
    "        true  = np.concatenate(self.labels) \n",
    "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
    "        return accuracy_score(true, preds)\n",
    "\n",
    "    def precision(self, predictions):\n",
    "        precisions = []\n",
    "        num_answers = []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
    "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
    "            if len(p) == 0:\n",
    "                print(predictions[i])\n",
    "            correct = sum([a == b for a,b in zip(p, r)])\n",
    "            # for a,b in zip(p, r)\n",
    "            # num_answers.append(len(p))\n",
    "            precisions.append(correct/len(p))\n",
    "        return np.mean(precisions)\n",
    "        # return np.average(np.array(precisions), weights=num_answers)\n",
    "\n",
    "    def mean_spearmanr(self, predictions):\n",
    "        assert len(predictions) == len(self.references)\n",
    "        count, total = 0, 0\n",
    "        preds, refs = [], []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
    "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
    "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
    "            preds += p; refs += r\n",
    "            if len(r) == 1:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            elif len(r) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                total += 1\n",
    "                count += spearmanr(p, r)[0]\n",
    "        return spearmanr(preds, refs)[0]\n",
    "        # return count/total\n",
    "\n",
    "    def mean_reciprocal_rank(self, predicted):\n",
    "        rs = []\n",
    "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
    "            res = np.array(a)[np.argsort(b)]\n",
    "            labels = QA[k].labels\n",
    "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
    "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqqvI5WoQA-5",
    "outputId": "dd4a2536-1e05-48ce-eb94-3097f3ca1f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_sequence(seq):\n",
    "    seq = np.array(seq)\n",
    "    a = np.argsort(seq)\n",
    "    seq[a] = list(range(1,len(seq)+1))\n",
    "    return seq\n",
    "normalize_sequence([55, 55,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Zz4_hw-UJ4N8"
   },
   "outputs": [],
   "source": [
    "QA = QuestionsAndAnswers(dataset = 'Test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lfed9fHGLRlk",
    "outputId": "d2186749-f21a-4685-da5f-64172e40aad6"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-cdf1fb29b96e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mQA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "QA[0].question_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JIitEluGgwa"
   },
   "outputs": [],
   "source": [
    "system_ranks = [q.system_rank for q in QA]\n",
    "reference_ranks = [q.reference_rank for q in QA]\n",
    "labels = [q.labels for q in QA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIePqfZfdUj8",
    "outputId": "74b4c294-5a70-448c-8f28-314057b98eba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=1.0, pvalue=0.0)"
      ]
     },
     "execution_count": 406,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(np.concatenate(system_ranks), np.concatenate(reference_ranks))\n",
    "spearmanr([7, 9, 1], [2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8ZsOJp1deKg",
    "outputId": "904672f6-90e1-4507-b568-963e5451dfd2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system_ranks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-826e16b5cb88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_reciprocal_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msystem_ranks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'system_ranks' is not defined"
     ]
    }
   ],
   "source": [
    "QA.mean_reciprocal_rank(system_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Yw7uWfRdx3Y",
    "outputId": "98e00d94-95d5-4ef0-c260-0a004ebfd510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4492904692300491"
      ]
     },
     "execution_count": 408,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA.mean_spearmanr(system_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HCLPkI3ONfg",
    "outputId": "ca4b0f90-8e3c-403e-aeff-e6177f401ce6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5167118337850045"
      ]
     },
     "execution_count": 409,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_labels = [np.ones(len(l)) for l in labels]\n",
    "QA.accuracy(system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFo7-rcbRUzB",
    "outputId": "10be0f54-9220-46e4-a30e-9d050d5d6e18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4866481481481482"
      ]
     },
     "execution_count": 410,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA.precision(system_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "k51sU7zuS0nO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d7e003c8-c32d-472a-8154-ac5e1e39fb76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n",
      "1,1_Answer6,1\n",
      "1,1_Answer8,1\n",
      "1,1_Answer7,1\n",
      "1,1_Answer2,1\n",
      "1,1_Answer4,1\n",
      "1,1_Answer3,1\n",
      "1,1_Answer1,1\n",
      "2,2_Answer1,1\n",
      "2,2_Answer2,1\n",
      "2,2_Answer4,1\n",
      "2,2_Answer3,1\n",
      "3,3_Answer5,1\n",
      "3,3_Answer2,1\n",
      "3,3_Answer3,1\n",
      "3,3_Answer6,1\n",
      "3,3_Answer4,1\n",
      "3,3_Answer7,1\n",
      "3,3_Answer8,1\n",
      "3,3_Answer10,1\n",
      "3,3_Answer11,1\n",
      "3,3_Answer9,1\n",
      "5,5_Answer6,1\n",
      "5,5_Answer4,1\n",
      "5,5_Answer5,1\n",
      "5,5_Answer7,1\n",
      "5,5_Answer1,1\n",
      "5,5_Answer2,1\n",
      "5,5_Answer9,1\n",
      "6,6_Answer8,1\n",
      "6,6_Answer9,1\n",
      "6,6_Answer2,1\n",
      "6,6_Answer5,1\n",
      "6,6_Answer6,1\n",
      "6,6_Answer4,1\n",
      "6,6_Answer3,1\n",
      "6,6_Answer7,1\n",
      "6,6_Answer1,1\n",
      "7,7_Answer2,1\n",
      "7,7_Answer1,1\n",
      "7,7_Answer4,1\n",
      "7,7_Answer3,1\n",
      "7,7_Answer6,1\n",
      "7,7_Answer5,1\n",
      "7,7_Answer7,1\n",
      "8,8_Answer1,1\n",
      "8,8_Answer2,1\n",
      "8,8_Answer3,1\n",
      "10,10_Answer2,1\n",
      "10,10_Answer8,1\n",
      "10,10_Answer1,1\n",
      "10,10_Answer7,1\n",
      "10,10_Answer6,1\n",
      "10,10_Answer4,1\n",
      "10,10_Answer5,1\n",
      "10,10_Answer3,1\n",
      "12,12_Answer5,1\n",
      "12,12_Answer1,1\n",
      "12,12_Answer2,1\n",
      "12,12_Answer3,1\n",
      "12,12_Answer4,1\n",
      "13,13_Answer1,1\n",
      "13,13_Answer2,1\n",
      "13,13_Answer4,1\n",
      "13,13_Answer3,1\n",
      "14,14_Answer2,1\n",
      "14,14_Answer1,1\n",
      "15,15_Answer3,1\n",
      "15,15_Answer9,1\n",
      "15,15_Answer4,1\n",
      "15,15_Answer1,1\n",
      "15,15_Answer6,1\n",
      "15,15_Answer7,1\n",
      "15,15_Answer5,1\n",
      "15,15_Answer8,1\n",
      "15,15_Answer2,1\n",
      "16,16_Answer1,1\n",
      "16,16_Answer5,1\n",
      "16,16_Answer3,1\n",
      "16,16_Answer4,1\n",
      "16,16_Answer2,1\n",
      "17,17_Answer3,1\n",
      "17,17_Answer4,1\n",
      "17,17_Answer1,1\n",
      "17,17_Answer5,1\n",
      "18,18_Answer1,1\n",
      "18,18_Answer5,1\n",
      "18,18_Answer2,1\n",
      "18,18_Answer3,1\n",
      "18,18_Answer4,1\n",
      "19,19_Answer7,1\n",
      "19,19_Answer6,1\n",
      "19,19_Answer3,1\n",
      "19,19_Answer1,1\n",
      "19,19_Answer2,1\n",
      "19,19_Answer4,1\n",
      "21,21_Answer2,1\n",
      "21,21_Answer3,1\n",
      "21,21_Answer9,1\n",
      "21,21_Answer4,1\n",
      "21,21_Answer5,1\n",
      "21,21_Answer6,1\n",
      "21,21_Answer8,1\n",
      "21,21_Answer1,1\n",
      "21,21_Answer7,1\n",
      "22,22_Answer1,1\n",
      "22,22_Answer4,1\n",
      "22,22_Answer2,1\n",
      "22,22_Answer3,1\n",
      "23,23_Answer1,1\n",
      "23,23_Answer4,1\n",
      "23,23_Answer2,1\n",
      "23,23_Answer5,1\n",
      "24,24_Answer1,1\n",
      "24,24_Answer3,1\n",
      "24,24_Answer2,1\n",
      "25,25_Answer1,1\n",
      "25,25_Answer3,1\n",
      "25,25_Answer2,1\n",
      "25,25_Answer4,1\n",
      "25,25_Answer5,1\n",
      "25,25_Answer6,1\n",
      "27,27_Answer1,1\n",
      "27,27_Answer3,1\n",
      "27,27_Answer5,1\n",
      "27,27_Answer2,1\n",
      "27,27_Answer4,1\n",
      "28,28_Answer2,1\n",
      "28,28_Answer1,1\n",
      "28,28_Answer5,1\n",
      "28,28_Answer3,1\n",
      "28,28_Answer4,1\n",
      "29,29_Answer1,1\n",
      "29,29_Answer7,1\n",
      "29,29_Answer2,1\n",
      "29,29_Answer5,1\n",
      "29,29_Answer6,1\n",
      "29,29_Answer3,1\n",
      "29,29_Answer4,1\n",
      "30,30_Answer2,1\n",
      "30,30_Answer8,1\n",
      "30,30_Answer1,1\n",
      "30,30_Answer9,1\n",
      "30,30_Answer6,1\n",
      "30,30_Answer3,1\n",
      "30,30_Answer4,1\n",
      "30,30_Answer5,1\n",
      "30,30_Answer7,1\n",
      "31,31_Answer1,1\n",
      "31,31_Answer2,1\n",
      "31,31_Answer4,1\n",
      "31,31_Answer3,1\n",
      "31,31_Answer6,1\n",
      "32,32_Answer2,1\n",
      "32,32_Answer6,1\n",
      "32,32_Answer1,1\n",
      "32,32_Answer5,1\n",
      "32,32_Answer4,1\n",
      "32,32_Answer7,1\n",
      "32,32_Answer8,1\n",
      "32,32_Answer3,1\n",
      "33,33_Answer2,1\n",
      "33,33_Answer10,1\n",
      "33,33_Answer5,1\n",
      "33,33_Answer6,1\n",
      "33,33_Answer1,1\n",
      "33,33_Answer7,1\n",
      "33,33_Answer8,1\n",
      "33,33_Answer9,1\n",
      "33,33_Answer3,1\n",
      "36,36_Answer3,1\n",
      "36,36_Answer2,1\n",
      "36,36_Answer1,1\n",
      "36,36_Answer10,1\n",
      "36,36_Answer4,1\n",
      "36,36_Answer11,1\n",
      "36,36_Answer7,1\n",
      "36,36_Answer9,1\n",
      "36,36_Answer5,1\n",
      "36,36_Answer6,1\n",
      "38,38_Answer7,1\n",
      "38,38_Answer10,1\n",
      "38,38_Answer8,1\n",
      "38,38_Answer1,1\n",
      "38,38_Answer6,1\n",
      "38,38_Answer2,1\n",
      "38,38_Answer9,1\n",
      "38,38_Answer4,1\n",
      "38,38_Answer3,1\n",
      "38,38_Answer5,1\n",
      "39,39_Answer1,1\n",
      "39,39_Answer3,1\n",
      "39,39_Answer2,1\n",
      "39,39_Answer4,1\n",
      "39,39_Answer5,1\n",
      "39,39_Answer6,1\n",
      "40,40_Answer1,1\n",
      "40,40_Answer2,1\n",
      "40,40_Answer6,1\n",
      "40,40_Answer9,1\n",
      "40,40_Answer7,1\n",
      "40,40_Answer3,1\n",
      "40,40_Answer8,1\n",
      "40,40_Answer4,1\n",
      "40,40_Answer5,1\n",
      "41,41_Answer3,1\n",
      "41,41_Answer9,1\n",
      "41,41_Answer1,1\n",
      "41,41_Answer10,1\n",
      "41,41_Answer2,1\n",
      "41,41_Answer5,1\n",
      "41,41_Answer6,1\n",
      "41,41_Answer7,1\n",
      "41,41_Answer4,1\n",
      "41,41_Answer8,1\n",
      "42,42_Answer3,1\n",
      "42,42_Answer5,1\n",
      "42,42_Answer1,1\n",
      "42,42_Answer2,1\n",
      "42,42_Answer4,1\n",
      "43,43_Answer2,1\n",
      "43,43_Answer5,1\n",
      "43,43_Answer11,1\n",
      "43,43_Answer4,1\n",
      "43,43_Answer3,1\n",
      "43,43_Answer6,1\n",
      "43,43_Answer1,1\n",
      "43,43_Answer7,1\n",
      "43,43_Answer10,1\n",
      "43,43_Answer8,1\n",
      "43,43_Answer9,1\n",
      "45,45_Answer2,1\n",
      "45,45_Answer1,1\n",
      "45,45_Answer3,1\n",
      "45,45_Answer4,1\n",
      "45,45_Answer5,1\n",
      "45,45_Answer6,1\n",
      "45,45_Answer7,1\n",
      "46,46_Answer1,1\n",
      "46,46_Answer8,1\n",
      "46,46_Answer4,1\n",
      "46,46_Answer9,1\n",
      "46,46_Answer5,1\n",
      "46,46_Answer6,1\n",
      "46,46_Answer2,1\n",
      "46,46_Answer3,1\n",
      "46,46_Answer10,1\n",
      "46,46_Answer7,1\n",
      "47,47_Answer3,1\n",
      "47,47_Answer5,1\n",
      "47,47_Answer2,1\n",
      "47,47_Answer1,1\n",
      "47,47_Answer4,1\n",
      "47,47_Answer6,1\n",
      "47,47_Answer8,1\n",
      "47,47_Answer7,1\n",
      "49,49_Answer1,1\n",
      "49,49_Answer5,1\n",
      "49,49_Answer2,1\n",
      "49,49_Answer3,1\n",
      "49,49_Answer4,1\n",
      "49,49_Answer6,1\n",
      "54,54_Answer2,1\n",
      "54,54_Answer8,1\n",
      "54,54_Answer5,1\n",
      "54,54_Answer6,1\n",
      "54,54_Answer3,1\n",
      "54,54_Answer4,1\n",
      "54,54_Answer7,1\n",
      "54,54_Answer1,1\n",
      "54,54_Answer9,1\n",
      "54,54_Answer10,1\n",
      "55,55_Answer6,1\n",
      "55,55_Answer3,1\n",
      "55,55_Answer1,1\n",
      "55,55_Answer2,1\n",
      "55,55_Answer4,1\n",
      "56,56_Answer1,1\n",
      "56,56_Answer3,1\n",
      "56,56_Answer5,1\n",
      "56,56_Answer4,1\n",
      "57,57_Answer2,1\n",
      "57,57_Answer3,1\n",
      "57,57_Answer1,1\n",
      "58,58_Answer2,1\n",
      "58,58_Answer1,1\n",
      "58,58_Answer5,1\n",
      "58,58_Answer4,1\n",
      "58,58_Answer6,1\n",
      "58,58_Answer7,1\n",
      "58,58_Answer3,1\n",
      "59,59_Answer2,1\n",
      "59,59_Answer5,1\n",
      "59,59_Answer1,1\n",
      "59,59_Answer6,1\n",
      "59,59_Answer4,1\n",
      "59,59_Answer7,1\n",
      "59,59_Answer3,1\n",
      "60,60_Answer1,1\n",
      "60,60_Answer8,1\n",
      "60,60_Answer3,1\n",
      "60,60_Answer5,1\n",
      "60,60_Answer6,1\n",
      "60,60_Answer4,1\n",
      "60,60_Answer2,1\n",
      "61,61_Answer1,1\n",
      "61,61_Answer5,1\n",
      "61,61_Answer4,1\n",
      "61,61_Answer3,1\n",
      "61,61_Answer2,1\n",
      "62,62_Answer2,1\n",
      "62,62_Answer1,1\n",
      "62,62_Answer3,1\n",
      "62,62_Answer4,1\n",
      "62,62_Answer5,1\n",
      "62,62_Answer6,1\n",
      "62,62_Answer7,1\n",
      "64,64_Answer1,1\n",
      "64,64_Answer2,1\n",
      "64,64_Answer4,1\n",
      "64,64_Answer3,1\n",
      "66,66_Answer1,1\n",
      "66,66_Answer2,1\n",
      "66,66_Answer4,1\n",
      "66,66_Answer5,1\n",
      "66,66_Answer6,1\n",
      "66,66_Answer7,1\n",
      "66,66_Answer8,1\n",
      "66,66_Answer3,1\n",
      "66,66_Answer9,1\n",
      "67,67_Answer1,1\n",
      "67,67_Answer5,1\n",
      "67,67_Answer6,1\n",
      "67,67_Answer2,1\n",
      "67,67_Answer3,1\n",
      "67,67_Answer7,1\n",
      "67,67_Answer4,1\n",
      "68,68_Answer3,1\n",
      "68,68_Answer7,1\n",
      "68,68_Answer1,1\n",
      "68,68_Answer6,1\n",
      "68,68_Answer8,1\n",
      "68,68_Answer5,1\n",
      "68,68_Answer2,1\n",
      "68,68_Answer4,1\n",
      "70,70_Answer1,1\n",
      "70,70_Answer2,1\n",
      "70,70_Answer5,1\n",
      "70,70_Answer6,1\n",
      "70,70_Answer7,1\n",
      "70,70_Answer4,1\n",
      "71,71_Answer1,1\n",
      "71,71_Answer2,1\n",
      "71,71_Answer5,1\n",
      "71,71_Answer4,1\n",
      "71,71_Answer3,1\n",
      "72,72_Answer1,1\n",
      "72,72_Answer3,1\n",
      "72,72_Answer2,1\n",
      "72,72_Answer6,1\n",
      "72,72_Answer4,1\n",
      "72,72_Answer8,1\n",
      "72,72_Answer5,1\n",
      "72,72_Answer7,1\n",
      "72,72_Answer9,1\n",
      "73,73_Answer1,1\n",
      "73,73_Answer4,1\n",
      "73,73_Answer2,1\n",
      "73,73_Answer3,1\n",
      "74,74_Answer11,1\n",
      "74,74_Answer10,1\n",
      "74,74_Answer2,1\n",
      "74,74_Answer9,1\n",
      "74,74_Answer5,1\n",
      "74,74_Answer1,1\n",
      "74,74_Answer8,1\n",
      "74,74_Answer3,1\n",
      "74,74_Answer6,1\n",
      "74,74_Answer4,1\n",
      "74,74_Answer7,1\n",
      "75,75_Answer2,1\n",
      "75,75_Answer1,1\n",
      "75,75_Answer4,1\n",
      "75,75_Answer3,1\n",
      "75,75_Answer7,1\n",
      "75,75_Answer6,1\n",
      "75,75_Answer5,1\n",
      "76,76_Answer2,1\n",
      "76,76_Answer4,1\n",
      "76,76_Answer3,1\n",
      "76,76_Answer5,1\n",
      "76,76_Answer1,1\n",
      "76,76_Answer6,1\n",
      "76,76_Answer10,1\n",
      "76,76_Answer8,1\n",
      "76,76_Answer9,1\n",
      "76,76_Answer7,1\n",
      "76,76_Answer11,1\n",
      "78,78_Answer8,1\n",
      "78,78_Answer9,1\n",
      "78,78_Answer4,1\n",
      "78,78_Answer7,1\n",
      "78,78_Answer3,1\n",
      "78,78_Answer5,1\n",
      "78,78_Answer6,1\n",
      "78,78_Answer2,1\n",
      "78,78_Answer1,1\n",
      "79,79_Answer4,1\n",
      "79,79_Answer3,1\n",
      "79,79_Answer2,1\n",
      "79,79_Answer6,1\n",
      "79,79_Answer1,1\n",
      "79,79_Answer5,1\n",
      "79,79_Answer7,1\n",
      "81,81_Answer1,1\n",
      "81,81_Answer3,1\n",
      "81,81_Answer2,1\n",
      "81,81_Answer4,1\n",
      "81,81_Answer5,1\n",
      "81,81_Answer7,1\n",
      "81,81_Answer6,1\n",
      "82,82_Answer1,1\n",
      "82,82_Answer4,1\n",
      "82,82_Answer3,1\n",
      "82,82_Answer2,1\n",
      "84,84_Answer1,1\n",
      "84,84_Answer3,1\n",
      "84,84_Answer2,1\n",
      "84,84_Answer4,1\n",
      "84,84_Answer9,1\n",
      "84,84_Answer5,1\n",
      "84,84_Answer6,1\n",
      "84,84_Answer8,1\n",
      "85,85_Answer1,1\n",
      "85,85_Answer2,1\n",
      "85,85_Answer3,1\n",
      "85,85_Answer6,1\n",
      "85,85_Answer4,1\n",
      "85,85_Answer7,1\n",
      "85,85_Answer8,1\n",
      "85,85_Answer5,1\n",
      "86,86_Answer9,1\n",
      "86,86_Answer1,1\n",
      "86,86_Answer4,1\n",
      "86,86_Answer3,1\n",
      "86,86_Answer7,1\n",
      "86,86_Answer6,1\n",
      "86,86_Answer2,1\n",
      "86,86_Answer5,1\n",
      "86,86_Answer8,1\n",
      "90,90_Answer1,1\n",
      "90,90_Answer2,1\n",
      "91,91_Answer2,1\n",
      "91,91_Answer1,1\n",
      "92,92_Answer2,1\n",
      "92,92_Answer1,1\n",
      "92,92_Answer3,1\n",
      "92,92_Answer6,1\n",
      "92,92_Answer4,1\n",
      "92,92_Answer8,1\n",
      "92,92_Answer7,1\n",
      "92,92_Answer5,1\n",
      "92,92_Answer9,1\n",
      "93,93_Answer1,1\n",
      "93,93_Answer4,1\n",
      "93,93_Answer3,1\n",
      "93,93_Answer8,1\n",
      "93,93_Answer5,1\n",
      "93,93_Answer7,1\n",
      "93,93_Answer6,1\n",
      "93,93_Answer9,1\n",
      "93,93_Answer10,1\n",
      "93,93_Answer11,1\n",
      "95,95_Answer5,1\n",
      "95,95_Answer4,1\n",
      "95,95_Answer3,1\n",
      "95,95_Answer9,1\n",
      "95,95_Answer2,1\n",
      "95,95_Answer8,1\n",
      "95,95_Answer7,1\n",
      "95,95_Answer6,1\n",
      "95,95_Answer1,1\n",
      "97,97_Answer1,1\n",
      "97,97_Answer8,1\n",
      "97,97_Answer3,1\n",
      "97,97_Answer7,1\n",
      "97,97_Answer4,1\n",
      "97,97_Answer5,1\n",
      "97,97_Answer2,1\n",
      "97,97_Answer6,1\n",
      "98,98_Answer1,1\n",
      "98,98_Answer4,1\n",
      "98,98_Answer2,1\n",
      "98,98_Answer3,1\n",
      "99,99_Answer1,1\n",
      "99,99_Answer2,1\n",
      "99,99_Answer3,1\n",
      "99,99_Answer6,1\n",
      "99,99_Answer5,1\n",
      "101,101_Answer5,1\n",
      "101,101_Answer6,1\n",
      "101,101_Answer2,1\n",
      "101,101_Answer1,1\n",
      "101,101_Answer3,1\n",
      "101,101_Answer4,1\n",
      "101,101_Answer7,1\n",
      "101,101_Answer8,1\n",
      "103,103_Answer1,1\n",
      "103,103_Answer2,1\n",
      "103,103_Answer6,1\n",
      "103,103_Answer3,1\n",
      "103,103_Answer4,1\n",
      "103,103_Answer5,1\n",
      "105,105_Answer1,1\n",
      "105,105_Answer6,1\n",
      "105,105_Answer7,1\n",
      "105,105_Answer2,1\n",
      "105,105_Answer4,1\n",
      "105,105_Answer3,1\n",
      "105,105_Answer5,1\n",
      "105,105_Answer8,1\n",
      "106,106_Answer2,1\n",
      "106,106_Answer1,1\n",
      "106,106_Answer7,1\n",
      "106,106_Answer4,1\n",
      "106,106_Answer8,1\n",
      "106,106_Answer6,1\n",
      "106,106_Answer3,1\n",
      "106,106_Answer5,1\n",
      "107,107_Answer8,1\n",
      "107,107_Answer4,1\n",
      "107,107_Answer6,1\n",
      "107,107_Answer1,1\n",
      "107,107_Answer2,1\n",
      "107,107_Answer3,1\n",
      "107,107_Answer7,1\n",
      "108,108_Answer4,1\n",
      "108,108_Answer5,1\n",
      "108,108_Answer2,1\n",
      "108,108_Answer1,1\n",
      "108,108_Answer6,1\n",
      "108,108_Answer3,1\n",
      "108,108_Answer8,1\n",
      "108,108_Answer7,1\n",
      "108,108_Answer9,1\n",
      "109,109_Answer2,1\n",
      "109,109_Answer1,1\n",
      "109,109_Answer6,1\n",
      "109,109_Answer7,1\n",
      "109,109_Answer8,1\n",
      "109,109_Answer9,1\n",
      "109,109_Answer4,1\n",
      "109,109_Answer3,1\n",
      "109,109_Answer5,1\n",
      "110,110_Answer5,1\n",
      "110,110_Answer4,1\n",
      "110,110_Answer2,1\n",
      "110,110_Answer1,1\n",
      "110,110_Answer3,1\n",
      "110,110_Answer6,1\n",
      "111,111_Answer5,1\n",
      "111,111_Answer1,1\n",
      "111,111_Answer3,1\n",
      "111,111_Answer4,1\n",
      "111,111_Answer7,1\n",
      "111,111_Answer6,1\n",
      "111,111_Answer2,1\n",
      "112,112_Answer1,1\n",
      "112,112_Answer8,1\n",
      "112,112_Answer2,1\n",
      "112,112_Answer4,1\n",
      "112,112_Answer3,1\n",
      "112,112_Answer5,1\n",
      "112,112_Answer6,1\n",
      "112,112_Answer7,1\n",
      "112,112_Answer9,1\n",
      "113,113_Answer3,1\n",
      "113,113_Answer7,1\n",
      "113,113_Answer4,1\n",
      "113,113_Answer6,1\n",
      "113,113_Answer2,1\n",
      "113,113_Answer8,1\n",
      "113,113_Answer9,1\n",
      "113,113_Answer1,1\n",
      "113,113_Answer5,1\n",
      "115,115_Answer1,1\n",
      "115,115_Answer4,1\n",
      "115,115_Answer3,1\n",
      "115,115_Answer9,1\n",
      "115,115_Answer7,1\n",
      "115,115_Answer10,1\n",
      "115,115_Answer2,1\n",
      "115,115_Answer6,1\n",
      "115,115_Answer8,1\n",
      "116,116_Answer2,1\n",
      "116,116_Answer4,1\n",
      "116,116_Answer8,1\n",
      "116,116_Answer7,1\n",
      "116,116_Answer6,1\n",
      "116,116_Answer3,1\n",
      "116,116_Answer5,1\n",
      "116,116_Answer1,1\n",
      "117,117_Answer1,1\n",
      "117,117_Answer2,1\n",
      "117,117_Answer3,1\n",
      "117,117_Answer5,1\n",
      "117,117_Answer6,1\n",
      "117,117_Answer4,1\n",
      "118,118_Answer2,1\n",
      "118,118_Answer1,1\n",
      "118,118_Answer5,1\n",
      "118,118_Answer4,1\n",
      "118,118_Answer6,1\n",
      "118,118_Answer3,1\n",
      "118,118_Answer7,1\n",
      "119,119_Answer1,1\n",
      "119,119_Answer8,1\n",
      "119,119_Answer9,1\n",
      "119,119_Answer7,1\n",
      "119,119_Answer2,1\n",
      "119,119_Answer3,1\n",
      "119,119_Answer4,1\n",
      "119,119_Answer5,1\n",
      "119,119_Answer6,1\n",
      "121,121_Answer1,1\n",
      "121,121_Answer9,1\n",
      "121,121_Answer3,1\n",
      "121,121_Answer10,1\n",
      "121,121_Answer2,1\n",
      "121,121_Answer11,1\n",
      "121,121_Answer4,1\n",
      "121,121_Answer5,1\n",
      "121,121_Answer8,1\n",
      "121,121_Answer6,1\n",
      "122,122_Answer1,1\n",
      "122,122_Answer4,1\n",
      "122,122_Answer3,1\n",
      "122,122_Answer7,1\n",
      "122,122_Answer6,1\n",
      "122,122_Answer5,1\n",
      "122,122_Answer2,1\n",
      "123,123_Answer5,1\n",
      "123,123_Answer6,1\n",
      "123,123_Answer7,1\n",
      "123,123_Answer2,1\n",
      "123,123_Answer1,1\n",
      "123,123_Answer4,1\n",
      "123,123_Answer3,1\n",
      "123,123_Answer8,1\n",
      "123,123_Answer9,1\n",
      "124,124_Answer3,1\n",
      "124,124_Answer5,1\n",
      "124,124_Answer2,1\n",
      "124,124_Answer4,1\n",
      "124,124_Answer1,1\n",
      "127,127_Answer7,1\n",
      "127,127_Answer4,1\n",
      "127,127_Answer8,1\n",
      "127,127_Answer3,1\n",
      "127,127_Answer2,1\n",
      "127,127_Answer5,1\n",
      "127,127_Answer1,1\n",
      "127,127_Answer9,1\n",
      "127,127_Answer6,1\n",
      "129,129_Answer1,1\n",
      "129,129_Answer9,1\n",
      "129,129_Answer3,1\n",
      "129,129_Answer10,1\n",
      "129,129_Answer2,1\n",
      "129,129_Answer11,1\n",
      "129,129_Answer4,1\n",
      "129,129_Answer5,1\n",
      "129,129_Answer6,1\n",
      "129,129_Answer8,1\n",
      "130,130_Answer4,1\n",
      "130,130_Answer6,1\n",
      "130,130_Answer7,1\n",
      "130,130_Answer2,1\n",
      "130,130_Answer3,1\n",
      "130,130_Answer1,1\n",
      "130,130_Answer8,1\n",
      "130,130_Answer9,1\n",
      "130,130_Answer5,1\n",
      "130,130_Answer10,1\n",
      "131,131_Answer2,1\n",
      "131,131_Answer4,1\n",
      "131,131_Answer5,1\n",
      "131,131_Answer7,1\n",
      "131,131_Answer1,1\n",
      "131,131_Answer8,1\n",
      "131,131_Answer3,1\n",
      "131,131_Answer6,1\n",
      "131,131_Answer9,1\n",
      "132,132_Answer2,1\n",
      "132,132_Answer1,1\n",
      "132,132_Answer9,1\n",
      "132,132_Answer7,1\n",
      "132,132_Answer4,1\n",
      "132,132_Answer8,1\n",
      "132,132_Answer3,1\n",
      "132,132_Answer5,1\n",
      "132,132_Answer6,1\n",
      "133,133_Answer4,1\n",
      "133,133_Answer1,1\n",
      "133,133_Answer2,1\n",
      "133,133_Answer6,1\n",
      "133,133_Answer5,1\n",
      "133,133_Answer7,1\n",
      "133,133_Answer10,1\n",
      "133,133_Answer8,1\n",
      "133,133_Answer3,1\n",
      "133,133_Answer9,1\n",
      "134,134_Answer1,1\n",
      "134,134_Answer3,1\n",
      "134,134_Answer7,1\n",
      "134,134_Answer6,1\n",
      "134,134_Answer4,1\n",
      "134,134_Answer2,1\n",
      "134,134_Answer5,1\n",
      "135,135_Answer2,1\n",
      "135,135_Answer9,1\n",
      "135,135_Answer6,1\n",
      "135,135_Answer8,1\n",
      "135,135_Answer5,1\n",
      "135,135_Answer7,1\n",
      "135,135_Answer3,1\n",
      "135,135_Answer4,1\n",
      "135,135_Answer1,1\n",
      "137,137_Answer7,1\n",
      "137,137_Answer6,1\n",
      "137,137_Answer2,1\n",
      "137,137_Answer3,1\n",
      "137,137_Answer1,1\n",
      "137,137_Answer5,1\n",
      "137,137_Answer4,1\n",
      "138,138_Answer2,1\n",
      "138,138_Answer3,1\n",
      "138,138_Answer1,1\n",
      "138,138_Answer6,1\n",
      "138,138_Answer5,1\n",
      "138,138_Answer4,1\n",
      "138,138_Answer7,1\n",
      "139,139_Answer1,1\n",
      "139,139_Answer4,1\n",
      "139,139_Answer2,1\n",
      "139,139_Answer3,1\n",
      "140,140_Answer1,1\n",
      "140,140_Answer6,1\n",
      "140,140_Answer5,1\n",
      "140,140_Answer9,1\n",
      "140,140_Answer10,1\n",
      "140,140_Answer2,1\n",
      "140,140_Answer4,1\n",
      "140,140_Answer3,1\n",
      "140,140_Answer8,1\n",
      "140,140_Answer7,1\n",
      "142,142_Answer3,1\n",
      "142,142_Answer4,1\n",
      "142,142_Answer2,1\n",
      "142,142_Answer1,1\n",
      "143,143_Answer1,1\n",
      "143,143_Answer2,1\n",
      "143,143_Answer4,1\n",
      "143,143_Answer3,1\n",
      "143,143_Answer7,1\n",
      "143,143_Answer6,1\n",
      "143,143_Answer9,1\n",
      "143,143_Answer8,1\n",
      "143,143_Answer5,1\n",
      "144,144_Answer3,1\n",
      "144,144_Answer2,1\n",
      "144,144_Answer5,1\n",
      "144,144_Answer6,1\n",
      "144,144_Answer1,1\n",
      "144,144_Answer4,1\n",
      "144,144_Answer7,1\n",
      "144,144_Answer8,1\n",
      "144,144_Answer9,1\n",
      "144,144_Answer10,1\n",
      "145,145_Answer2,1\n",
      "145,145_Answer3,1\n",
      "145,145_Answer4,1\n",
      "145,145_Answer9,1\n",
      "145,145_Answer10,1\n",
      "145,145_Answer11,1\n",
      "145,145_Answer1,1\n",
      "145,145_Answer8,1\n",
      "145,145_Answer5,1\n",
      "145,145_Answer6,1\n",
      "145,145_Answer7,1\n",
      "147,147_Answer1,1\n",
      "147,147_Answer3,1\n",
      "147,147_Answer4,1\n",
      "147,147_Answer2,1\n",
      "147,147_Answer5,1\n",
      "148,148_Answer1,1\n",
      "148,148_Answer4,1\n",
      "148,148_Answer2,1\n",
      "148,148_Answer7,1\n",
      "148,148_Answer5,1\n",
      "148,148_Answer8,1\n",
      "148,148_Answer9,1\n",
      "148,148_Answer3,1\n",
      "148,148_Answer6,1\n",
      "150,150_Answer2,1\n",
      "150,150_Answer1,1\n",
      "150,150_Answer6,1\n",
      "150,150_Answer3,1\n",
      "150,150_Answer5,1\n",
      "150,150_Answer4,1\n",
      "150,150_Answer7,1\n",
      "152,152_Answer1,1\n",
      "152,152_Answer5,1\n",
      "152,152_Answer3,1\n",
      "152,152_Answer4,1\n",
      "152,152_Answer2,1\n",
      "152,152_Answer6,1\n",
      "152,152_Answer7,1\n",
      "153,153_Answer3,1\n",
      "153,153_Answer4,1\n",
      "153,153_Answer2,1\n",
      "153,153_Answer6,1\n",
      "153,153_Answer1,1\n",
      "153,153_Answer8,1\n",
      "153,153_Answer10,1\n",
      "153,153_Answer5,1\n",
      "153,153_Answer7,1\n",
      "153,153_Answer9,1\n",
      "154,154_Answer2,1\n",
      "154,154_Answer8,1\n",
      "154,154_Answer1,1\n",
      "154,154_Answer5,1\n",
      "154,154_Answer6,1\n",
      "154,154_Answer9,1\n",
      "154,154_Answer4,1\n",
      "154,154_Answer10,1\n",
      "154,154_Answer3,1\n",
      "154,154_Answer11,1\n",
      "154,154_Answer7,1\n",
      "155,155_Answer3,1\n",
      "155,155_Answer1,1\n",
      "155,155_Answer2,1\n",
      "155,155_Answer7,1\n",
      "155,155_Answer4,1\n",
      "155,155_Answer5,1\n",
      "155,155_Answer9,1\n",
      "155,155_Answer10,1\n",
      "155,155_Answer6,1\n",
      "155,155_Answer8,1\n",
      "156,156_Answer1,1\n",
      "156,156_Answer3,1\n",
      "156,156_Answer2,1\n",
      "156,156_Answer4,1\n",
      "156,156_Answer5,1\n",
      "157,157_Answer3,1\n",
      "157,157_Answer2,1\n",
      "157,157_Answer5,1\n",
      "157,157_Answer6,1\n",
      "157,157_Answer4,1\n",
      "157,157_Answer1,1\n",
      "158,158_Answer6,1\n",
      "158,158_Answer3,1\n",
      "158,158_Answer1,1\n",
      "158,158_Answer5,1\n",
      "158,158_Answer10,1\n",
      "158,158_Answer7,1\n",
      "158,158_Answer8,1\n",
      "158,158_Answer2,1\n",
      "158,158_Answer9,1\n",
      "158,158_Answer4,1\n",
      "159,159_Answer3,1\n",
      "159,159_Answer8,1\n",
      "159,159_Answer9,1\n",
      "159,159_Answer1,1\n",
      "159,159_Answer5,1\n",
      "159,159_Answer7,1\n",
      "159,159_Answer6,1\n",
      "159,159_Answer2,1\n",
      "159,159_Answer4,1\n",
      "160,160_Answer2,1\n",
      "160,160_Answer4,1\n",
      "160,160_Answer1,1\n",
      "160,160_Answer6,1\n",
      "160,160_Answer7,1\n",
      "160,160_Answer5,1\n",
      "160,160_Answer3,1\n",
      "161,161_Answer1,1\n",
      "161,161_Answer4,1\n",
      "161,161_Answer5,1\n",
      "161,161_Answer2,1\n",
      "161,161_Answer6,1\n",
      "161,161_Answer3,1\n",
      "161,161_Answer7,1\n",
      "162,162_Answer2,1\n",
      "162,162_Answer1,1\n",
      "162,162_Answer7,1\n",
      "162,162_Answer3,1\n",
      "162,162_Answer4,1\n",
      "162,162_Answer5,1\n",
      "162,162_Answer6,1\n",
      "163,163_Answer2,1\n",
      "163,163_Answer7,1\n",
      "163,163_Answer3,1\n",
      "163,163_Answer5,1\n",
      "163,163_Answer6,1\n",
      "163,163_Answer4,1\n",
      "165,165_Answer4,1\n",
      "165,165_Answer3,1\n",
      "165,165_Answer5,1\n",
      "165,165_Answer6,1\n",
      "165,165_Answer2,1\n",
      "165,165_Answer1,1\n",
      "165,165_Answer8,1\n",
      "165,165_Answer10,1\n",
      "165,165_Answer7,1\n",
      "165,165_Answer9,1\n",
      "166,166_Answer2,1\n",
      "166,166_Answer8,1\n",
      "166,166_Answer9,1\n",
      "166,166_Answer7,1\n",
      "166,166_Answer4,1\n",
      "166,166_Answer6,1\n",
      "166,166_Answer5,1\n",
      "166,166_Answer1,1\n",
      "166,166_Answer3,1\n",
      "167,167_Answer1,1\n",
      "167,167_Answer2,1\n",
      "167,167_Answer3,1\n",
      "167,167_Answer4,1\n",
      "167,167_Answer5,1\n",
      "168,168_Answer7,1\n",
      "168,168_Answer6,1\n",
      "168,168_Answer3,1\n",
      "168,168_Answer1,1\n",
      "168,168_Answer2,1\n",
      "168,168_Answer5,1\n",
      "168,168_Answer4,1\n",
      "169,169_Answer3,1\n",
      "169,169_Answer4,1\n",
      "169,169_Answer2,1\n",
      "169,169_Answer5,1\n",
      "169,169_Answer1,1\n",
      "169,169_Answer8,1\n",
      "169,169_Answer10,1\n",
      "169,169_Answer6,1\n",
      "169,169_Answer7,1\n",
      "169,169_Answer9,1\n",
      "170,170_Answer1,1\n",
      "170,170_Answer2,1\n",
      "170,170_Answer5,1\n",
      "170,170_Answer4,1\n",
      "170,170_Answer6,1\n",
      "170,170_Answer7,1\n",
      "170,170_Answer8,1\n",
      "170,170_Answer3,1\n",
      "170,170_Answer9,1\n",
      "171,171_Answer3,1\n",
      "171,171_Answer6,1\n",
      "171,171_Answer4,1\n",
      "171,171_Answer5,1\n",
      "171,171_Answer7,1\n",
      "171,171_Answer2,1\n",
      "171,171_Answer1,1\n",
      "171,171_Answer8,1\n",
      "171,171_Answer9,1\n",
      "171,171_Answer10,1\n",
      "174,174_Answer5,1\n",
      "174,174_Answer1,1\n",
      "174,174_Answer3,1\n",
      "174,174_Answer2,1\n",
      "174,174_Answer7,1\n",
      "174,174_Answer8,1\n",
      "174,174_Answer9,1\n",
      "174,174_Answer6,1\n",
      "176,176_Answer1,1\n",
      "176,176_Answer4,1\n",
      "176,176_Answer2,1\n",
      "176,176_Answer3,1\n",
      "176,176_Answer5,1\n",
      "177,177_Answer1,1\n",
      "177,177_Answer4,1\n",
      "177,177_Answer2,1\n",
      "177,177_Answer5,1\n",
      "177,177_Answer9,1\n",
      "177,177_Answer6,1\n",
      "177,177_Answer3,1\n",
      "177,177_Answer7,1\n",
      "177,177_Answer8,1\n",
      "177,177_Answer11,1\n",
      "177,177_Answer10,1\n",
      "179,179_Answer1,1\n",
      "179,179_Answer2,1\n",
      "179,179_Answer10,1\n",
      "179,179_Answer4,1\n",
      "179,179_Answer3,1\n",
      "179,179_Answer5,1\n",
      "179,179_Answer6,1\n",
      "179,179_Answer7,1\n",
      "179,179_Answer8,1\n",
      "179,179_Answer9,1\n",
      "180,180_Answer1,1\n",
      "180,180_Answer3,1\n",
      "180,180_Answer4,1\n",
      "180,180_Answer2,1\n",
      "181,181_Answer4,1\n",
      "181,181_Answer1,1\n",
      "181,181_Answer2,1\n",
      "181,181_Answer7,1\n",
      "181,181_Answer3,1\n",
      "181,181_Answer8,1\n",
      "181,181_Answer5,1\n",
      "181,181_Answer6,1\n",
      "181,181_Answer9,1\n",
      "182,182_Answer8,1\n",
      "182,182_Answer1,1\n",
      "182,182_Answer5,1\n",
      "182,182_Answer3,1\n",
      "182,182_Answer2,1\n",
      "182,182_Answer4,1\n",
      "182,182_Answer6,1\n",
      "183,183_Answer2,1\n",
      "183,183_Answer1,1\n",
      "183,183_Answer3,1\n",
      "183,183_Answer4,1\n",
      "183,183_Answer5,1\n",
      "183,183_Answer7,1\n",
      "183,183_Answer6,1\n",
      "184,184_Answer1,1\n",
      "184,184_Answer3,1\n",
      "184,184_Answer2,1\n",
      "185,185_Answer2,1\n",
      "185,185_Answer3,1\n",
      "185,185_Answer9,1\n",
      "185,185_Answer4,1\n",
      "185,185_Answer5,1\n",
      "185,185_Answer6,1\n",
      "185,185_Answer1,1\n",
      "185,185_Answer7,1\n",
      "185,185_Answer8,1\n",
      "186,186_Answer1,1\n",
      "186,186_Answer4,1\n",
      "186,186_Answer2,1\n",
      "186,186_Answer5,1\n",
      "186,186_Answer7,1\n",
      "186,186_Answer3,1\n",
      "186,186_Answer9,1\n",
      "186,186_Answer8,1\n",
      "186,186_Answer6,1\n",
      "187,187_Answer4,1\n",
      "187,187_Answer3,1\n",
      "187,187_Answer7,1\n",
      "187,187_Answer9,1\n",
      "187,187_Answer1,1\n",
      "187,187_Answer5,1\n",
      "187,187_Answer8,1\n",
      "187,187_Answer2,1\n",
      "187,187_Answer6,1\n",
      "188,188_Answer2,1\n",
      "188,188_Answer1,1\n",
      "188,188_Answer5,1\n",
      "188,188_Answer3,1\n",
      "188,188_Answer6,1\n",
      "188,188_Answer7,1\n",
      "188,188_Answer4,1\n",
      "188,188_Answer8,1\n",
      "189,189_Answer1,1\n",
      "189,189_Answer4,1\n",
      "189,189_Answer5,1\n",
      "189,189_Answer6,1\n",
      "189,189_Answer7,1\n",
      "189,189_Answer8,1\n",
      "189,189_Answer2,1\n",
      "189,189_Answer3,1\n",
      "189,189_Answer9,1\n",
      "190,190_Answer1,1\n",
      "190,190_Answer4,1\n",
      "190,190_Answer5,1\n",
      "190,190_Answer2,1\n",
      "190,190_Answer6,1\n",
      "190,190_Answer7,1\n",
      "190,190_Answer3,1\n",
      "191,191_Answer3,1\n",
      "191,191_Answer9,1\n",
      "191,191_Answer2,1\n",
      "191,191_Answer4,1\n",
      "191,191_Answer5,1\n",
      "191,191_Answer6,1\n",
      "191,191_Answer7,1\n",
      "191,191_Answer8,1\n",
      "191,191_Answer1,1\n",
      "193,193_Answer2,1\n",
      "193,193_Answer3,1\n",
      "193,193_Answer8,1\n",
      "193,193_Answer7,1\n",
      "193,193_Answer1,1\n",
      "193,193_Answer5,1\n",
      "193,193_Answer6,1\n",
      "193,193_Answer4,1\n",
      "195,195_Answer4,1\n",
      "195,195_Answer3,1\n",
      "195,195_Answer1,1\n",
      "195,195_Answer2,1\n",
      "195,195_Answer9,1\n",
      "195,195_Answer6,1\n",
      "195,195_Answer5,1\n",
      "195,195_Answer7,1\n",
      "195,195_Answer8,1\n",
      "195,195_Answer10,1\n"
     ]
    }
   ],
   "source": [
    "QA.output_predictions(reference_ranks, system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdPcaI-8Awa0"
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for q in QA:\n",
    "    for a in q.answers:\n",
    "        lengths.append(len(a))\n",
    "        print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcRtWLKNS8ze"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXEHExavZtdE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7daxnXJZtZi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rIfyXiblZtU-",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "bea87d86-7e0f-4a7f-cdeb-ac9cc3e5e53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/task3/sample_submission_round_2.csv does not exist: 'data/task3/sample_submission_round_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-59da14ca2456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0maicrowd_evaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMediqaEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maicrowd_evaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_client_payload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-59da14ca2456>\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, client_payload, _context)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_task_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_payload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_task_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_payload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-59da14ca2456>\u001b[0m in \u001b[0;36m_evaluate_task_3\u001b[1;34m(self, client_payload, _context)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mcol_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'question_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'answer_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mgold_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manswer_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File data/task3/sample_submission_round_2.csv does not exist: 'data/task3/sample_submission_round_2.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "class MediqaEvaluator:\n",
    "    def __init__(self, answer_file_path, task=1, round=1):\n",
    "        \"\"\"\n",
    "        `round` : Holds the round for which the evaluation is being done.\n",
    "        can be 1, 2...upto the number of rounds the challenge has.\n",
    "        Different rounds will mostly have different ground truth files.\n",
    "        \"\"\"\n",
    "        self.answer_file_path = answer_file_path\n",
    "        self.round = round\n",
    "        self.task = task\n",
    "\n",
    "    def _evaluate(self, client_payload, _context={}):\n",
    "        if self.task == 1:\n",
    "            return self._evaluate_task_1(client_payload, _context)\n",
    "        elif self.task == 2:\n",
    "            return self._evaluate_task_2(client_payload, _context)\n",
    "        elif self.task == 3:\n",
    "            return self._evaluate_task_3(client_payload, _context)\n",
    "\n",
    "\n",
    "    def _evaluate_task_1(self, client_payload, _context={}):\n",
    "        \"\"\"\n",
    "        `client_payload` will be a dict with (atleast) the following keys :\n",
    "          - submission_file_path : local file path of the submitted file\n",
    "          - aicrowd_submission_id : A unique id representing the submission\n",
    "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
    "        \"\"\"\n",
    "        submission_file_path = client_payload[\"submission_file_path\"]\n",
    "\n",
    "        # Result file format: pair_id,label (csv file)\n",
    "\n",
    "        col_names = ['pair_id', 'label']\n",
    "\n",
    "        submission = pd.read_csv(submission_file_path, header=None, names=col_names)\n",
    "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names)\n",
    "\n",
    "        # Drop duplicates except for the first occurrence.\n",
    "        submission = submission.drop_duplicates(['pair_id'])\n",
    "\n",
    "        submission.label = submission.label.astype(str)\n",
    "        gold_truth.label = gold_truth.label.astype(str)\n",
    "\n",
    "        submission['entry'] = submission.apply(lambda x: '_'.join(x), axis=1)\n",
    "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
    "\n",
    "        accuracy = s1.size / gold_truth.size\n",
    "\n",
    "        _result_object = {\n",
    "            \"score\": accuracy,\n",
    "            \"score_secondary\" : 0.0\n",
    "        }\n",
    "        return _result_object\n",
    "\n",
    "    def _evaluate_task_2(self, client_payload, _context={}):\n",
    "        \"\"\"\n",
    "        `client_payload` will be a dict with (atleast) the following keys :\n",
    "          - submission_file_path : local file path of the submitted file\n",
    "          - aicrowd_submission_id : A unique id representing the submission\n",
    "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
    "        \"\"\"\n",
    "        submission_file_path = client_payload[\"submission_file_path\"]\n",
    "\n",
    "        # Result file format: pair_id,label (csv file)\n",
    "\n",
    "        col_names = ['pair_id', 'label']\n",
    "\n",
    "        submission = pd.read_csv(submission_file_path, header=None, names=col_names, dtype={'pair_id': str, \"label\": str})\n",
    "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names, dtype={'pair_id': str, \"label\": str})\n",
    "\n",
    "        # Drop duplicates except for the first occurrence.\n",
    "        submission = submission.drop_duplicates(['pair_id'])\n",
    "\n",
    "        submission.label = submission.label.astype(str)\n",
    "        gold_truth.label = gold_truth.label.astype(str)\n",
    "\n",
    "        submission['entry'] = submission.apply(lambda x: '_'.join(x), axis=1)\n",
    "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(x), axis=1)\n",
    "\n",
    "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
    "\n",
    "        accuracy = s1.size / gold_truth.size\n",
    "\n",
    "        _result_object = {\n",
    "            \"score\": accuracy,\n",
    "            \"score_secondary\" : 0.0\n",
    "        }\n",
    "\n",
    "        return _result_object\n",
    "\n",
    "    def _evaluate_task_3(self, client_payload, _context={}):\n",
    "        \"\"\"\n",
    "        `client_payload` will be a dict with (atleast) the following keys :\n",
    "          - submission_file_path : local file path of the submitted file\n",
    "          - aicrowd_submission_id : A unique id representing the submission\n",
    "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
    "        \"\"\"\n",
    "        submission_file_path = client_payload[\"submission_file_path\"]\n",
    "\n",
    "        # Result file format: q_id,a_id,label{0/1}\n",
    "\n",
    "        col_names = ['question_id','answer_id', 'label']\n",
    "\n",
    "        submission = pd.read_csv(submission_file_path, header=None, names=col_names)\n",
    "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names)\n",
    "\n",
    "        # Drop duplicates except for the first occurrence.\n",
    "        submission = submission.drop_duplicates(['question_id', 'answer_id'])\n",
    "\n",
    "        submission.label = submission.label.astype(str)\n",
    "        gold_truth.label = gold_truth.label.astype(str)\n",
    "\n",
    "        submission['entry'] = submission.apply(lambda x: '_'.join(map(str,x)), axis=1)\n",
    "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(map(str,x)), axis=1)\n",
    "\n",
    "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
    "\n",
    "        accuracy = s1.size / gold_truth.size\n",
    "\n",
    "        question_ids = []\n",
    "        correct_answers = {}\n",
    "        for index, row in gold_truth.iterrows():\n",
    "            qid = row['question_id']\n",
    "\n",
    "            if qid not in question_ids:\n",
    "                question_ids.append(qid)\n",
    "\n",
    "            if row['label'] == '1':\n",
    "                if qid not in correct_answers:\n",
    "                    correct_answers[qid] = []\n",
    "\n",
    "                correct_answers[qid].append(row['answer_id'])\n",
    "\n",
    "        Pr = 0.\n",
    "        spearman = 0.\n",
    "        pv = 0.\n",
    "        predictedPositive = 0.\n",
    "        correctPredictedPositive = 0.\n",
    "        mrr = 0.\n",
    "        sp_nan_ignoredQs = 0\n",
    "\n",
    "        for qid in question_ids:\n",
    "            submitted_correct_answers = []\n",
    "            index = 1\n",
    "            first = True\n",
    "            for _, row in submission[submission['question_id']==qid].iterrows():\n",
    "                aid = row['answer_id']\n",
    "                if row['label'] == '1':\n",
    "                    predictedPositive += 1\n",
    "                    if aid in correct_answers[qid]:\n",
    "                        correctPredictedPositive += 1\n",
    "                        submitted_correct_answers.append(aid)\n",
    "                        if first:\n",
    "                            mrr += 1. / index\n",
    "                            first=False\n",
    "\n",
    "                index += 1\n",
    "            matched_gold_subset = []\n",
    "\n",
    "            for x in correct_answers[qid]:\n",
    "                if x in submitted_correct_answers:\n",
    "                    matched_gold_subset.append(x)\n",
    "\n",
    "            rho, p_value = scipy.stats.spearmanr(submitted_correct_answers, matched_gold_subset)\n",
    "            if np.isnan(rho):\n",
    "                rho = 0.0\n",
    "                sp_nan_ignoredQs += 1\n",
    "            spearman += rho\n",
    "            pv += p_value\n",
    "\n",
    "        question_nb = len(question_ids)\n",
    "        q_nb_spearman = question_nb - sp_nan_ignoredQs\n",
    "        spearman = spearman / q_nb_spearman\n",
    "        Pr = correctPredictedPositive / predictedPositive\n",
    "        mrr = mrr / question_nb\n",
    "\n",
    "        if np.isnan(spearman):\n",
    "            spearman = 0.0\n",
    "\n",
    "        _result_object = {\n",
    "            \"score\": accuracy,\n",
    "            \"score_secondary\": spearman,\n",
    "            \"meta\" : {\n",
    "                \"MRR\": mrr,\n",
    "                \"Precision\": Pr\n",
    "            }\n",
    "        }\n",
    "        return _result_object\n",
    "\n",
    "\n",
    "# Test Tasks 1,2,3\n",
    "for task in []:\n",
    "    print(\"Testing Task (Round-1) : {}\".format(task))\n",
    "    answer_file_path = \"data/task{}/ground_truth_round_2.csv\".format(task)\n",
    "    _client_payload = {}\n",
    "    _client_payload[\"submission_file_path\"] = \"data/task{}/sample_submission_round_2.csv\".format(task)\n",
    "\n",
    "    # Instaiate a dummy context\n",
    "    _context = {}\n",
    "    # Instantiate an evaluator\n",
    "    aicrowd_evaluator = MediqaEvaluator(answer_file_path, task=task)\n",
    "    # Evaluate\n",
    "    result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "    print(result)\n",
    "\n",
    "# Test Tasks 1,2,3 - Round -2\n",
    "for task in [3]:\n",
    "    print(\"Testing Task (Round-2) : {}\".format(task))\n",
    "    answer_file_path = \"data/task{}/ground_truth_round_2.csv\".format(task)\n",
    "    _client_payload = {}\n",
    "    _client_payload[\"submission_file_path\"] = \"data/task{}/sample_submission_round_2.csv\".format(task)\n",
    "\n",
    "    # Instaiate a dummy context\n",
    "    _context = {}\n",
    "    # Instantiate an evaluator\n",
    "    aicrowd_evaluator = MediqaEvaluator(answer_file_path, task=task, round=2)\n",
    "    # Evaluate\n",
    "    result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzyudPpuZ1B8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ4pEiGlvhuY"
   },
   "source": [
    "### **BioELMo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "My_O_qOBvitB",
    "outputId": "e4802eeb-264b-4af8-d0e1-1e89ab015ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/4d/c9c4da41c6d7b9a4949cb9e53c7032d7d9b7da0410f1226f7455209dd962/tensorflow_gpu-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (89.5MB)\n",
      "\u001b[K     |████████████████████████████████| 89.5MB 33kB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
      "Collecting markdown==2.2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 41.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (3.12.4)\n",
      "Collecting html5lib==0.9999999\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 42.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.18.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (0.35.1)\n",
      "Collecting backports.weakref==1.0rc1\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
      "Collecting bleach==1.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow-gpu==1.2) (50.3.2)\n",
      "Building wheels for collected packages: markdown, html5lib\n",
      "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136279 sha256=c0c95af1c9f2dc84d3ffa183b0ef07f4efb77e59886ca9426d9dd1102e8936d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
      "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=6ee8ab4e295e152a39b2ea351e4722a7c6fb812164f57fe24987e1c3eb2776a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built markdown html5lib\n",
      "\u001b[31mERROR: tensorboard 2.3.0 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: markdown, html5lib, backports.weakref, bleach, tensorflow-gpu\n",
      "  Found existing installation: Markdown 3.3.3\n",
      "    Uninstalling Markdown-3.3.3:\n",
      "      Successfully uninstalled Markdown-3.3.3\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 3.2.1\n",
      "    Uninstalling bleach-3.2.1:\n",
      "      Successfully uninstalled bleach-3.2.1\n",
      "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-gpu-1.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow-gpu==1.2 h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAVbKJx1xmxi",
    "outputId": "2cf1a20f-026e-494c-8f13-75b34f74fc02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSwGZ1XZyAnx",
    "outputId": "ff047260-60b5-4999-81b4-963946903cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bilm-tf'...\n",
      "remote: Enumerating objects: 292, done.\u001b[K\n",
      "remote: Total 292 (delta 0), reused 0 (delta 0), pack-reused 292\u001b[K\n",
      "Receiving objects: 100% (292/292), 588.40 KiB | 782.00 KiB/s, done.\n",
      "Resolving deltas: 100% (137/137), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/allenai/bilm-tf.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk64Bgrt1rOc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoEtla-r5AxU",
    "outputId": "e2960e18-7c6e-432f-8b74-2d3e8c096cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mbilm-tf\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwSoJh8m4xi4",
    "outputId": "cd079aff-0eca-4b15-c861-7cfc752d85c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data =  (1000003, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                       <S>\n",
       "1                      </S>\n",
       "2                     <UNK>\n",
       "3                        of\n",
       "4                       the\n",
       "                 ...       \n",
       "999998                SgcE6\n",
       "999999     cubilin-mediated\n",
       "1000000       syndrome/drug\n",
       "1000001              11,214\n",
       "1000002       artery.RESULT\n",
       "Name: 0, Length: 1000003, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('/content/bilm-tf/vocabulary.txt', sep=\" \", header=None)\n",
    "print(\"Shape of training data = \", data_train.shape)\n",
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "H1-z9EUr5GqG",
    "outputId": "a2e7ebce-0021-46be-99e3-972d20272d5d"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2c55fd6318f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/bilm-tf/train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 4: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"/content/bilm-tf/train\"):\n",
    "    os.makedirs(\"/content/bilm-tf/train\")\n",
    " \n",
    "for i in range(0,data_train.shape[0],6):\n",
    "    text = \"\\n\".join(data_train[0][i:i+6].tolist())\n",
    "    fp = open(\"/content/bilm-tf/train/\"+str(i)+\".txt\",\"w\")\n",
    "    fp.write(text)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWpBMbxl5qjy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07b7a135531e43fb8174e780bf4a54e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "10eb159905cb4da881e506bea7ef3bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1398398f8aef4f27b93bc85edacdd770": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "147abfcfb0ac497a9736336ecf1a5c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2441cd058509472ea3fef74f72b3ba0f",
       "IPY_MODEL_ab9fea5b4c2f4426827ecfbd711097a9"
      ],
      "layout": "IPY_MODEL_ff0c4714c57f4cc697301ef2bf58eb28"
     }
    },
    "1a0d610808c54752a01d8fafe188c6a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a3968f8f4114cbcbd04edb27c82717e",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff2c3058101f4d7b8ec7e6b479ab5924",
      "value": 433
     }
    },
    "1f8d2fe393ea4898a5d9384974cc7e6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2441cd058509472ea3fef74f72b3ba0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71fb84f8487542429fa488d0c6fef2a6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5493bc3fc0704e3e8ea055de72f52367",
      "value": 231508
     }
    },
    "3a3968f8f4114cbcbd04edb27c82717e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4080dd44dc56497eb9585b20104cf45a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5493bc3fc0704e3e8ea055de72f52367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71fb84f8487542429fa488d0c6fef2a6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85f6584af22b4a1e931aad09f7fe66b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98128371afc04f1495643f1524b95c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e40dd44721f5472baae808befb672eb9",
      "placeholder": "​",
      "style": "IPY_MODEL_4080dd44dc56497eb9585b20104cf45a",
      "value": " 433/433 [00:00&lt;00:00, 1.02kB/s]"
     }
    },
    "9c8345c9dea24483a59817527326f1ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab9fea5b4c2f4426827ecfbd711097a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9b952cefb264ce28c1988a5d0652459",
      "placeholder": "​",
      "style": "IPY_MODEL_1398398f8aef4f27b93bc85edacdd770",
      "value": " 232k/232k [00:00&lt;00:00, 597kB/s]"
     }
    },
    "b4961a103212423296653018838aaa87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a0d610808c54752a01d8fafe188c6a5",
       "IPY_MODEL_98128371afc04f1495643f1524b95c7a"
      ],
      "layout": "IPY_MODEL_10eb159905cb4da881e506bea7ef3bf7"
     }
    },
    "b97b0de7f6684d60a0744f03f63c3510": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c8345c9dea24483a59817527326f1ef",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07b7a135531e43fb8174e780bf4a54e9",
      "value": 440473133
     }
    },
    "d8865f8d7f684edcb9c323c7b30ac7a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b97b0de7f6684d60a0744f03f63c3510",
       "IPY_MODEL_e7e5210cbf89470d914f0dec74f58fc0"
      ],
      "layout": "IPY_MODEL_1f8d2fe393ea4898a5d9384974cc7e6f"
     }
    },
    "dad2627650c6436fa21d6cf6bb1b2143": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e40dd44721f5472baae808befb672eb9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7e5210cbf89470d914f0dec74f58fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85f6584af22b4a1e931aad09f7fe66b2",
      "placeholder": "​",
      "style": "IPY_MODEL_dad2627650c6436fa21d6cf6bb1b2143",
      "value": " 440M/440M [00:10&lt;00:00, 43.2MB/s]"
     }
    },
    "e9b952cefb264ce28c1988a5d0652459": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff0c4714c57f4cc697301ef2bf58eb28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff2c3058101f4d7b8ec7e6b479ab5924": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
