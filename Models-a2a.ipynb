{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xml.dom.minidom import parse, parseString\n",
    "from nltk import tokenize as tk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class Question(object):\n",
    "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
    "        self.question_id = q_id\n",
    "        self.question = q\n",
    "        self.answer_ids = a_ids\n",
    "        self.answers = a\n",
    "        self.reference_rank = r\n",
    "        self.system_rank = s\n",
    "        self.labels = l\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class QuestionsAndAnswers(list):\n",
    "    def __init__(self, dataset='Train'):\n",
    "        ''' dataset = {Train,Test,Validation} '''\n",
    "        list.__init__(self)\n",
    "        self.PATH = 'MEDIQA2019_datasets/MEDIQA_Task3_QA/'\n",
    "        p = self.read_dataset(dataset)\n",
    "        self.extend(self.read_dataset(dataset))\n",
    "        \n",
    "        self.references = [np.array(q.reference_rank) for q in self]\n",
    "        self.labels = [np.array(q.labels) for q in self]\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "        return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "    def get_answers(self, answers):\n",
    "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
    "        for answer in answers:\n",
    "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "            a_id = answer.getAttribute('AID')\n",
    "            reference = int(answer.getAttribute('ReferenceRank'))\n",
    "            system = int(answer.getAttribute('SystemRank'))\n",
    "            label = answer.getAttribute('ReferenceScore')\n",
    "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "        return answs, answs_ids, rank, chiqa, y\n",
    "    \n",
    "    def get_system_ranks(self):\n",
    "          return [q.system_rank for q in self]\n",
    "        \n",
    "    def get_reference_ranks(self):\n",
    "          return [q.reference_rank for q in self]\n",
    "        \n",
    "    def get_labels(self):\n",
    "          return [q.labels for q in self]\n",
    "\n",
    "    def read_dataset(self, dataset='Train'):\n",
    "        i = 0\n",
    "        indx2id = []\n",
    "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
    "        for filename in os.listdir(self.PATH):\n",
    "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
    "            tree = parse(self.PATH + filename)\n",
    "            questions = tree.getElementsByTagName('Question')\n",
    "            for question in questions:\n",
    "                qelem = question.getElementsByTagName('QuestionText')\n",
    "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "                # print(q) # --> questions\n",
    "                answers = question.getElementsByTagName('Answer')\n",
    "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
    "                QA.append([q,answers_list, rank, labels])\n",
    "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
    "                # QA2.append([q,answers_list, rank, system, labels])\n",
    "                QA2.append(question)\n",
    "                indx2id.append(q_id); i+=1;\n",
    "                # break\n",
    "        return QA2\n",
    "\n",
    "    def output_predictions(self, predictions, labels, file=''):\n",
    "        assert len(predictions) == len(self)\n",
    "        print('question_id,answer_id,label')\n",
    "        with open(f'task3/sample_submission_round_2_{file}.csv', mode='w') as csv_file:\n",
    "            for i, p in enumerate(predictions):\n",
    "                q_id = self[i].question_id\n",
    "                answers = self[i].answer_ids\n",
    "                assert len(p) == len(answers), f'{len(p)} != {len(answers)}'\n",
    "                # order = np.array(a)[np.argsort(p)]\n",
    "                p = self.normalize_sequence(p)\n",
    "                order = np.array(answers)[np.argsort(p)]\n",
    "                # order = np.array(answers)[np.array(p)-1]\n",
    "                lab = labels[i]\n",
    "                ordered_lab = np.array(lab)[np.argsort(p)]\n",
    "                if file == '':\n",
    "                    \n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        print(f\"{q_id},{a_id},{int(l)}\")\n",
    "                else:\n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        csv_file.write(f\"{q_id},{a_id},{int(l)}\\n\")\n",
    "            \n",
    "    def normalize_sequence(self, seq):\n",
    "        seq = np.array(seq)\n",
    "        a = np.argsort(seq)\n",
    "        seq[a] = list(range(1,len(seq)+1))\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        preds = np.concatenate(predictions)\n",
    "        true  = np.concatenate(self.labels) \n",
    "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
    "        return accuracy_score(true, preds)\n",
    "\n",
    "    def precision(self, predictions):\n",
    "        precisions = []\n",
    "        num_answers = []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
    "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
    "            if len(p) == 0:\n",
    "                print(predictions[i])\n",
    "            correct = sum([a == b for a,b in zip(p, r)])\n",
    "            # for a,b in zip(p, r)\n",
    "            # num_answers.append(len(p))\n",
    "            precisions.append(correct/len(p))\n",
    "        return np.mean(precisions)\n",
    "        # return np.average(np.array(precisions), weights=num_answers)\n",
    "\n",
    "    def mean_spearmanr(self, predictions):\n",
    "        assert len(predictions) == len(self.references)\n",
    "        count, total = 0, 0\n",
    "        preds, refs = [], []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
    "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
    "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
    "            preds += p; refs += r\n",
    "            if len(r) == 1:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            elif len(r) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                total += 1\n",
    "                count += spearmanr(p, r)[0]\n",
    "        return spearmanr(preds, refs)[0]\n",
    "        # return count/total\n",
    "\n",
    "    def mean_reciprocal_rank(self, predicted):\n",
    "        rs = []\n",
    "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
    "            res = np.array(a)[np.argsort(b)]\n",
    "            labels = self[k].labels\n",
    "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
    "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = QuestionsAndAnswers(dataset = 'Train')\n",
    "QA_val = QuestionsAndAnswers(dataset = 'Validation')\n",
    "QA_test = QuestionsAndAnswers(dataset = 'Test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_ranks = QA_test.get_system_ranks()\n",
    "reference_ranks = [q.reference_rank for q in QA_test]\n",
    "labels = [q.labels for q in QA_test]\n",
    "system_labels = [np.ones(len(l)) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA.output_predictions(reference_ranks, labels)\n",
    "# QA.output_predictions(system_ranks, system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "QA_test.output_predictions(system_ranks, system_labels, file='test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test2.csv\n",
      "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}\n"
     ]
    }
   ],
   "source": [
    "import evaluator\n",
    "\n",
    "def evaluate(filename):\n",
    "    for task in [3]:\n",
    "        print(f\"Testing Task (Round-2) : {task}\")\n",
    "        answer_file_path = f\"task{task}/ground_truth_round_2.csv\"\n",
    "        _client_payload = {}\n",
    "        _client_payload[\"submission_file_path\"] = f\"task{task}/sample_submission_round_2_{filename}.csv\"\n",
    "\n",
    "        # Instaiate a dummy context\n",
    "        _context = {}\n",
    "        # Instantiate an evaluator\n",
    "        aicrowd_evaluator = evaluator.MediqaEvaluator(answer_file_path, task=task, round=2)\n",
    "        # Evaluate\n",
    "        result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "        print(result)\n",
    "\n",
    "evaluate('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline\n",
    "\n",
    "Testing Task (Round-2) : 3\n",
    "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5fd5ff59eb4103a4127e82f8b020a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "\n",
    "# model = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
    "#                                   output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + q + \" [SEP]\"))[:max_len_seq]\n",
    "            _q += [0]*(max_len_seq-len(_q))\n",
    "            _a = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + a + \" [SEP]\"))[:max_len_seq]\n",
    "            _a += [0]*(max_len_seq-len(_a))\n",
    "            self.X.append([_q, _a])\n",
    "        self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset(X=sentences_test, y=labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55130,\n",
       " 49363,\n",
       " 39554,\n",
       " 35113,\n",
       " 34288,\n",
       " 31397,\n",
       " 31086,\n",
       " 31086,\n",
       " 30534,\n",
       " 30070,\n",
       " 27904,\n",
       " 25920,\n",
       " 25238,\n",
       " 23995,\n",
       " 22489,\n",
       " 22010,\n",
       " 21908,\n",
       " 21372,\n",
       " 21372,\n",
       " 19886,\n",
       " 19699,\n",
       " 19081,\n",
       " 18399,\n",
       " 17864,\n",
       " 17864,\n",
       " 16916,\n",
       " 16872,\n",
       " 16866,\n",
       " 16763,\n",
       " 16608,\n",
       " 16608,\n",
       " 16608,\n",
       " 16463,\n",
       " 16454,\n",
       " 16454,\n",
       " 16450,\n",
       " 16436,\n",
       " 16436,\n",
       " 16436,\n",
       " 16436,\n",
       " 16436,\n",
       " 16032,\n",
       " 15934,\n",
       " 15606,\n",
       " 15606,\n",
       " 15606,\n",
       " 15606,\n",
       " 15550,\n",
       " 15199,\n",
       " 14524,\n",
       " 14098,\n",
       " 13812,\n",
       " 13798,\n",
       " 13707,\n",
       " 13707,\n",
       " 13103,\n",
       " 13103,\n",
       " 13087,\n",
       " 12224,\n",
       " 12075,\n",
       " 12040,\n",
       " 12005,\n",
       " 11893,\n",
       " 11690,\n",
       " 11690,\n",
       " 11675,\n",
       " 11675,\n",
       " 11671,\n",
       " 10868,\n",
       " 10832,\n",
       " 10610,\n",
       " 10574,\n",
       " 10386,\n",
       " 10260,\n",
       " 10137,\n",
       " 9704,\n",
       " 9584,\n",
       " 9423,\n",
       " 9186,\n",
       " 9133,\n",
       " 9062,\n",
       " 9062,\n",
       " 9062,\n",
       " 9062,\n",
       " 9062,\n",
       " 9020,\n",
       " 9012,\n",
       " 8927,\n",
       " 8867,\n",
       " 8827,\n",
       " 8818,\n",
       " 8805,\n",
       " 8545,\n",
       " 8545,\n",
       " 8513,\n",
       " 8473,\n",
       " 8369,\n",
       " 8340,\n",
       " 8173,\n",
       " 8152,\n",
       " 8040,\n",
       " 8003,\n",
       " 7899,\n",
       " 7899,\n",
       " 7821,\n",
       " 7782,\n",
       " 7573,\n",
       " 7528,\n",
       " 7528,\n",
       " 7513,\n",
       " 7482,\n",
       " 7478,\n",
       " 7478,\n",
       " 7442,\n",
       " 7430,\n",
       " 7420,\n",
       " 7404,\n",
       " 7316,\n",
       " 7243,\n",
       " 7227,\n",
       " 7195,\n",
       " 7172,\n",
       " 7170,\n",
       " 7154,\n",
       " 7145,\n",
       " 7103,\n",
       " 7093,\n",
       " 7078,\n",
       " 7050,\n",
       " 7049,\n",
       " 7009,\n",
       " 6997,\n",
       " 6981,\n",
       " 6958,\n",
       " 6911,\n",
       " 6895,\n",
       " 6895,\n",
       " 6895,\n",
       " 6895,\n",
       " 6843,\n",
       " 6825,\n",
       " 6761,\n",
       " 6680,\n",
       " 6636,\n",
       " 6636,\n",
       " 6636,\n",
       " 6636,\n",
       " 6636,\n",
       " 6636,\n",
       " 6561,\n",
       " 6550,\n",
       " 6543,\n",
       " 6530,\n",
       " 6517,\n",
       " 6517,\n",
       " 6495,\n",
       " 6471,\n",
       " 6459,\n",
       " 6423,\n",
       " 6411,\n",
       " 6407,\n",
       " 6390,\n",
       " 6382,\n",
       " 6356,\n",
       " 6356,\n",
       " 6356,\n",
       " 6356,\n",
       " 6318,\n",
       " 6318,\n",
       " 6298,\n",
       " 6294,\n",
       " 6275,\n",
       " 6275,\n",
       " 6275,\n",
       " 6275,\n",
       " 6275,\n",
       " 6275,\n",
       " 6260,\n",
       " 6228,\n",
       " 6220,\n",
       " 6179,\n",
       " 6125,\n",
       " 6095,\n",
       " 6065,\n",
       " 6037,\n",
       " 6026,\n",
       " 6026,\n",
       " 6026,\n",
       " 5985,\n",
       " 5909,\n",
       " 5825,\n",
       " 5819,\n",
       " 5776,\n",
       " 5774,\n",
       " 5767,\n",
       " 5677,\n",
       " 5672,\n",
       " 5649,\n",
       " 5635,\n",
       " 5607,\n",
       " 5604,\n",
       " 5597,\n",
       " 5597,\n",
       " 5587,\n",
       " 5574,\n",
       " 5395,\n",
       " 5343,\n",
       " 5335,\n",
       " 5319,\n",
       " 5312,\n",
       " 5279,\n",
       " 5275,\n",
       " 5275,\n",
       " 5275,\n",
       " 5275,\n",
       " 5275,\n",
       " 5275,\n",
       " 5272,\n",
       " 5272,\n",
       " 5272,\n",
       " 5183,\n",
       " 5161,\n",
       " 5161,\n",
       " 5146,\n",
       " 5146,\n",
       " 5146,\n",
       " 5146,\n",
       " 5121,\n",
       " 5056,\n",
       " 5049,\n",
       " 4986,\n",
       " 4986,\n",
       " 4970,\n",
       " 4935,\n",
       " 4904,\n",
       " 4897,\n",
       " 4869,\n",
       " 4843,\n",
       " 4833,\n",
       " 4825,\n",
       " 4804,\n",
       " 4801,\n",
       " 4794,\n",
       " 4791,\n",
       " 4707,\n",
       " 4675,\n",
       " 4629,\n",
       " 4605,\n",
       " 4603,\n",
       " 4599,\n",
       " 4570,\n",
       " 4556,\n",
       " 4543,\n",
       " 4534,\n",
       " 4531,\n",
       " 4521,\n",
       " 4521,\n",
       " 4521,\n",
       " 4510,\n",
       " 4499,\n",
       " 4491,\n",
       " 4485,\n",
       " 4482,\n",
       " 4482,\n",
       " 4482,\n",
       " 4482,\n",
       " 4482,\n",
       " 4482,\n",
       " 4457,\n",
       " 4441,\n",
       " 4439,\n",
       " 4425,\n",
       " 4416,\n",
       " 4412,\n",
       " 4384,\n",
       " 4371,\n",
       " 4351,\n",
       " 4331,\n",
       " 4322,\n",
       " 4306,\n",
       " 4286,\n",
       " 4265,\n",
       " 4214,\n",
       " 4214,\n",
       " 4182,\n",
       " 4165,\n",
       " 4123,\n",
       " 4093,\n",
       " 4090,\n",
       " 4090,\n",
       " 4075,\n",
       " 4075,\n",
       " 4075,\n",
       " 4075,\n",
       " 4075,\n",
       " 4069,\n",
       " 4063,\n",
       " 4030,\n",
       " 4020,\n",
       " 4016,\n",
       " 4016,\n",
       " 4016,\n",
       " 3979,\n",
       " 3973,\n",
       " 3968,\n",
       " 3968,\n",
       " 3968,\n",
       " 3968,\n",
       " 3968,\n",
       " 3953,\n",
       " 3952,\n",
       " 3933,\n",
       " 3898,\n",
       " 3896,\n",
       " 3890,\n",
       " 3872,\n",
       " 3839,\n",
       " 3828,\n",
       " 3823,\n",
       " 3823,\n",
       " 3819,\n",
       " 3813,\n",
       " 3813,\n",
       " 3813,\n",
       " 3812,\n",
       " 3775,\n",
       " 3772,\n",
       " 3731,\n",
       " 3706,\n",
       " 3698,\n",
       " 3695,\n",
       " 3695,\n",
       " 3692,\n",
       " 3677,\n",
       " 3667,\n",
       " 3657,\n",
       " 3642,\n",
       " 3624,\n",
       " 3612,\n",
       " 3607,\n",
       " 3607,\n",
       " 3605,\n",
       " 3604,\n",
       " 3604,\n",
       " 3598,\n",
       " 3598,\n",
       " 3598,\n",
       " 3597,\n",
       " 3580,\n",
       " 3580,\n",
       " 3580,\n",
       " 3580,\n",
       " 3580,\n",
       " 3573,\n",
       " 3559,\n",
       " 3558,\n",
       " 3554,\n",
       " 3551,\n",
       " 3551,\n",
       " 3551,\n",
       " 3545,\n",
       " 3543,\n",
       " 3513,\n",
       " 3513,\n",
       " 3490,\n",
       " 3488,\n",
       " 3480,\n",
       " 3473,\n",
       " 3456,\n",
       " 3455,\n",
       " 3449,\n",
       " 3449,\n",
       " 3446,\n",
       " 3443,\n",
       " 3443,\n",
       " 3443,\n",
       " 3443,\n",
       " 3443,\n",
       " 3435,\n",
       " 3390,\n",
       " 3357,\n",
       " 3351,\n",
       " 3341,\n",
       " 3338,\n",
       " 3323,\n",
       " 3323,\n",
       " 3323,\n",
       " 3319,\n",
       " 3317,\n",
       " 3317,\n",
       " 3317,\n",
       " 3317,\n",
       " 3317,\n",
       " 3309,\n",
       " 3300,\n",
       " 3263,\n",
       " 3236,\n",
       " 3236,\n",
       " 3220,\n",
       " 3220,\n",
       " 3205,\n",
       " 3185,\n",
       " 3148,\n",
       " 3120,\n",
       " 3092,\n",
       " 3092,\n",
       " 3078,\n",
       " 3078,\n",
       " 3078,\n",
       " 3078,\n",
       " 3064,\n",
       " 3063,\n",
       " 3063,\n",
       " 3059,\n",
       " 3044,\n",
       " 3034,\n",
       " 3027,\n",
       " 3010,\n",
       " 3004,\n",
       " 3004,\n",
       " 3004,\n",
       " 3004,\n",
       " 2998,\n",
       " 2997,\n",
       " 2996,\n",
       " 2996,\n",
       " 2992,\n",
       " 2985,\n",
       " 2967,\n",
       " 2960,\n",
       " 2956,\n",
       " 2953,\n",
       " 2953,\n",
       " 2937,\n",
       " 2920,\n",
       " 2919,\n",
       " 2912,\n",
       " 2889,\n",
       " 2886,\n",
       " 2878,\n",
       " 2865,\n",
       " 2862,\n",
       " 2862,\n",
       " 2862,\n",
       " 2859,\n",
       " 2853,\n",
       " 2844,\n",
       " 2831,\n",
       " 2827,\n",
       " 2824,\n",
       " 2794,\n",
       " 2794,\n",
       " 2791,\n",
       " 2783,\n",
       " 2782,\n",
       " 2780,\n",
       " 2773,\n",
       " 2773,\n",
       " 2744,\n",
       " 2744,\n",
       " 2741,\n",
       " 2737,\n",
       " 2726,\n",
       " 2704,\n",
       " 2695,\n",
       " 2694,\n",
       " 2692,\n",
       " 2668,\n",
       " 2639,\n",
       " 2637,\n",
       " 2626,\n",
       " 2611,\n",
       " 2610,\n",
       " 2608,\n",
       " 2587,\n",
       " 2587,\n",
       " 2587,\n",
       " 2587,\n",
       " 2587,\n",
       " 2585,\n",
       " 2585,\n",
       " 2580,\n",
       " 2571,\n",
       " 2571,\n",
       " 2570,\n",
       " 2566,\n",
       " 2566,\n",
       " 2553,\n",
       " 2547,\n",
       " 2546,\n",
       " 2542,\n",
       " 2501,\n",
       " 2500,\n",
       " 2495,\n",
       " 2489,\n",
       " 2488,\n",
       " 2488,\n",
       " 2487,\n",
       " 2482,\n",
       " 2460,\n",
       " 2457,\n",
       " 2453,\n",
       " 2444,\n",
       " 2434,\n",
       " 2423,\n",
       " 2419,\n",
       " 2418,\n",
       " 2414,\n",
       " 2414,\n",
       " 2414,\n",
       " 2408,\n",
       " 2402,\n",
       " 2402,\n",
       " 2393,\n",
       " 2389,\n",
       " 2389,\n",
       " 2389,\n",
       " 2389,\n",
       " 2389,\n",
       " 2388,\n",
       " 2386,\n",
       " 2385,\n",
       " 2362,\n",
       " 2359,\n",
       " 2357,\n",
       " 2349,\n",
       " 2342,\n",
       " 2333,\n",
       " 2327,\n",
       " 2317,\n",
       " 2317,\n",
       " 2317,\n",
       " 2313,\n",
       " 2313,\n",
       " 2298,\n",
       " 2295,\n",
       " 2279,\n",
       " 2264,\n",
       " 2261,\n",
       " 2246,\n",
       " 2243,\n",
       " 2240,\n",
       " 2226,\n",
       " 2221,\n",
       " 2219,\n",
       " 2217,\n",
       " 2209,\n",
       " 2209,\n",
       " 2209,\n",
       " 2204,\n",
       " 2194,\n",
       " 2194,\n",
       " 2189,\n",
       " 2178,\n",
       " 2177,\n",
       " 2175,\n",
       " 2175,\n",
       " 2172,\n",
       " 2145,\n",
       " 2145,\n",
       " 2138,\n",
       " 2132,\n",
       " 2128,\n",
       " 2114,\n",
       " 2086,\n",
       " 2085,\n",
       " 2079,\n",
       " 2074,\n",
       " 2067,\n",
       " 2063,\n",
       " 2056,\n",
       " 2056,\n",
       " 2056,\n",
       " 2056,\n",
       " 2056,\n",
       " 2055,\n",
       " 2055,\n",
       " 2055,\n",
       " 2055,\n",
       " 2055,\n",
       " 2041,\n",
       " 2031,\n",
       " 2030,\n",
       " 2026,\n",
       " 2018,\n",
       " 2010,\n",
       " 1991,\n",
       " 1985,\n",
       " 1981,\n",
       " 1981,\n",
       " 1973,\n",
       " 1972,\n",
       " 1964,\n",
       " 1950,\n",
       " 1942,\n",
       " 1941,\n",
       " 1941,\n",
       " 1941,\n",
       " 1940,\n",
       " 1935,\n",
       " 1922,\n",
       " 1919,\n",
       " 1911,\n",
       " 1905,\n",
       " 1901,\n",
       " 1900,\n",
       " 1899,\n",
       " 1887,\n",
       " 1885,\n",
       " 1885,\n",
       " 1885,\n",
       " 1885,\n",
       " 1882,\n",
       " 1881,\n",
       " 1879,\n",
       " 1867,\n",
       " 1866,\n",
       " 1866,\n",
       " 1864,\n",
       " 1863,\n",
       " 1863,\n",
       " 1863,\n",
       " 1863,\n",
       " 1863,\n",
       " 1862,\n",
       " 1853,\n",
       " 1843,\n",
       " 1828,\n",
       " 1828,\n",
       " 1822,\n",
       " 1820,\n",
       " 1820,\n",
       " 1811,\n",
       " 1806,\n",
       " 1791,\n",
       " 1787,\n",
       " 1775,\n",
       " 1775,\n",
       " 1775,\n",
       " 1775,\n",
       " 1775,\n",
       " 1775,\n",
       " 1769,\n",
       " 1766,\n",
       " 1766,\n",
       " 1758,\n",
       " 1756,\n",
       " 1755,\n",
       " 1742,\n",
       " 1732,\n",
       " 1732,\n",
       " 1732,\n",
       " 1731,\n",
       " 1714,\n",
       " 1713,\n",
       " 1712,\n",
       " 1711,\n",
       " 1711,\n",
       " 1705,\n",
       " 1705,\n",
       " 1705,\n",
       " 1703,\n",
       " 1701,\n",
       " 1700,\n",
       " 1688,\n",
       " 1686,\n",
       " 1684,\n",
       " 1682,\n",
       " 1682,\n",
       " 1681,\n",
       " 1681,\n",
       " 1670,\n",
       " 1670,\n",
       " 1653,\n",
       " 1649,\n",
       " 1636,\n",
       " 1635,\n",
       " 1635,\n",
       " 1633,\n",
       " 1632,\n",
       " 1624,\n",
       " 1618,\n",
       " 1617,\n",
       " 1596,\n",
       " 1596,\n",
       " 1585,\n",
       " 1581,\n",
       " 1579,\n",
       " 1572,\n",
       " 1568,\n",
       " 1566,\n",
       " 1566,\n",
       " 1566,\n",
       " 1566,\n",
       " 1563,\n",
       " 1560,\n",
       " 1555,\n",
       " 1551,\n",
       " 1547,\n",
       " 1547,\n",
       " 1547,\n",
       " 1547,\n",
       " 1547,\n",
       " 1547,\n",
       " 1547,\n",
       " 1544,\n",
       " 1541,\n",
       " 1539,\n",
       " 1529,\n",
       " 1527,\n",
       " 1525,\n",
       " 1525,\n",
       " 1522,\n",
       " 1521,\n",
       " 1521,\n",
       " 1521,\n",
       " 1521,\n",
       " 1521,\n",
       " 1519,\n",
       " 1518,\n",
       " 1514,\n",
       " 1508,\n",
       " 1507,\n",
       " 1507,\n",
       " 1490,\n",
       " 1487,\n",
       " 1487,\n",
       " 1487,\n",
       " 1487,\n",
       " 1485,\n",
       " 1481,\n",
       " 1481,\n",
       " 1481,\n",
       " 1477,\n",
       " 1476,\n",
       " 1471,\n",
       " 1468,\n",
       " 1468,\n",
       " 1468,\n",
       " 1468,\n",
       " 1468,\n",
       " 1468,\n",
       " 1467,\n",
       " 1467,\n",
       " 1464,\n",
       " 1464,\n",
       " 1464,\n",
       " 1461,\n",
       " 1461,\n",
       " 1461,\n",
       " 1451,\n",
       " 1449,\n",
       " 1448,\n",
       " 1447,\n",
       " 1447,\n",
       " 1435,\n",
       " 1431,\n",
       " 1423,\n",
       " 1417,\n",
       " 1415,\n",
       " 1412,\n",
       " 1412,\n",
       " 1410,\n",
       " 1408,\n",
       " 1403,\n",
       " 1397,\n",
       " 1396,\n",
       " 1386,\n",
       " 1382,\n",
       " 1375,\n",
       " 1374,\n",
       " 1370,\n",
       " 1370,\n",
       " 1368,\n",
       " 1365,\n",
       " 1355,\n",
       " 1354,\n",
       " 1351,\n",
       " 1350,\n",
       " 1347,\n",
       " 1346,\n",
       " 1343,\n",
       " 1343,\n",
       " 1343,\n",
       " 1327,\n",
       " 1321,\n",
       " 1312,\n",
       " 1308,\n",
       " 1307,\n",
       " 1304,\n",
       " 1304,\n",
       " 1302,\n",
       " 1302,\n",
       " 1302,\n",
       " 1301,\n",
       " 1300,\n",
       " 1300,\n",
       " 1297,\n",
       " 1294,\n",
       " 1294,\n",
       " 1293,\n",
       " 1293,\n",
       " 1293,\n",
       " 1289,\n",
       " 1286,\n",
       " 1285,\n",
       " 1282,\n",
       " 1280,\n",
       " 1280,\n",
       " 1270,\n",
       " 1269,\n",
       " 1262,\n",
       " 1260,\n",
       " 1257,\n",
       " 1256,\n",
       " 1256,\n",
       " 1256,\n",
       " 1256,\n",
       " 1249,\n",
       " 1247,\n",
       " 1247,\n",
       " 1244,\n",
       " 1243,\n",
       " 1241,\n",
       " 1236,\n",
       " 1229,\n",
       " 1228,\n",
       " 1227,\n",
       " 1227,\n",
       " 1226,\n",
       " 1225,\n",
       " 1225,\n",
       " 1225,\n",
       " 1225,\n",
       " 1225,\n",
       " 1225,\n",
       " 1224,\n",
       " 1219,\n",
       " 1219,\n",
       " 1219,\n",
       " 1216,\n",
       " 1214,\n",
       " 1214,\n",
       " 1206,\n",
       " 1206,\n",
       " 1206,\n",
       " 1201,\n",
       " 1197,\n",
       " 1197,\n",
       " 1197,\n",
       " 1191,\n",
       " 1188,\n",
       " 1187,\n",
       " 1184,\n",
       " 1182,\n",
       " 1180,\n",
       " 1179,\n",
       " 1179,\n",
       " 1178,\n",
       " 1175,\n",
       " 1173,\n",
       " 1168,\n",
       " 1168,\n",
       " 1168,\n",
       " 1168,\n",
       " 1168,\n",
       " 1149,\n",
       " 1149,\n",
       " 1148,\n",
       " 1145,\n",
       " 1144,\n",
       " 1137,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1136,\n",
       " 1126,\n",
       " 1120,\n",
       " 1118,\n",
       " 1118,\n",
       " 1118,\n",
       " 1118,\n",
       " 1118,\n",
       " 1118,\n",
       " 1117,\n",
       " 1115,\n",
       " 1115,\n",
       " 1110,\n",
       " 1105,\n",
       " 1105,\n",
       " 1105,\n",
       " 1101,\n",
       " 1099,\n",
       " 1099,\n",
       " 1097,\n",
       " 1092,\n",
       " 1089,\n",
       " 1087,\n",
       " 1085,\n",
       " 1081,\n",
       " 1078,\n",
       " 1078,\n",
       " 1077,\n",
       " 1075,\n",
       " 1075,\n",
       " 1075,\n",
       " 1075,\n",
       " 1075,\n",
       " 1070,\n",
       " 1068,\n",
       " 1068,\n",
       " 1061,\n",
       " 1061,\n",
       " 1060,\n",
       " 1060,\n",
       " 1057,\n",
       " 1057,\n",
       " 1057,\n",
       " 1057,\n",
       " 1056,\n",
       " 1055,\n",
       " 1054,\n",
       " 1054,\n",
       " 1054,\n",
       " 1046,\n",
       " 1045,\n",
       " 1045,\n",
       " 1045,\n",
       " 1045,\n",
       " 1044,\n",
       " 1044,\n",
       " 1037,\n",
       " 1037,\n",
       " 1037,\n",
       " 1037,\n",
       " 1037,\n",
       " 1037,\n",
       " 1035,\n",
       " 1032,\n",
       " 1032,\n",
       " 1026,\n",
       " 1021,\n",
       " 1021,\n",
       " 1021,\n",
       " 1021,\n",
       " 1021,\n",
       " 1018,\n",
       " 1018,\n",
       " 1018,\n",
       " 1015,\n",
       " 1015,\n",
       " 1015,\n",
       " 1014,\n",
       " 1014,\n",
       " 1012,\n",
       " 1012,\n",
       " 1011,\n",
       " 1011,\n",
       " 1006,\n",
       " 1004,\n",
       " 1004,\n",
       " 1002,\n",
       " 999,\n",
       " 998,\n",
       " 998,\n",
       " 998,\n",
       " 989,\n",
       " 988,\n",
       " 988,\n",
       " 988,\n",
       " 988,\n",
       " 984,\n",
       " 984,\n",
       " 982,\n",
       " 981,\n",
       " 979,\n",
       " 978,\n",
       " 977,\n",
       " 974,\n",
       " 970,\n",
       " 970,\n",
       " 969,\n",
       " 964,\n",
       " 957,\n",
       " 956,\n",
       " 955,\n",
       " 952,\n",
       " 951,\n",
       " 949,\n",
       " 949,\n",
       " 949,\n",
       " 949,\n",
       " 947,\n",
       " 947,\n",
       " 947,\n",
       " 946,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)\n",
    "max_len_seq = 0\n",
    "lenghts = []\n",
    "for q,a in sentences:\n",
    "    lenghts.append(len(a))\n",
    "    if len(a)>max_len_seq:\n",
    "        max_len_seq = len(a)\n",
    "max_len_seq\n",
    "sorted(lenghts, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bert_clf.bert.encoder.layer)\n",
    "# bert_clf.bert.config.hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained('dmis-lab/biobert-v1.1')\n",
    "        self.bert = BertModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*self.bert.config.hidden_size, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        CLS1 = self.get_CLS(q)\n",
    "        CLS2 = self.get_CLS(a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([CLS1, CLS2], dim=1)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear2(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear3(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, CLS1, CLS2\n",
    "\n",
    "\n",
    "    def get_CLS(self, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokeniEARLY_STOPPINGtext)\n",
    "#         segments_ids = [1] * len(indexed_tokens)\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = self.bert(tokens_tensor)\n",
    "        CLS = outputs[0][:,0,:]\n",
    "        return CLS\n",
    "\n",
    "    def get_full_sentence_embedding(self, sentence):\n",
    "        embeddings = []\n",
    "        e = 0\n",
    "        max_size = 1024#512\n",
    "        for i in range(int(len(sentence)/max_size)+1):\n",
    "    #         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "    #         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "            e = self.get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "    #         print(e)\n",
    "            embeddings.append(e)\n",
    "        embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "        print(embedding)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del bert_clf\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f25861a9a741ed90962db78f0d3ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=385.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47d426ddf1a4b09b32ee0bdf32c08fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=435778770.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_clf = MEDIQA_Model()\n",
    "bert_clf = bert_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,q,a in tqdm.tqdm(test_loader):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(labels_test, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-540d278a607e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# bert_clf = MEDIQA_Model()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# bert_clf = bert_clf.to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbert_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=1e-4)\n",
    "bert_clf.train()\n",
    "EPOCHS = 200\n",
    "EARLY_STOPPING = 5\n",
    "loss_func = nn.BCELoss()\n",
    "def ranking_loss(x1, x2, y):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=0)\n",
    "        return 1-cos(a,b)\n",
    "    margin = 0.5\n",
    "    loss = y*dist(x1,x2) + (1-y)*torch.max(0, margin - dist(x1,x2))\n",
    "    return loss\n",
    "\n",
    "train_losses, test_losses, test_acc = [], [], []\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    for step_num, batch_data in enumerate(train_loader):\n",
    "        y_true, questions, answers = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        if questions.shape != answers.shape: continue\n",
    "        logits, _, _ = bert_clf(questions.to(device), answers.to(device))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "        \n",
    "        bert_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print('step', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    acc, probs_labels, _ = get_test_acc(bert_clf, return_probs_and_labels=True)\n",
    "    test_acc.append(acc)\n",
    "    test_loss = loss_func(torch.from_numpy(probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    test_losses.append(test_loss)\n",
    "    print(f'Test acc:', acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_acc) <= 1 or acc > max(test_acc[:-1]):\n",
    "        torch.save(bert_clf.state_dict(), 'checkpoints/model')\n",
    "    if len(test_acc) > EARLY_STOPPING and test_acc[-(EARLY_STOPPING+1)] > max(test_acc[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model()\n",
    "        model.load_state_dict(torch.load('checkpoints/model'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_acc, label='test acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(bert_clf.state_dict(), 'models/mediqa_model_biobert_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model = MEDIQA_Model()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [01:06<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "acc, probs, y_pred = get_test_acc(model.to(device), return_probs_and_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_predictions(probs, y):\n",
    "    rankings  = []\n",
    "    entailed = []\n",
    "    i_start  = 0\n",
    "    for i, q in enumerate(QA_test):\n",
    "        rankings.append(1- np.array(probs[i_start:i_start+len(q.answers)]))\n",
    "        entailed.append(y[i_start:i_start+len(q.answers)])\n",
    "        i_start += len(q.answers)\n",
    "        assert len(rankings[i] == len(QA_test[i].answer_ids))\n",
    "        assert len(entailed[i] == len(QA_test[i].answers))\n",
    "    return rankings, entailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "ranking_pred, labels_pred = get_ranking_predictions(probs, y_pred)\n",
    "QA_test.output_predictions(ranking_pred, labels_pred, file='test_biobert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test_biobert2.csv\n",
      "{'score_acc': 0.5663956639566395, 'score_secondary_spearman': 0.11690140845070421, 'meta': {'MRR': 0.6255555555555556, 'Precision': 0.6133004926108374}}\n"
     ]
    }
   ],
   "source": [
    "evaluate('test_biobert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:51<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "pred_labels = []\n",
    "bert_clf.to(device)\n",
    "with torch.no_grad():\n",
    "    for s,q,a in tqdm.tqdm(test_loader):\n",
    "        logits = bert_clf(q.to(device),a.to(device))\n",
    "        pred_labels.extend(logits.to('cpu'))\n",
    "    pred_labels = np.array([x.item() for x in pred_labels])\n",
    "    pred = (pred_labels > 0.5).astype(np.int16)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971093044263776"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([1,2,3]), torch.tensor([1,2,3])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101,   193,   118,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3073, 10294,  ...,  1110,  1136,  2276],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101, 14051, 16026,  ...,     0,     0,     0],\n",
      "        [  101,  1887,  8006,  ...,  2039,   119,  1142],\n",
      "        [  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1221, 1167,  ...,    0,    0,    0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1187,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 19640,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,  2975,  1115,  1138],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 32180, 20939,  ...,  1132,  1160,  1514],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36359, 31630,  ...,  7604,  1137,  8192],\n",
      "        [  101, 44511,  1596,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 15355, 15491,  ...,  1128,  1444,  1106],\n",
      "        [  101, 16638,  1822,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  4333,  1183,  ...,  1240,  2027,  1144],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101, 58456, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 20557, 22214,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,     0,     0,     0],\n",
      "        [  101,  3607, 14255,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  2016,  1104,  4182],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41844,  1162,  ..., 17713,   120, 37553],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]]), tensor([[  101, 20844,  6575,  ...,   170,   119,   173],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 24443, 20497,  ...,   118, 29346,  2149],\n",
      "        [  101, 14255, 43199,  ..., 43199, 48974, 20484]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  3924,  9304,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14947,   113,  ...,     0,     0,     0],\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  3252,  6665,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 45648, 11098,  ...,  2332,  2094,  4822],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 16374,   117, 23658],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,  1104,  2094,  1106],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101, 19245,  1105,  ...,  2914,   119,  2367]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 35810,  ...,  2116,   118,  7930],\n",
      "        [  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,  1165,  1106,  1840]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 27410, 29261,  ..., 29261, 10306,  3252],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 39960, 41482,  ...,     0,     0,     0],\n",
      "        [  101,  4457,   118,  ...,  5173, 24034,  8341]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,  5800,  2109, 14255],\n",
      "        [  101, 14255, 43199,  ...,  1274,   112,   189],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,  1128,  4330,  1315],\n",
      "        [  101, 43760, 21459,  ...,  8006,  1336,  7907],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,  2612,  1105,  2450],\n",
      "        [  101, 15604, 16420,  ..., 23658,  1175,  1132],\n",
      "        ...,\n",
      "        [  101, 13316, 33391,  ...,  1132,  1276,  1219],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101, 29278, 25453,  ...,   173,   119,   170]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 53109,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3678, 22869,  ...,  1118,   131,   179],\n",
      "        [  101,  1322,  6758,  ...,     0,     0,     0],\n",
      "        [  101, 17972,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 10878, 17972,  ...,  3843, 39241,  8032],\n",
      "        [  101, 34754,  1643,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 39241,  8032,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,  2633,   119,  1191],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1110,  1122,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101,  5153, 29284,  ...,  1191,  1115,  2086],\n",
      "        [  101, 53685, 35810,  ...,   170,  2960,  1104],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        ...,\n",
      "        [  101, 14434,   193,  ...,     0,     0,     0],\n",
      "        [  101,  7753, 22869,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ...,  6028,  2445,   117]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,  3490,  1107,   170],\n",
      "        [  101,  3245, 40739,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,  1116,  3652,  1105],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6245,  1104,  ...,  2922,   117, 37521],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0]]), tensor([[  101,  5354, 20939,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,  1353,  6556,  1104],\n",
      "        [  101, 47433, 10024,  ...,  1936,  1334,  3154],\n",
      "        ...,\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 44648, 32219,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  3252,  1111,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 12809,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35929, 42193,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ..., 24259,  1116,   119],\n",
      "        [  101, 33869, 31719,  ...,  2769,  1104,  1142]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9947,  1181,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1322,  6758,  ...,   185,  8057,  2225],\n",
      "        [  101,  1940,  1233,  ...,   176,   117,  2027]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101, 43165,   113,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  5837, 17953,  ...,  1107,  1199,  2740],\n",
      "        [  101,  3245, 40680,  ...,   119,   177,   119],\n",
      "        [  101,  6898,  1161,  ..., 36431,  8043,  4626],\n",
      "        ...,\n",
      "        [  101, 29261, 10306,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 37521, 55658,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1716,  2445,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101, 24181, 29232,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9947,  1158,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101,  2841,  2445,  ...,  1128, 44077,  3798]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0]]), tensor([[  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ..., 57169,  7889, 32704]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,  1712,  1122,  1228],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,  1278,   117,  1934],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 35750,  1465,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1725,  1169,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0]]), tensor([[  101, 17291, 36647,  ...,   113, 30322, 20713],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,  1932, 13974,  1234],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 8805, 1399,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  178, 1138,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 31015,  4559,  ...,     0,     0,     0],\n",
      "        [  101, 36359, 31630,  ...,  6986,  1170,  1425],\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  7209,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 29346,  2149,  ...,  2812,  6059,  1137],\n",
      "        [  101, 12104, 24928,  ...,  1129,  1694,  1511],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 30560,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 10507,   113,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0]]), tensor([[  101,  3245, 40739,  ..., 29660,  4371,   114],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4107,  1164,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9077,  1105,  ...,  1152,  1145,  1494],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 18419,  2765,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 13316, 33391,  ...,     0,     0,     0],\n",
      "        [  101, 13316, 33391,  ..., 13782,  2225,   119],\n",
      "        [  101,  1662,  4777,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 46407,  4060,  ...,  1137, 48117,  6108],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0]]), tensor([[  101,  1301, 13523,  ...,   119,  1128,  1336],\n",
      "        [  101, 53685, 35810,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1139,  1401,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 36431,  5168,  ...,  1173,  9711,  1111],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,  1443,  3634,  1807],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,  1510,  1431,   178],\n",
      "        [  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1110,  ...,  1128,  1169,  1321],\n",
      "        [  101, 13316,  9028,  ...,  1103,  1378,   131],\n",
      "        [  101, 19245, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,  1106, 12434,  1103],\n",
      "        [  101,  4106,  6997,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0]]), tensor([[  101, 22214, 10507,  ...,  5199,   119,  1128],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35041, 42490,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1690,  1114,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  8856,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  3995,  1105, 46657],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,  5837, 17953,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0]]), tensor([[  101,  9304, 34581,  ...,  1240, 16212,   119],\n",
      "        [  101,  3196,  2841,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  1267,  1293,  1218],\n",
      "        ...,\n",
      "        [  101, 36344,  2042,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5557,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101,  1344, 47310,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]]), tensor([[  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 25506, 37041,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0]]), tensor([[  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,  1673,   113,  1185],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1674,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 6898, 1161,  ...,    0,    0,    0]]), tensor([[  101, 13306, 16042,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1114, 29123,  4759],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ..., 29660, 15243, 12633],\n",
      "        [  101,  6898,  1161,  ...,  1825,   119,   118]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 20968, 14051,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        [  101, 17972,   118,  ...,     0,     0,     0],\n",
      "        [  101, 44676,  4182,  ...,  1110,  1270, 45758]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 14837, 20673,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ..., 29056,   117,  1639],\n",
      "        [  101, 50352,  1733,  ...,  4607,  1105,  3843],\n",
      "        ...,\n",
      "        [  101,  4809,  1513,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1510,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 29193, 16838,  ..., 16838, 12736, 22992],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ..., 30177,   178,   118]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1132, 1175,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0],\n",
      "        [ 101, 4680, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 3252,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,  1404,   118,   170],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,   119,   170,  3112]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0]]), tensor([[  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 11552, 46789, 12571],\n",
      "        [  101, 29056,  4455,  ...,  1874, 20192,  1566]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0]]), tensor([[  101, 23123,  4184,  ...,     0,     0,     0],\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 26600, 58355,  ...,  2612,   119,  1372],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,  1128,  1132,  1253],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  3245, 40739,  ...,  5735, 12362,  1116],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  2218, 16565,   119],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 51541, 41482,  ..., 11478,  2217,  1110],\n",
      "        [  101,  1762,  2035,  ..., 30216,  6951,  1106]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,  1219,  1103, 12104],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 26707, 32304,  ...,  1162,  1114, 19035],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 24762,  6575,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4287,  1240,  ...,     0,     0,     0],\n",
      "        [  101, 10507, 11759,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1887,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1494, 1114,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,  5363,  1114,  1142],\n",
      "        [  101, 35929, 42193,  ...,  1110,  1126, 55496],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 14051, 16026,  ...,  1138,  1137,  1138]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 54074, 14196,  ...,     0,     0,     0],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0]]), tensor([[  101, 57481, 12602,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1202,   178,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        [  101,  1169,   178,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ..., 13753,   117,  1321],\n",
      "        [  101, 16320,  1116,  ...,     0,     0,     0],\n",
      "        [  101,  6730,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 11200,  1111,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,  3870,  1157,  3053],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,  1103,   118,  4073],\n",
      "        [  101, 32401,  5132,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 52549, 15355,  ...,     0,     0,     0],\n",
      "        [  101,  4267, 15284,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ..., 11009,  1201,   117],\n",
      "        [  101,  6307, 24662,  ...,  2241,  1112,  1936]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,     0,     0,     0]]), tensor([[  101, 41437,  1204,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,   113,  2824,  1103],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,  2645,  1235,  1103]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0]]), tensor([[  101, 24259, 23897,  ...,  1110,   175,  1810],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  1120,  1240, 19328],\n",
      "        ...,\n",
      "        [  101, 11536,  1106,  ...,  1296,  3420,   119],\n",
      "        [  101, 29156, 18208,  ...,  1431,  5427,  1107],\n",
      "        [  101,  3073, 10294,  ...,  1240,  1148, 10203]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 56401,  8840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 42193, 16071,  ...,  2218, 13558,  1107],\n",
      "        [  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,  1114, 35929, 42193],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  1105,  8006,   119]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 8006, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1129,  1694,  1106],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,   118,  3987,  1892],\n",
      "        [  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1184, 2774,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 9987,  ...,    0,    0,    0],\n",
      "        [ 101, 1165, 1105,  ...,    0,    0,    0]]), tensor([[  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6857,  1964,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101,   193,   118,  ...,  2747,  7459,  2975]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 4107, 1164,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1195, 1138,  ...,    0,    0,    0]]), tensor([[  101, 18419,  2765,  ..., 31033, 21180,   113],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1156, 8856,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10211,  1111,  ...,  1142,  2076,  1104],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101,  6857,  1964,  ...,  1104,  6857,  1964]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 51632,  1200,  ...,  4567,   117,  1134],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        [  101, 11019, 31086,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 41156, 11955,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  8204,  9987,  1127],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 46789, 12571,  ...,     0,     0,     0],\n",
      "        [  101, 29261, 10306,  ...,  1336,  1494,  3843],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23123,  4184,  ...,   119,  1164,   122],\n",
      "        [  101, 15355,   118,  ...,  8054,  1118,   131],\n",
      "        [  101, 26600, 32514,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 11111,  1825,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 13306,  1139,  ...,     0,     0,     0],\n",
      "        [  101, 14947,   118,  ...,     0,     0,     0]])]\n"
     ]
    }
   ],
   "source": [
    "for b in train_loader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [00:07<00:00, 51.2MB/s] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-277-251332b25f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mrepresentations_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu\n",
    "\n",
    "model_names = [\n",
    "    'bert-base-nli-stsb-mean-tokens',\n",
    "    'bert-large-nli-stsb-mean-tokens',\n",
    "    'roberta-base-nli-stsb-mean-tokens',\n",
    "    'roberta-large-nli-stsb-mean-tokens',\n",
    "    'distilbert-base-nli-stsb-mean-tokens'\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = SentenceTransformer(name)\n",
    "    model = model.to(cuda)\n",
    "\n",
    "    representations_a = []\n",
    "    representations_b = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sent_a, sent_b) in tqdm(test_sentences, desc='Embedding Sentences', ncols=800):\n",
    "            sentences_embeddings = model.encode([sent_a, sent_b])\n",
    "            representations_a.append(sentences_embeddings[0])\n",
    "            representations_b.append(sentences_embeddings[1])\n",
    "\n",
    "    obtained_scores = []\n",
    "    for idx, (repr_a, repr_b) in enumerate(zip(representations_a, representations_b)):\n",
    "        score = 1 - cosine(repr_a, repr_b)\n",
    "        obtained_scores.append(score)\n",
    "\n",
    "    corr_score = pearsonr(test_scores[:len(obtained_scores)], obtained_scores)[0]\n",
    "    print(f'{name}: {corr_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioELMo\n",
    "\n",
    "https://docs.allennlp.org/v1.0.0rc5/tutorials/how_to/elmo/\n",
    "\n",
    "https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp\n",
    "# ! pip install allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonre\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo\n",
    "# elmo = Elmo(\n",
    "#     options_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json', \n",
    "#     weight_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "#     num_output_representations=3,\n",
    "#     dropout=0\n",
    "    \n",
    "# )\n",
    "\n",
    "bioelmo = Elmo(\n",
    "    options_file='bioelmo/biomed_elmo_options.json', \n",
    "    weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "    num_output_representations=3,\n",
    "    dropout=0\n",
    ")\n",
    "bioelmo = bioelmo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  71, 106, 115, 116, 117, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 116, 102, 111, 117, 102, 111, 100, 102, 260, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  66, 111, 112, 117, 105, 102, 115, 260, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  74, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 117, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 100,  98, 115, 115, 112, 117, 260, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 103, 112, 115, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  99, 115, 102,  98, 108, 103,  98, 116, 117, 260, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [['First', 'sentence', '.'], ['Another', '.'], [\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"]]\n",
    "character_ids = batch_to_ids(sentences).to(device)\n",
    "embeddings = bioelmo(character_ids)\n",
    "character_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_embedding(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    sentences = [tokens]\n",
    "    character_ids = batch_to_ids(sentences).to(device)\n",
    "    return bioelmo(character_ids)['elmo_representations'][2].mean(dim=0).mean(dim=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1981, -0.2493,  0.1472,  ...,  0.0856,  0.0514,  0.0953],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['elmo_representations'][0].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0\n",
    "q = get_elmo_embedding(QA[K].question)\n",
    "ans = [get_elmo_embedding(a) for a in QA[K].answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n",
      "1 2 0.7145789861679077\n",
      "0 7 0.6949490308761597\n",
      "1 3 0.7414701581001282\n",
      "0 8 0.6276549696922302\n",
      "1 5 0.7520613670349121\n",
      "0 6 0.6759256720542908\n",
      "0 10 0.6990264654159546\n",
      "1 4 0.740582287311554\n",
      "0 9 0.6365541219711304\n",
      "1 1 0.7022466659545898\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach().cpu(), a.detach().cpu())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset2(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = batch_to_ids([nltk.word_tokenize(q)])\n",
    "            _a = batch_to_ids([nltk.word_tokenize(a)])\n",
    "            self.X.append([_q, _a])\n",
    "#         self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return self.X.shape[0]\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset2(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset2(X=sentences_test, y=labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model_bioELMo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model_bioELMo, self).__init__()\n",
    "        self.bioelmo = Elmo(\n",
    "            options_file='bioelmo/biomed_elmo_options.json', \n",
    "            weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "            num_output_representations=3,\n",
    "            dropout=0\n",
    "        )\n",
    "        for param in self.bioelmo.parameters():\n",
    "            param.requires_grad = False\n",
    "#         self.bioelmo = bioelmo.to(device)\n",
    "#         modules = [self.bert.embeddings, *self.bert.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "#         for module in modules:\n",
    "#             for param in module.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*1024, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        q_emb = self.get_elmo_embedding(q)\n",
    "        a_emb = self.get_elmo_embedding(a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([q_emb, a_emb], dim=0)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear2(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, q_emb, a_emb\n",
    "\n",
    "\n",
    "    def get_elmo_embedding(self, sentence):\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "#         sentences = [tokens]\n",
    "#         character_ids = batch_to_ids(sentence).to(device)\n",
    "        return self.bioelmo(sentence)['elmo_representations'][2].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioelmo_clf = MEDIQA_Model_bioELMo()\n",
    "bioelmo_clf = bioelmo_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,(q,a) in tqdm.tqdm(zip(test_dataset.y, test_dataset.X)):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(labels_test, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1699/1701 0.6242034435272217443.6841151714324951 0.10314517468214035 0.15529237687587738 0.339221715927124 0.3030651807785034 2.9525387287139893 0.07003825902938843 0.12832801043987274 0.043231889605522156 0.18832813203334808 0.21925053000450134 0.6420642733573914 0.7310922741889954 0.18545939028263092 0.1863744854927063 0.16231219470500946 0.4953307509422302 0.28373128175735474 0.9389384984970093 0.6665723919868469 0.5955307483673096 0.15899860858917236 2.0907347202301025 0.7578749060630798 0.32404041290283203 0.4283123314380646 0.012842393480241299 1.1186972856521606 0.896552562713623 0.5974249243736267 0.4825071096420288 1.257737159729004 1.2403526306152344 0.6301290988922119 0.6242996454238892 0.5066736340522766 0.9388933777809143 0.8013446927070618 0.7967394590377808 0.6420504450798035 0.2655837833881378 0.3406597971916199 0.14492468535900116 0.3025912940502167 0.260383665561676 1.2056822776794434 0.41638943552970886 0.6138029098510742 0.08509863913059235 0.4399171769618988 0.024819491431117058 0.03502781689167023 0.4880228638648987 1.0412309169769287 0.3329477310180664 0.22649303078651428 1.2098809480667114 0.15811429917812347 0.43458157777786255 0.730207085609436 0.4693262577056885 0.4107000231742859 0.698379635810852 0.8760024905204773 0.45869940519332886 0.221679225564003 1.146744966506958 1.154973030090332 0.6550112366676331 0.3216390907764435 0.33180177211761475 1.7560920715332031 0.5610791444778442 0.4339221715927124 0.26364490389823914\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.5052285194396973\n",
      "Epoch 1: 0.6197752810447701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [14:22,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5049683830171635   Test loss: 0.7481869661701842\n",
      "\n",
      "step 1699/1701 0.73201268911361693883803939163684845 0.2535375952720642 0.005680152215063572 0.7322623133659363 0.005709165707230568 0.14031632244586945 0.1676725298166275 0.31905126571655273 0.001588592422194779 0.18932464718818665 0.16674073040485382 0.5876138806343079 1.414900541305542 0.8171281814575195 0.7008195519447327 0.16309267282485962 0.005251583177596331 0.1256628781557083 0.17419327795505524 0.1211492270231247 0.4929419457912445 0.8375941514968872 0.5414513349533081 0.3195420205593109 0.36483561992645264 0.0961986854672432 1.7083277702331543 0.04774060100317001 0.05610094964504242 0.6481554508209229 0.20060551166534424 2.141049861907959 0.049198925495147705 0.8543755412101746 0.5185822248458862 0.5792037844657898 1.6116873025894165 0.2130742073059082 1.750300407409668 0.5993948578834534 0.4369775950908661 0.5291591882705688 0.8439643383026123 0.8684171438217163 0.08556673675775528 0.2070160061120987 0.22558994591236115 0.3709108829498291 0.6323883533477783 0.8384262919425964 0.7767566442489624 1.2156249284744263 0.38529860973358154 0.01274169236421585 0.007309682667255402 0.8531038761138916 0.007979854941368103 0.2976530194282532 0.25065043568611145 0.5564987659454346 0.42003297805786133 0.21601015329360962 0.21179507672786713 0.004666890017688274 1.9181480407714844 0.5739555954933167 0.27470463514328003 0.38199546933174133 0.21474403142929077 1.4198193550109863 0.5160959959030151 1.2276579141616821 0.3398893475532532 1.2368539571762085 0.4013151228427887 0.20861274003982544 1.6719040870666504 0.44780653715133667 0.5958219766616821 1.5143625736236572 1.0373551845550537 0.05680041387677193 0.14300502836704254\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.4131612777709961\n",
      "Epoch 2: 0.5681940983006284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [14:19,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5094850948509485   Test loss: 0.7940796232894721\n",
      "\n",
      "step 1699/1701 0.8380759358406067757433838814496994 0.20474161207675934 0.000975130416918546 0.000815664476249367 0.01943238079547882 0.2099863886833191 0.01936638355255127 0.30916452407836914 0.011323364451527596 0.02517712675035 0.4470158815383911 7.605842256452888e-05 0.24865788221359253 0.4572198688983917 0.4970248341560364 0.7310962080955505 0.12124039977788925 0.42268702387809753 0.00790607649832964 0.26384541392326355 0.5777623653411865 0.5268548727035522 0.33492106199264526 0.9274551272392273 0.3516268730163574 0.1708405762910843 0.14435730874538422 1.9499200582504272 0.020529532805085182 0.019156139343976974 0.659080982208252 0.2318136990070343 0.8155465126037598 0.6102678179740906 0.8245601058006287 1.7891318798065186 0.2461579591035843 1.4012855291366577 1.272321105003357 0.13465054333209991 0.6663691401481628 0.35019323229789734 0.813841700553894 0.516106367111206 0.2865593433380127 0.7561862468719482 0.16816936433315277 0.1434907168149948 0.6445662379264832 0.8457300662994385 1.07706880569458 0.34988442063331604 0.0019937350880354643 0.3445984423160553 0.3607177734375 0.5759868621826172 0.07740339636802673 0.6712338924407959 0.22437319159507751 0.6478711366653442 0.3163013756275177 0.32705578207969666 1.1363469362258911 0.5441790819168091 0.3570702075958252 0.19198726117610931 1.1864522695541382 1.1831603050231934 0.4234517514705658 0.2565663158893585 1.3532267808914185 0.3266199827194214 0.10087668150663376 0.430044025182724 0.8139938712120056 0.15936867892742157 0.6154060363769531\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.25598791241645813\n",
      "Epoch 3: 0.5302221145702745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [14:20,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5212285456187895   Test loss: 0.8184377863532302\n",
      "\n",
      "step 1699/1701 1.03695678710937573653140576124191284 0.15077844262123108 0.0021066786721348763 0.5832656621932983 0.0027586088981479406 0.0063565513119101524 0.2512713372707367 0.03608005493879318 0.5214544534683228 0.8031959533691406 0.8000285625457764 0.003688154509291053 0.05881792679429054 0.039273619651794434 2.7954969482379965e-05 0.20181451737880707 0.12534236907958984 0.39951056241989136 1.0081446170806885 0.24946968257427216 0.00014711508993059397 0.005400012247264385 0.1908811628818512 0.27221840620040894 0.09722517430782318 0.39951881766319275 0.8838584423065186 1.1623446941375732 0.055719226598739624 0.07205360382795334 0.04652765020728111 0.04683304578065872 0.057721927762031555 0.008508778177201748 0.36366936564445496 0.07042714953422546 0.27741557359695435 0.7455621361732483 0.4969443082809448 0.8214646577835083 1.7692699432373047 1.7003158330917358 2.095325231552124 0.8447962999343872 0.8388808965682983 0.8395260572433472 0.6860347390174866 0.08601368218660355 0.17805169522762299 0.19146603345870972 0.14942564070224762 0.16241399943828583 0.822380781173706 0.2508116662502289 0.0035204195883125067 0.0001063403396983631 0.0012980776373296976 1.025910496711731 0.00254627107642591 0.4939268231391907 0.4425644874572754 0.32726940512657166 0.11500068753957748 0.3626689314842224 0.036447614431381226 0.13190357387065887 0.0027591469697654247 0.06580720096826553 2.6539342403411865 0.3903229236602783 0.21513909101486206 0.878279447555542 0.08339902013540268 0.486747145652771 0.2658946216106415 0.9638837575912476 0.34868934750556946 0.8029428720474243 0.1485901176929474 1.1749887466430664 1.3383885622024536 0.6012588143348694 1.7795194387435913 0.6214747428894043 0.011633691377937794 0.4388696253299713 0.14359599351882935 0.18168999254703522 0.6334489583969116\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.11138967424631119\n",
      "Epoch 4: 0.49645983259108556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [14:16,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5176151761517616   Test loss: 0.9081658793955999\n",
      "\n",
      "step 1699/1701 1.0281440019607544462414856910705566406 0.002390378387644887 1.1336123943328857 1.8785548210144043 0.17211811244487762 0.004299691878259182 0.879508376121521 0.00012458146375138313 0.024692649021744728 2.342490006412845e-05 0.06829139590263367 0.382839173078537 0.764104962348938 1.2312592267990112 0.18441618978977203 0.002633340423926711 0.1101718619465828 0.06692344695329666 0.0887523740530014 0.21990302205085754 0.07510048151016235 0.4696975350379944 0.3453184962272644 1.1979376077651978 0.005217430181801319 0.008792376145720482 0.10548710823059082 0.1326049119234085 0.4274557828903198 0.007240816950798035 0.12064965069293976 2.9644882678985596 0.0009373645880259573 2.605417251586914 0.4727250337600708 0.2929639220237732 0.11404819786548615 0.6143626570701599 1.0052356719970703 0.9274531006813049 0.024733034893870354 0.283735454082489 1.47776460647583 1.0402839183807373 0.48319798707962036 0.265763521194458 0.05633411183953285 0.147469162940979 0.2947995662689209 0.5034106969833374 4.4168016756884754e-05 6.8666908191517e-05 0.2772708237171173 1.872316837310791 0.001112483674660325 0.2537362277507782 0.054653748869895935 0.47231417894363403 1.263291597366333 0.0007004806539043784 0.025899020954966545 2.6254780292510986 0.04442090541124344 0.7920216917991638 0.10868996381759644 0.8251396417617798 0.2422836273908615 0.27393653988838196 0.31139421463012695 0.051438502967357635 0.2975659966468811 0.49808552861213684 1.3539098501205444 0.09033755213022232 0.1556471437215805 1.2729464769363403 0.537194013595581 0.7329666614532471 0.1792750209569931 0.007873755879700184 0.14004600048065186\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.12534412741661072\n",
      "Epoch 5: 0.45982026245420327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1107it [14:19,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.5004516711833785   Test loss: 1.0611633258244801\n",
      "\n",
      "step 973/1701 0.44131830334663394785.2416839897632599 0.11987028270959854 0.0012083197943866253 0.6377884745597839 0.002576986560598016 0.0017440618248656392 2.0378544330596924 0.09156860411167145 0.0006418499397113919 1.2790082693099976 1.8477456933396752e-06 0.00014133259537629783 0.0003668742720037699 0.0037779556587338448 3.4420840740203857 1.1265341527177952e-05 0.10970580577850342 0.044317662715911865 0.4867549240589142 0.4117478132247925 0.61576730012893680.05575817450881004 1.0572940111160278 0.13079829514026642 0.009169107303023338 0.19202567636966705 0.1871742606163025 0.29898709058761597 0.031920865178108215 1.3410018682479858 0.2451186627149582 0.059857796877622604 0.026975370943546295 0.0495416484773159 0.003055826062336564 0.168474480509758 1.167762279510498 0.060407672077417374 0.29108867049217224 0.0076528810895979404 0.02884047105908394 0.42276743054389954 2.949871063232422 0.0009384981240145862 1.396744966506958 0.14233353734016418 0.3308504819869995 0.15998660027980804 1.1807923316955566\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-3ddbd201df7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#         x = torch.cat([q_e, a_e], dim=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#         print(y_true)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbioelmo_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-92887519cb04>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q, a)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         print(q.shape, a.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mq_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0ma_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m#         print('CLS:', CLS1.shape, CLS2.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-92887519cb04>\u001b[0m in \u001b[0;36mget_elmo_embedding\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#         sentences = [tokens]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#         character_ids = batch_to_ids(sentence).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbioelmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elmo_representations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# run the biLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mbilm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"activations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_embedding\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[0mlstm_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# Prepare the output.  The first layer is duplicated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         stacked_sequence_output, final_states, restoration_indices = self.sort_and_run_forward(\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         )\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[1;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36m_lstm_forward\u001b[1;34m(self, inputs, initial_state)\u001b[0m\n\u001b[0;32m    229\u001b[0m             )\n\u001b[0;32m    230\u001b[0m             backward_output_sequence, backward_state = backward_layer(\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mbackward_output_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             )\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# Skip connections, just adding the input to the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\lstm_cell_with_projection.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, batch_lengths, initial_state)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# Do the projections for all the gates all at once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;31m# Both have shape (batch_size, 4 * cell_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mprojected_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_linearity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mprojected_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_linearity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bioelmo_clf.parameters(), lr=1e-3)\n",
    "bioelmo_clf.train()\n",
    "EPOCHS = 100\n",
    "loss_func = nn.BCELoss()\n",
    "train_losses, test_losses, test_acc = [], [], []\n",
    "N = len(train_dataset.y)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    \n",
    "    for step_num, batch_data in enumerate(list(zip(train_dataset.y, train_dataset.X))):\n",
    "        y_true, (questions, answers) = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "#         q_e = bioelmo_clf.get_elmo_embedding(questions.to(device))\n",
    "#         a_e = bioelmo_clf.get_elmo_embedding(answers.to(device))\n",
    "#         print(q_e)\n",
    "#         print(a_e)\n",
    "#         x = torch.cat([q_e, a_e], dim=0)\n",
    "#         print(y_true)\n",
    "        logits, _, _ = bioelmo_clf(questions.to(device), answers.to(device))\n",
    "        y_true = torch.from_numpy(np.array([y_true], dtype=np.float32))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "        \n",
    "        bioelmo_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f'step {step_num}/{N}', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1}:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "#     acc = get_test_acc(bioelmo_clf)\n",
    "    acc, probs_labels, _ = get_test_acc(bioelmo_clf, return_probs_and_labels=True)\n",
    "    test_acc.append(acc)\n",
    "    test_loss = loss_func(torch.from_numpy(probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(acc)\n",
    "    print(f'Test acc:', acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_acc) > 5 and test_acc[-6] > max(test_acc[-5:]):\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
