{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **ACL-BioNLP'19 - MEDIQA 2019 Shared Task**\n",
    "Authors: Gonzalo Recio and Jana ReventÃ³s \n",
    "\n",
    "## Models \n",
    "\n",
    "Question object and Questions & Answer class:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xml.dom.minidom import parse, parseString\n",
    "from nltk import tokenize as tk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class Question(object):\n",
    "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
    "        self.question_id = q_id\n",
    "        self.question = q\n",
    "        self.answer_ids = a_ids\n",
    "        self.answers = a\n",
    "        self.reference_rank = r\n",
    "        self.system_rank = s\n",
    "        self.labels = l\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class QuestionsAndAnswers(list):\n",
    "    def __init__(self, dataset='Train'):\n",
    "        ''' dataset = {Train,Test,Validation} '''\n",
    "        list.__init__(self)\n",
    "        self.PATH = 'MEDIQA2019_datasets/MEDIQA_Task3_QA/'\n",
    "        p = self.read_dataset(dataset)\n",
    "        self.extend(self.read_dataset(dataset))\n",
    "        \n",
    "        self.references = [np.array(q.reference_rank) for q in self]\n",
    "        self.labels = [np.array(q.labels) for q in self]\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "        return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "    def get_answers(self, answers):\n",
    "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
    "        for answer in answers:\n",
    "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "            a_id = answer.getAttribute('AID')\n",
    "            reference = int(answer.getAttribute('ReferenceRank'))\n",
    "            system = int(answer.getAttribute('SystemRank'))\n",
    "            label = answer.getAttribute('ReferenceScore')\n",
    "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "        return answs, answs_ids, rank, chiqa, y\n",
    "    \n",
    "    def get_system_ranks(self):\n",
    "          return [q.system_rank for q in self]\n",
    "        \n",
    "    def get_reference_ranks(self):\n",
    "          return [q.reference_rank for q in self]\n",
    "        \n",
    "    def get_labels(self):\n",
    "          return [q.labels for q in self]\n",
    "\n",
    "    def read_dataset(self, dataset='Train'):\n",
    "        i = 0\n",
    "        indx2id = []\n",
    "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
    "        for filename in os.listdir(self.PATH):\n",
    "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
    "            tree = parse(self.PATH + filename)\n",
    "            questions = tree.getElementsByTagName('Question')\n",
    "            for question in questions:\n",
    "                qelem = question.getElementsByTagName('QuestionText')\n",
    "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "                # print(q) # --> questions\n",
    "                answers = question.getElementsByTagName('Answer')\n",
    "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
    "                QA.append([q,answers_list, rank, labels])\n",
    "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
    "                # QA2.append([q,answers_list, rank, system, labels])\n",
    "                QA2.append(question)\n",
    "                indx2id.append(q_id); i+=1;\n",
    "                # break\n",
    "        return QA2\n",
    "\n",
    "    def output_predictions(self, predictions, labels, file=''):\n",
    "        assert len(predictions) == len(self)\n",
    "        print('question_id,answer_id,label')\n",
    "        with open(f'task3/sample_submission_round_2_{file}.csv', mode='w') as csv_file:\n",
    "            for i, p in enumerate(predictions):\n",
    "                q_id = self[i].question_id\n",
    "                answers = self[i].answer_ids\n",
    "                assert len(p) == len(answers), f'{len(p)} != {len(answers)}'\n",
    "                # order = np.array(a)[np.argsort(p)]\n",
    "                p = self.normalize_sequence(p)\n",
    "                order = np.array(answers)[np.argsort(p)]\n",
    "                # order = np.array(answers)[np.array(p)-1]\n",
    "                lab = labels[i]\n",
    "                ordered_lab = np.array(lab)[np.argsort(p)]\n",
    "                if file == '':\n",
    "                    \n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        print(f\"{q_id},{a_id},{int(l)}\")\n",
    "                else:\n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        csv_file.write(f\"{q_id},{a_id},{int(l)}\\n\")\n",
    "            \n",
    "    def normalize_sequence(self, seq):\n",
    "        seq = np.array(seq)\n",
    "        a = np.argsort(seq)\n",
    "        seq[a] = list(range(1,len(seq)+1))\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        \n",
    "        '''\n",
    "        Compute accuracy incorrect answers (label values of 0) of the model predictions  \n",
    "        '''\n",
    "        \n",
    "        # Model predictions:\n",
    "        preds = np.concatenate(predictions)\n",
    "        # preds = np.concatenate(predictions==0)\n",
    "        # idx_preds_incorr_answ = [if predictions [i] == 0for i in range(len(pred))]\n",
    "        \n",
    "        # Ground truth labels:\n",
    "        true  = np.concatenate(self.labels) \n",
    "        #labels_true_incorrect_answ = [self.labels[index] for index in idx_preds_incorr_answ]\n",
    "        #true  = np.concatenate(labels_true_incorrect_answ) \n",
    "        \n",
    "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
    "        return accuracy_score(true, preds)\n",
    "\n",
    "    def precision(self, predictions):\n",
    "        '''\n",
    "        Number of correct ranked answers divided by the total number of retrieved answers for an specific question.\n",
    "        '''\n",
    "        precisions = []\n",
    "        num_answers = []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
    "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
    "            if len(p) == 0:\n",
    "                print(predictions[i])\n",
    "            correct = sum([a == b for a,b in zip(p, r)])\n",
    "            # for a,b in zip(p, r)\n",
    "            # num_answers.append(len(p))\n",
    "            precisions.append(correct/len(p))\n",
    "        return np.mean(precisions)\n",
    "        # return np.average(np.array(precisions), weights=num_answers)\n",
    "\n",
    "    def mean_spearmanr(self, predictions):\n",
    "        '''\n",
    "        Penalizes the differences (d) on predicted rank and true rank\n",
    "        '''\n",
    "        assert len(predictions) == len(self.references)\n",
    "        count, total = 0, 0\n",
    "        preds, refs = [], []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
    "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
    "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
    "            preds += p; refs += r\n",
    "            if len(r) == 1:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            elif len(r) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                total += 1\n",
    "                count += spearmanr(p, r)[0]\n",
    "        return spearmanr(preds, refs)[0]\n",
    "        # return count/total\n",
    "\n",
    "    def mean_reciprocal_rank(self, predicted):\n",
    "        '''\n",
    "        Evaluates any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness\n",
    "        '''\n",
    "        rs = []\n",
    "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
    "            res = np.array(a)[np.argsort(b)]\n",
    "            labels = self[k].labels\n",
    "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
    "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "QA = QuestionsAndAnswers(dataset = 'Train') \n",
    "QA_val = QuestionsAndAnswers(dataset = 'Validation')\n",
    "QA_test = QuestionsAndAnswers(dataset = 'Test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "system_ranks = QA_test.get_system_ranks()\n",
    "reference_ranks = [q.reference_rank for q in QA_test]\n",
    "labels = [q.labels for q in QA_test]\n",
    "system_labels = [np.ones(len(l)) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# QA.output_predictions(reference_ranks, labels)\n",
    "# QA.output_predictions(system_ranks, system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "question_id,answer_id,label\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "QA_test.output_predictions(system_ranks, system_labels, file='test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Testing Task (Round-2) : 3",
      "\nGround truth: task3/ground_truth_round_2.csv\nSubmission file: task3/sample_submission_round_2_test2.csv\n",
      "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import evaluator\n",
    "\n",
    "def evaluate(filename):\n",
    "    for task in [3]:\n",
    "        print(f\"Testing Task (Round-2) : {task}\")\n",
    "        answer_file_path = f\"task{task}/ground_truth_round_2.csv\"\n",
    "        _client_payload = {}\n",
    "        _client_payload[\"submission_file_path\"] = f\"task{task}/sample_submission_round_2_{filename}.csv\"\n",
    "\n",
    "        # Instaiate a dummy context\n",
    "        _context = {}\n",
    "        # Instantiate an evaluator\n",
    "        aicrowd_evaluator = evaluator.MediqaEvaluator(answer_file_path, task=task, round=2)\n",
    "        # Evaluate\n",
    "        result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "        print(result)\n",
    "\n",
    "evaluate('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline\n",
    "\n",
    "Testing Task (Round-2) : 3\n",
    "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, local_files_only)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;31m# File, but it doesn't exist.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file {} not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: file biobert/biobert_v1.1_pubmed/config.json not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0ce4d16166b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#                                   )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"biobert/biobert_v1.1_pubmed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             )\n\u001b[1;32m    605\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'biobert/biobert_v1.1_pubmed'. Make sure that:\n\n- 'biobert/biobert_v1.1_pubmed' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'biobert/biobert_v1.1_pubmed' is the correct path to a directory containing a config.json file\n\n"
     ],
     "ename": "OSError",
     "evalue": "Can't load config for 'biobert/biobert_v1.1_pubmed'. Make sure that:\n\n- 'biobert/biobert_v1.1_pubmed' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'biobert/biobert_v1.1_pubmed' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"biobert/biobert_v1.1_pubmed\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "\n",
    "# model = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
    "#                                   output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "#                                   )\n",
    "\n",
    "model = BertModel.from_pretrained(\"biobert/biobert_v1.1_pubmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_sentence_embedding(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        CLS = outputs[0][0]\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # print(len(hidden_states.shape))\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all n token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "\n",
    "    return sentence_embedding\n",
    "\n",
    "def get_CLS(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    CLS = outputs[0][:,0,:]\n",
    "    return CLS\n",
    "\n",
    "\n",
    "def get_full_sentence_embedding(sentence):\n",
    "    embeddings = []\n",
    "    e = 0\n",
    "    max_size = 1024#512\n",
    "    for i in range(int(len(sentence)/max_size)+1):\n",
    "#         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "#         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "        e = get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "#         print(e)\n",
    "        embeddings.append(e)\n",
    "    embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    print(embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f3183058258a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bert_sentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_full_sentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 512 is the maximum length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-8882d40a250d>\u001b[0m in \u001b[0;36mget_bert_sentence_embedding\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msegments_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegments_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Evaluating the model will return a different number of objects based on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "K = 7\n",
    "q = get_bert_sentence_embedding(QA[K].question)\n",
    "ans = [get_full_sentence_embedding(a) for a in QA[K].answers] # 512 is the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Label,Rank,Similarity\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-6071dcfb4c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label,Rank,Similarity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ans' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'ans' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach(), a.detach())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-35659ba5af06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmarked_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[CLS] \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" [SEP]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarked_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindexed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msegments_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'K' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "marked_text = \"[CLS] \" + QA[K].question + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text, add_special_tokens=True)\n",
    "print(tokenized_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "a = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "a[0][:,0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "# lr_clf = LogisticRegression()\n",
    "# lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val]) \n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] question \" + q + \" [SEP]\"))[:max_len_seq]\n",
    "            _q += [0]*(max_len_seq-len(_q))\n",
    "            _a = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] answer \" + a + \" [SEP]\"))[:max_len_seq]\n",
    "            _a += [0]*(max_len_seq-len(_a))\n",
    "            self.X.append([_q, _a])\n",
    "        self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create validation dataset\n",
    "val_dataset = MEDIQA_Dataset(X=sentences_val, y=labels_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset(X=sentences_test, y=labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# len(sentences)\n",
    "# max_len_seq = 0\n",
    "# lenghts = []\n",
    "# for q,a in sentences:\n",
    "#     lenghts.append(len(a))\n",
    "#     if len(a)>max_len_seq:\n",
    "#         max_len_seq = len(a)\n",
    "# max_len_seq\n",
    "# sorted(lenghts, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('biobert/biobert_v1.1_pubmed')\n",
    "        #self.bert = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-3]] #Replace 5 by what you want\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*self.bert.config.hidden_size, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "\n",
    "        CLS1 = self.get_CLS(q)\n",
    "#       q_vect = self.get_sentence_vectors(q)\n",
    "\n",
    "        CLS2 = self.get_CLS(a)\n",
    "#       a_vect = self.get_sentence_vectors(a)\n",
    "#       print('CLS:', CLS1.shape, CLS2.shape)\n",
    "#       print('Q vect:', q_vect.shape,a_vect.shape)\n",
    "        x = torch.cat([CLS1, CLS2], dim=1)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear2(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear3(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, CLS1, CLS2\n",
    "        #return prob, q_vect, a_vect\n",
    "\n",
    "\n",
    "\n",
    "    def get_CLS(self, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokeniEARLY_STOPPINGtext)\n",
    "#         segments_ids = [1] * len(indexed_tokens)\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = self.bert(tokens_tensor)\n",
    "        CLS = outputs[0][:,0,:]\n",
    "        return CLS\n",
    "    \n",
    "    def get_sentence_vectors(self, indexed_tokens):\n",
    "       \n",
    "        # Token tensor of the sentence       \n",
    "        tokens_tensor = indexed_tokens\n",
    "        \n",
    "        # Model\n",
    "        hidden_states = self.bert(tokens_tensor)\n",
    "        \n",
    "        # Token vectors from BERT\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "        \n",
    "        # Calculate the average of all token vectors.\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        #sentence_embedding.size()\n",
    "        return sentence_embedding\n",
    "    \n",
    "\n",
    "    def get_full_sentence_embedding(self, sentence):\n",
    "        embeddings = []\n",
    "        e = 0\n",
    "        max_size = 1024#512\n",
    "        for i in range(int(len(sentence)/max_size)+1):\n",
    "    #         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "    #         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "            e = self.get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "    #         print(e)\n",
    "            embeddings.append(e)\n",
    "        embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "        print(embedding)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# del bert_clf\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "702"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4426262b1a4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mmemory_allocated\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mdetails\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0mmanagement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \"\"\"\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_memoryAllocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/cuda/_utils.py\u001b[0m in \u001b[0;36m_get_device_index\u001b[0;34m(device, optional)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# default cuda device index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             raise ValueError('Expected a cuda device with a specified index '\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m             raise RuntimeError(\n\u001b[1;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ],
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error"
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f238ec95a233>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbert_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMEDIQA_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbert_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-223b68683b42>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMEDIQA_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biobert/biobert_v1.1_pubmed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#self.bert = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Replace 5 by what you want\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertModel' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'BertModel' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "bert_clf = MEDIQA_Model()\n",
    "bert_clf = bert_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# len(bert_clf.bert.encoder.layer)\n",
    "# bert_clf.bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, data_loader, true_labels, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,q,a in tqdm.tqdm(data_loader):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=8e-5)\n",
    "bert_clf.train()\n",
    "EPOCHS = 200\n",
    "EARLY_STOPPING = 3\n",
    "loss_func = nn.BCELoss()\n",
    "def ranking_loss(x1, x2, y):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        return 1-cos(a,b)\n",
    "    margin = torch.tensor(0.5, requires_grad=True).to(device)\n",
    "    loss = y*dist(x1,x2) + (1-y)*torch.max(torch.tensor(0.0, requires_grad=True).to(device), margin - dist(x1,x2))\n",
    "    return torch.mean(loss)\n",
    "train_losses, test_losses, val_losses, val_accs, test_accs = [], [], [], [], []\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    for step_num, batch_data in enumerate(train_loader):\n",
    "        y_true, questions, answers = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        if questions.shape != answers.shape: continue\n",
    "        logits, CLS1, CLS2 = bert_clf(questions.to(device), answers.to(device))\n",
    "        # logits, q_vec, a_vect = bert_clf(questions.to(device), answers.to(device))\n",
    "        # loss = loss_func(logits, y_true.to(device))\n",
    "        loss = 0.5*ranking_loss(CLS1, CLS2, y_true.to(device)) + 0.5*loss_func(logits, y_true.to(device))\n",
    "\n",
    "        \n",
    "        bert_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print('step', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    val_acc, val_probs_labels, _   = get_test_acc(bert_clf, val_loader,  labels_val,  return_probs_and_labels=True)\n",
    "    test_acc, test_probs_labels, _ = get_test_acc(bert_clf, test_loader, labels_test, return_probs_and_labels=True)\n",
    "    val_accs.append(val_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    val_loss  = loss_func(torch.from_numpy(val_probs_labels),  torch.from_numpy(np.array(labels_val, dtype=np.double))).item()\n",
    "    test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Val acc: ', val_acc, '   Val loss: ', val_loss)\n",
    "    print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_accs) <= 1 or test_acc > max(test_accs[:-1]):\n",
    "        torch.save(bert_clf.state_dict(), 'checkpoints/model')\n",
    "    if len(test_accs) > EARLY_STOPPING and test_accs[-(EARLY_STOPPING+1)] > max(test_accs[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model()\n",
    "        model.load_state_dict(torch.load('checkpoints/model'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_accs, label='test acc')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.plot(val_accs, label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('figures/biobert_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/mediqa_model_clinicalbert_finetune_0_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model = MEDIQA_Model()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "model = MEDIQA_Model()\n",
    "model.load_state_dict(torch.load('checkpoints/model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "acc, probs, y_pred = get_test_acc(model.to(device), test_loader, labels_test, return_probs_and_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_ranking_predictions(probs, y):\n",
    "    rankings  = []\n",
    "    entailed = []\n",
    "    i_start  = 0\n",
    "    for i, q in enumerate(QA_test):\n",
    "        rankings.append(1- np.array(probs[i_start:i_start+len(q.answers)]))\n",
    "        entailed.append(y[i_start:i_start+len(q.answers)])\n",
    "        i_start += len(q.answers)\n",
    "        assert len(rankings[i] == len(QA_test[i].answer_ids))\n",
    "        assert len(entailed[i] == len(QA_test[i].answers))\n",
    "    return rankings, entailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ranking_pred, labels_pred = get_ranking_predictions(probs, y_pred)\n",
    "QA_test.output_predictions(ranking_pred, labels_pred, file='test_biobert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluate('test_biobert2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "bert_clf.eval()\n",
    "pred_labels = []\n",
    "bert_clf.to(device)\n",
    "with torch.no_grad():\n",
    "    for s,q,a in tqdm.tqdm(test_loader):\n",
    "        logits = bert_clf(q.to(device),a.to(device))\n",
    "        pred_labels.extend(logits.to('cpu'))\n",
    "    pred_labels = np.array([x.item() for x in pred_labels])\n",
    "    pred = (pred_labels > 0.5).astype(np.int16)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "torch.cat([torch.tensor([1,2,3]), torch.tensor([1,2,3])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu\n",
    "\n",
    "model_names = [\n",
    "    'bert-base-nli-stsb-mean-tokens',\n",
    "    'bert-large-nli-stsb-mean-tokens',\n",
    "    'roberta-base-nli-stsb-mean-tokens',\n",
    "    'roberta-large-nli-stsb-mean-tokens',\n",
    "    'distilbert-base-nli-stsb-mean-tokens'\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = SentenceTransformer(name)\n",
    "    model = model.to(cuda)\n",
    "\n",
    "    representations_a = []\n",
    "    representations_b = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sent_a, sent_b) in tqdm(test_sentences, desc='Embedding Sentences', ncols=800):\n",
    "            sentences_embeddings = model.encode([sent_a, sent_b])\n",
    "            representations_a.append(sentences_embeddings[0])\n",
    "            representations_b.append(sentences_embeddings[1])\n",
    "\n",
    "    obtained_scores = []\n",
    "    for idx, (repr_a, repr_b) in enumerate(zip(representations_a, representations_b)):\n",
    "        score = 1 - cosine(repr_a, repr_b)\n",
    "        obtained_scores.append(score)\n",
    "\n",
    "    corr_score = pearsonr(test_scores[:len(obtained_scores)], obtained_scores)[0]\n",
    "    print(f'{name}: {corr_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioELMo\n",
    "\n",
    "In this section we will use BioELMo which is a biomedical version of embeddings from language model (ELMo), pre-trained on PubMed abstracts. \n",
    "Pre-training uses 10M recent PubMed abstracts (2.46B tokens in total), and BioELMo achieves an averaged forward and backward perplexity of 31.37 on a held-out test set. \n",
    "BioELMo encodes biomedical entity-type and relational information pretty well as shown in the paper [Probing Biomedical Embeddings from Language Models](https://arxiv.org/abs/1904.02181)\n",
    "\n",
    "BioELMo is used as the same way as ELMO. Source code:\n",
    "https://docs.allennlp.org/v1.0.0rc5/tutorials/how_to/elmo/\n",
    "https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "alabaster==0.7.12\r\nallennlp==1.3.0\r\nanaconda-client==1.7.2\r\nanaconda-navigator==1.10.0\r\nanaconda-project==0.8.3\r\napplaunchservices==0.2.1\r\nappnope @ file:///opt/concourse/worker/volumes/live/0291c9e1-4b15-459f-623e-2770f55be269/volume/appnope_1594338395037/work\r\nappscript @ file:///opt/concourse/worker/volumes/live/50ca4c96-3090-40bb-6981-3a6114ed0af4/volume/appscript_1594840187551/work\r\nargh==0.26.2\r\nargon2-cffi @ file:///opt/concourse/worker/volumes/live/59af29ac-4890-416e-7ab7-794f8d6f7ecd/volume/argon2-cffi_1596828548321/work\r\nasn1crypto @ file:///tmp/build/80754af9/asn1crypto_1596577642040/work\r\nastroid @ file:///opt/concourse/worker/volumes/live/21fd14a9-2a7e-484b-7394-5a9912cdcf80/volume/astroid_1592498459180/work\r\nastropy==4.0.2\r\nasync-generator==1.10\r\natomicwrites==1.4.0\r\nattrs @ file:///tmp/build/80754af9/attrs_1604765588209/work\r\nautopep8 @ file:///tmp/build/80754af9/autopep8_1596578164842/work\r\nBabel @ file:///tmp/build/80754af9/babel_1605108370292/work\r\nbackcall==0.2.0\r\nbackports.functools-lru-cache==1.6.1\r\nbackports.shutil-get-terminal-size==1.0.0\r\nbackports.tempfile==1.0\r\nbackports.weakref==1.0.post1\r\nbeautifulsoup4 @ file:///tmp/build/80754af9/beautifulsoup4_1601924105527/work\r\nbitarray @ file:///opt/concourse/worker/volumes/live/fdfca23e-4dd8-48f7-512d-c4f3db552eeb/volume/bitarray_1605065128338/work\r\nbkcharts==0.2\r\nbleach @ file:///tmp/build/80754af9/bleach_1600439572647/work\r\nblis==0.7.4\r\nbokeh @ file:///opt/concourse/worker/volumes/live/b2253281-9b72-4dcb-624e-e22924b50435/volume/bokeh_1603297849453/work\r\nboto==2.49.0\r\nboto3==1.16.47\r\nbotocore==1.19.47\r\nBottleneck==1.3.2\r\nbrotlipy==0.7.0\r\ncatalogue==1.0.0\r\ncertifi==2020.6.20\r\ncffi @ file:///opt/concourse/worker/volumes/live/b9607b09-b777-4ff7-53dc-287727eb8574/volume/cffi_1600699191154/work\r\nchardet==3.0.4\r\nclick==7.1.2\r\ncloudpickle @ file:///tmp/build/80754af9/cloudpickle_1598884132938/work\r\nclyent==1.2.2\r\ncolorama @ file:///tmp/build/80754af9/colorama_1603211150991/work\r\nconda==4.9.2\r\nconda-build==3.20.5\r\nconda-package-handling @ file:///opt/concourse/worker/volumes/live/a7e34989-4c54-4cb6-4156-4e58ee270730/volume/conda-package-handling_1603018121300/work\r\nconda-verify==3.4.2\r\ncontextlib2==0.6.0.post1\r\ncryptography @ file:///opt/concourse/worker/volumes/live/aeb63a26-659e-4edb-5405-74ba8e0c76f2/volume/cryptography_1601046839724/work\r\ncycler==0.10.0\r\ncymem==2.0.5\r\nCython @ file:///opt/concourse/worker/volumes/live/6158b663-a4ca-4e19-7e05-8807e4f79146/volume/cython_1594835048880/work\r\ncytoolz==0.11.0\r\ndask @ file:///tmp/build/80754af9/dask-core_1602083700509/work\r\ndecorator==4.4.2\r\ndefusedxml==0.6.0\r\ndiff-match-patch @ file:///tmp/build/80754af9/diff-match-patch_1594828741838/work\r\ndistributed @ file:///opt/concourse/worker/volumes/live/bd66aa48-5cf5-4b60-6ed4-f204fff153f6/volume/distributed_1605066538557/work\r\ndocutils==0.16\r\nentrypoints==0.3\r\net-xmlfile==1.0.1\r\nfastcache==1.1.0\r\nfilelock==3.0.12\r\nflake8 @ file:///tmp/build/80754af9/flake8_1601911421857/work\r\nFlask==1.1.2\r\nfsspec @ file:///tmp/build/80754af9/fsspec_1602684995936/work\r\nfuture==0.18.2\r\ngevent @ file:///opt/concourse/worker/volumes/live/e6b243ce-c4b8-40bb-4934-ef3bf1c512f2/volume/gevent_1601397552921/work\r\nglob2==0.7\r\ngmpy2==2.0.8\r\ngreenlet @ file:///opt/concourse/worker/volumes/live/02d5d57d-1f11-4cf9-580a-19e679c78dc9/volume/greenlet_1600874049903/work\r\nh5py==2.10.0\r\nHeapDict==1.0.1\r\nhtml5lib @ file:///tmp/build/80754af9/html5lib_1593446221756/work\r\nidna @ file:///tmp/build/80754af9/idna_1593446292537/work\r\nimageio @ file:///tmp/build/80754af9/imageio_1594161405741/work\r\nimagesize==1.2.0\r\nimportlib-metadata @ file:///tmp/build/80754af9/importlib-metadata_1602276842396/work\r\niniconfig @ file:///tmp/build/80754af9/iniconfig_1602780191262/work\r\nintervaltree @ file:///tmp/build/80754af9/intervaltree_1598376443606/work\r\nipykernel @ file:///opt/concourse/worker/volumes/live/88f541d3-5a27-498f-7391-f2e50ca36560/volume/ipykernel_1596206680118/work/dist/ipykernel-5.3.4-py3-none-any.whl\r\nipython @ file:///opt/concourse/worker/volumes/live/26969e8f-c9f7-42dc-6ffb-b3effd424c49/volume/ipython_1604101242376/work\r\nipython-genutils==0.2.0\r\nipywidgets @ file:///tmp/build/80754af9/ipywidgets_1601490159889/work\r\nisort @ file:///tmp/build/80754af9/isort_1602603989581/work\r\nitsdangerous==1.1.0\r\njdcal==1.4.1\r\njedi @ file:///opt/concourse/worker/volumes/live/1c5c293b-9147-4b4b-5a7f-d3f5eddb8470/volume/jedi_1592841952519/work\r\nJinja2==2.11.2\r\njmespath==0.10.0\r\njoblib @ file:///tmp/build/80754af9/joblib_1601912903842/work\r\njson5==0.9.5\r\njsonnet==0.17.0\r\njsonpickle==1.4.2\r\njsonschema @ file:///tmp/build/80754af9/jsonschema_1602607155483/work\r\njupyter==1.0.0\r\njupyter-client @ file:///tmp/build/80754af9/jupyter_client_1601311786391/work\r\njupyter-console @ file:///tmp/build/80754af9/jupyter_console_1598884538475/work\r\njupyter-core==4.6.3\r\njupyterlab==2.2.6\r\njupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\r\njupyterlab-server @ file:///tmp/build/80754af9/jupyterlab_server_1594164409481/work\r\nkeyring @ file:///opt/concourse/worker/volumes/live/54fc3ec2-338b-44f5-5e13-d62afa6b5820/volume/keyring_1601490916376/work\r\nkiwisolver @ file:///opt/concourse/worker/volumes/live/b8936fa6-0e4b-47e7-4fb4-e02dbd4505ee/volume/kiwisolver_1604014598721/work\r\nlazy-object-proxy==1.4.3\r\nlibarchive-c==2.9\r\nllvmlite==0.34.0\r\nlocket==0.2.0\r\nlxml @ file:///opt/concourse/worker/volumes/live/9351a723-931c-40fa-7baa-f2f468cdccf6/volume/lxml_1603216287330/work\r\nMarkupSafe @ file:///opt/concourse/worker/volumes/live/cb778296-98db-45ad-411e-6f726e102dc3/volume/markupsafe_1594371638608/work\r\nmatplotlib @ file:///opt/concourse/worker/volumes/live/f7797860-f8aa-410c-4a56-72315954816b/volume/matplotlib-base_1603378002957/work\r\nmccabe==0.6.1\r\nmistune @ file:///opt/concourse/worker/volumes/live/95802d64-d39c-491b-74ce-b9326880ca54/volume/mistune_1594373201816/work\r\nmkl-fft==1.2.0\r\nmkl-random==1.1.1\r\nmkl-service==2.3.0\r\nmock==4.0.2\r\nmore-itertools @ file:///tmp/build/80754af9/more-itertools_1605111547926/work\r\nmpmath==1.1.0\r\nmsgpack==1.0.0\r\nmultipledispatch==0.6.0\r\nmurmurhash==1.0.5\r\nnavigator-updater==0.2.1\r\nnbclient @ file:///tmp/build/80754af9/nbclient_1602783176460/work\r\nnbconvert @ file:///opt/concourse/worker/volumes/live/2b9c1d93-d0fd-432f-7d93-66c93d81b614/volume/nbconvert_1601914875037/work\r\nnbformat @ file:///tmp/build/80754af9/nbformat_1602783287752/work\r\nnest-asyncio @ file:///tmp/build/80754af9/nest-asyncio_1605115881283/work\r\nnetworkx @ file:///tmp/build/80754af9/networkx_1598376031484/work\r\nnltk @ file:///tmp/build/80754af9/nltk_1592496090529/work\r\nnose @ file:///opt/concourse/worker/volumes/live/a029938e-1732-4cd8-5b98-0542283d158b/volume/nose_1594377915100/work\r\nnotebook @ file:///opt/concourse/worker/volumes/live/be0f3504-189d-4bae-4e57-c5d6da73ffcd/volume/notebook_1601501605350/work\r\nnumba @ file:///opt/concourse/worker/volumes/live/ae24c1ca-d916-4043-5919-a843fa33e451/volume/numba_1600084276085/work\r\nnumexpr==2.7.1\r\nnumpy @ file:///opt/concourse/worker/volumes/live/5572694e-967a-4c0c-52cf-b53d43e72de9/volume/numpy_and_numpy_base_1603491881791/work\r\nnumpydoc @ file:///tmp/build/80754af9/numpydoc_1605117425582/work\r\nolefile==0.46\r\nopenpyxl @ file:///tmp/build/80754af9/openpyxl_1598113097404/work\r\noverrides==3.1.0\r\npackaging==20.4\r\npandas @ file:///opt/concourse/worker/volumes/live/f14cf8c4-c564-4eff-4b17-158e90dbf88a/volume/pandas_1602088128240/work\r\npandocfilters @ file:///opt/concourse/worker/volumes/live/c330e404-216d-466b-5327-8ce8fe854d3a/volume/pandocfilters_1605120442288/work\r\nparso==0.7.0\r\npartd==1.1.0\r\npath @ file:///opt/concourse/worker/volumes/live/fcdf620c-46d6-4284-4c1e-5b8c3bc6c5c6/volume/path_1596907417277/work\r\npathlib2 @ file:///opt/concourse/worker/volumes/live/de518564-0d9f-405e-472b-38136f0c2169/volume/pathlib2_1594381084269/work\r\npathtools==0.1.2\r\npatsy==0.5.1\r\npep8==1.7.1\r\npexpect @ file:///opt/concourse/worker/volumes/live/8701bb20-ad87-46c7-5108-30c178cf97e5/volume/pexpect_1594383388344/work\r\npickleshare @ file:///opt/concourse/worker/volumes/live/93ec39d8-05bb-4f84-7efc-98735bc39b70/volume/pickleshare_1594384101884/work\r\nPillow @ file:///opt/concourse/worker/volumes/live/991b9a87-3372-4acd-45f9-eaa52701f03c/volume/pillow_1603822262543/work\r\npkginfo==1.6.1\r\nplac==1.1.3\r\npluggy==0.13.1\r\nply==3.11\r\npreshed==3.0.5\r\nprometheus-client==0.8.0\r\nprompt-toolkit @ file:///tmp/build/80754af9/prompt-toolkit_1602688806899/work\r\nprotobuf==3.14.0\r\npsutil @ file:///opt/concourse/worker/volumes/live/ff72f822-991c-4030-4f3a-8c41d3ac4e4f/volume/psutil_1598370232375/work\r\nptyprocess==0.6.0\r\npy @ file:///tmp/build/80754af9/py_1593446248552/work\r\npycodestyle==2.6.0\r\npycosat==0.6.3\r\npycparser @ file:///tmp/build/80754af9/pycparser_1594388511720/work\r\npycurl==7.43.0.6\r\npydocstyle @ file:///tmp/build/80754af9/pydocstyle_1598885001695/work\r\npyflakes==2.2.0\r\r\nPygments @ file:///tmp/build/80754af9/pygments_1604103097372/work\r\npylint @ file:///opt/concourse/worker/volumes/live/ed0164b6-bcc7-4f6b-7dd4-ad89660b5dcb/volume/pylint_1598624018129/work\r\npyodbc===4.0.0-unsupported\r\npyOpenSSL @ file:///tmp/build/80754af9/pyopenssl_1594392929924/work\r\npyparsing==2.4.7\r\npyrsistent @ file:///opt/concourse/worker/volumes/live/ff11f3f0-615b-4508-471d-4d9f19fa6657/volume/pyrsistent_1600141727281/work\r\nPySocks @ file:///opt/concourse/worker/volumes/live/85a5b906-0e08-41d9-6f59-084cee4e9492/volume/pysocks_1594394636991/work\r\npytest==0.0.0\r\npython-dateutil==2.8.1\r\npython-jsonrpc-server @ file:///tmp/build/80754af9/python-jsonrpc-server_1600278539111/work\r\npython-language-server @ file:///tmp/build/80754af9/python-language-server_1600454544709/work\r\npytz==2020.1\r\nPyWavelets @ file:///opt/concourse/worker/volumes/live/ea36e10f-66e8-43ae-511e-c4092764493f/volume/pywavelets_1601658378672/work\r\nPyYAML==5.3.1\r\npyzmq==19.0.2\r\nQDarkStyle==2.8.1\r\nQtAwesome @ file:///tmp/build/80754af9/qtawesome_1602272867890/work\r\nqtconsole @ file:///tmp/build/80754af9/qtconsole_1600870028330/work\r\nQtPy==1.9.0\r\nregex @ file:///opt/concourse/worker/volumes/live/7f106f75-0e11-45be-4c20-6b071e37c646/volume/regex_1602786678165/work\r\nrequests @ file:///tmp/build/80754af9/requests_1592841827918/work\r\nrope @ file:///tmp/build/80754af9/rope_1602264064449/work\r\nRtree==0.9.4\r\nruamel-yaml==0.15.87\r\ns3transfer==0.3.3\r\nsacremoses==0.0.43\r\nscikit-image==0.17.2\r\nscikit-learn @ file:///opt/concourse/worker/volumes/live/111833a2-339b-4578-413b-7337bb8fe64a/volume/scikit-learn_1598376920601/work\r\nscipy @ file:///opt/concourse/worker/volumes/live/851446f6-a052-41c4-4243-67bb78999b49/volume/scipy_1604596178167/work\r\nseaborn @ file:///tmp/build/80754af9/seaborn_1600553570093/work\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.94\r\nsimplegeneric==0.8.1\r\nsingledispatch @ file:///tmp/build/80754af9/singledispatch_1602523705405/work\r\nsix @ file:///opt/concourse/worker/volumes/live/5b31cb27-1e37-4ca5-6e9f-86246eb206d2/volume/six_1605205320872/work\r\nsnowballstemmer==2.0.0\r\nsortedcollections==1.2.1\r\nsortedcontainers==2.2.2\r\nsoupsieve==2.0.1\r\nspacy==2.3.5\r\nSphinx @ file:///tmp/build/80754af9/sphinx_1597428793432/work\r\nsphinxcontrib-applehelp==1.0.2\r\nsphinxcontrib-devhelp==1.0.2\r\nsphinxcontrib-htmlhelp==1.0.3\r\nsphinxcontrib-jsmath==1.0.1\r\nsphinxcontrib-qthelp==1.0.3\r\nsphinxcontrib-serializinghtml==1.1.4\r\nsphinxcontrib-websupport @ file:///tmp/build/80754af9/sphinxcontrib-websupport_1597081412696/work\r\nspyder @ file:///opt/concourse/worker/volumes/live/93f52c11-6bc0-49a8-541e-aa5e1de1eadc/volume/spyder_1599056974853/work\r\nspyder-kernels @ file:///opt/concourse/worker/volumes/live/b4ec5b57-5b3c-42d0-7731-c0691f88ee81/volume/spyder-kernels_1599056790993/work\r\nSQLAlchemy @ file:///opt/concourse/worker/volumes/live/0214475e-3c0a-49a9-6cb8-ab2d5c945bef/volume/sqlalchemy_1603812264100/work\r\nsrsly==1.0.5\r\nstatsmodels @ file:///opt/concourse/worker/volumes/live/148a0e6d-2163-4103-6ef5-61556693c052/volume/statsmodels_1602280229372/work\r\nsympy @ file:///opt/concourse/worker/volumes/live/d5d0b33b-5c2f-493b-5b67-8149e5531868/volume/sympy_1605119535834/work\r\ntables==3.6.1\r\ntblib @ file:///tmp/build/80754af9/tblib_1597928476713/work\r\ntensorboardX==2.1\r\nterminado==0.9.1\r\ntestpath==0.4.4\r\nthinc==7.4.5\r\nthreadpoolctl @ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl\r\ntifffile==2020.10.1\r\ntokenizers==0.9.4\r\ntoml @ file:///tmp/build/80754af9/toml_1592853716807/work\r\ntoolz @ file:///tmp/build/80754af9/toolz_1601054250827/work\r\ntorch==1.7.1\r\ntornado==6.0.4\r\ntqdm @ file:///tmp/build/80754af9/tqdm_1602185206534/work\r\ntraitlets @ file:///tmp/build/80754af9/traitlets_1602787416690/work\r\ntransformers==4.0.1\r\ntyping-extensions @ file:///tmp/build/80754af9/typing_extensions_1598376058250/work\r\nujson @ file:///opt/concourse/worker/volumes/live/2fc9988c-ebca-4577-6c4b-7383ea76e8ee/volume/ujson_1602523306974/work\r\nunicodecsv==0.14.1\r\nurllib3 @ file:///tmp/build/80754af9/urllib3_1603305693037/work\r\nwasabi==0.8.0\r\nwatchdog @ file:///opt/concourse/worker/volumes/live/cc0ee7bb-1065-44c4-5867-0fd5d13729e0/volume/watchdog_1593447373245/work\r\nwcwidth @ file:///tmp/build/80754af9/wcwidth_1593447189090/work\r\nwebencodings==0.5.1\r\nWerkzeug==1.0.1\r\nwidgetsnbextension==3.5.1\r\nwrapt==1.11.2\r\nwurlitzer @ file:///opt/concourse/worker/volumes/live/01a17f3d-eafe-4806-57a1-4b9ef5d1815f/volume/wurlitzer_1594753845129/work\r\nxlrd==1.2.0\r\nXlsxWriter @ file:///tmp/build/80754af9/xlsxwriter_1602692860603/work\r\nxlwings==0.20.8\r\nxlwt==1.3.0\r\nxmltodict==0.12.0\r\nyapf @ file:///tmp/build/80754af9/yapf_1593528177422/work\r\nzict==2.0.0\r\nzipp @ file:///tmp/build/80754af9/zipp_1604001098328/work\r\nzope.event==4.5.0\r\nzope.interface @ file:///opt/concourse/worker/volumes/live/de428e3b-00ba-4161-442e-b9e5d25e4219/volume/zope.interface_1602002489816/work\r\n",
      "\u001b[33mWARNING: Skipping dataclasses as it is not installed.\u001b[0m\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! pip freeze grep dataclasses\n",
    "! pip uninstall -y dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Requirement already up-to-date: allennlp in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (1.3.0)\r\nRequirement already satisfied, skipping upgrade: numpy in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (1.19.2)\r\nRequirement already satisfied, skipping upgrade: sentencepiece in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (0.1.94)\r\nRequirement already satisfied, skipping upgrade: nltk in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (3.5)\r\n",
      "Requirement already satisfied, skipping upgrade: overrides==3.1.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (3.1.0)\r\nRequirement already satisfied, skipping upgrade: h5py in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (2.10.0)\r\nRequirement already satisfied, skipping upgrade: requests>=2.18 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (2.24.0)\r\nRequirement already satisfied, skipping upgrade: jsonpickle in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (1.4.2)\r\n",
      "Requirement already satisfied, skipping upgrade: filelock<3.1,>=3.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (3.0.12)\r\nRequirement already satisfied, skipping upgrade: torch<1.8.0,>=1.6.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (1.7.1)\r\nRequirement already satisfied, skipping upgrade: scipy in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (1.5.2)\r\nRequirement already satisfied, skipping upgrade: tqdm>=4.19 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (4.50.2)\r\nRequirement already satisfied, skipping upgrade: transformers<4.1,>=4.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (4.0.1)\r\n",
      "Requirement already satisfied, skipping upgrade: tensorboardX>=1.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (2.1)\r\nRequirement already satisfied, skipping upgrade: jsonnet>=0.10.0; sys_platform != \"win32\" in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (0.17.0)\r\nRequirement already satisfied, skipping upgrade: pytest in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (0.0.0)\r\nRequirement already satisfied, skipping upgrade: spacy<2.4,>=2.1.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (2.3.5)\r\n",
      "Requirement already satisfied, skipping upgrade: boto3<2.0,>=1.14 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (1.16.47)\r\nRequirement already satisfied, skipping upgrade: scikit-learn in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from allennlp) (0.23.2)\r\nRequirement already satisfied, skipping upgrade: regex in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from nltk->allennlp) (2020.10.15)\r\nRequirement already satisfied, skipping upgrade: click in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from nltk->allennlp) (7.1.2)\r\nRequirement already satisfied, skipping upgrade: joblib in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from nltk->allennlp) (0.17.0)\r\nRequirement already satisfied, skipping upgrade: six in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from h5py->allennlp) (1.15.0)\r\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18->allennlp) (1.25.11)\r\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18->allennlp) (2.10)\r\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18->allennlp) (2020.6.20)\r\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.18->allennlp) (3.0.4)\r\nRequirement already satisfied, skipping upgrade: typing-extensions in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from torch<1.8.0,>=1.6.0->allennlp) (3.7.4.3)\r\nRequirement already satisfied, skipping upgrade: tokenizers==0.9.4 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from transformers<4.1,>=4.0->allennlp) (0.9.4)\r\nRequirement already satisfied, skipping upgrade: packaging in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from transformers<4.1,>=4.0->allennlp) (20.4)\r\nRequirement already satisfied, skipping upgrade: sacremoses in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from transformers<4.1,>=4.0->allennlp) (0.0.43)\r\nRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from tensorboardX>=1.2->allennlp) (3.14.0)\r\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from pytest->allennlp) (20.3.0)\r\nRequirement already satisfied, skipping upgrade: iniconfig in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from pytest->allennlp) (1.1.1)\r\nRequirement already satisfied, skipping upgrade: pluggy<1.0,>=0.12 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from pytest->allennlp) (0.13.1)\r\n",
      "Requirement already satisfied, skipping upgrade: py>=1.8.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from pytest->allennlp) (1.9.0)\r\nRequirement already satisfied, skipping upgrade: toml in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from pytest->allennlp) (0.10.1)\r\nRequirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\r\nRequirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (1.1.3)\r\nRequirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.0)\r\nRequirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (0.7.4)\r\nRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (0.8.0)\r\nRequirement already satisfied, skipping upgrade: thinc<7.5.0,>=7.4.1 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (7.4.5)\r\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (2.0.5)\r\nRequirement already satisfied, skipping upgrade: setuptools in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (50.3.1.post20201107)\r\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (3.0.5)\r\nRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.5)\r\nRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.14->allennlp) (0.10.0)\r\nRequirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.14->allennlp) (0.3.3)\r\nRequirement already satisfied, skipping upgrade: botocore<1.20.0,>=1.19.47 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from boto3<2.0,>=1.14->allennlp) (1.19.47)\r\nRequirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->allennlp) (2.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers<4.1,>=4.0->allennlp) (2.4.7)\r\nRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /Users/jreventos/opt/anaconda3/lib/python3.8/site-packages (from botocore<1.20.0,>=1.19.47->boto3<2.0,>=1.14->allennlp) (2.8.1)\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "! pip install allennlp --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "3.7.4 (v3.7.4:e09359112e, Jul  8 2019, 14:54:52) \n[Clang 6.0 (clang-600.0.57)]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f52c9f2cc7d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MAI/Semester 3/HLE/MAI-HLE/allennlp/allennlp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVERSION\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp.version'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp.version'",
     "output_type": "error"
    }
   ],
   "source": [
    "import torch\n",
    "from allennlp.allennlp.modules.elmo import Elmo, batch_to_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9b4ce26d8719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# elmo = Elmo(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     options_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     weight_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     num_output_representations=3,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp.modules'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp.modules'",
     "output_type": "error"
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo\n",
    "# elmo = Elmo(\n",
    "#     options_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json', \n",
    "#     weight_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "#     num_output_representations=3,\n",
    "#     dropout=0\n",
    "    \n",
    "# )\n",
    "\n",
    "bioelmo = Elmo(\n",
    "    options_file='bioelmo/biomed_elmo_options.json', \n",
    "    weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "    num_output_representations=3,\n",
    "    dropout=0\n",
    ")\n",
    "bioelmo = bioelmo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sentences = [['First', 'sentence', '.'], ['Another', '.'], [\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"]]\n",
    "character_ids = batch_to_ids(sentences).to(device)\n",
    "embeddings = bioelmo(character_ids)\n",
    "character_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_elmo_embedding(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    sentences = [tokens]\n",
    "    character_ids = batch_to_ids(sentences).to(device)\n",
    "    return bioelmo(character_ids)['elmo_representations'][2].mean(dim=0).mean(dim=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "embeddings['elmo_representations'][0].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "K = 0\n",
    "q = get_elmo_embedding(QA[K].question)\n",
    "ans = [get_elmo_embedding(a) for a in QA[K].answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach().cpu(), a.detach().cpu())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "QA[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset2(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = batch_to_ids([nltk.word_tokenize(q)])\n",
    "            _a = batch_to_ids([nltk.word_tokenize(a)])\n",
    "            self.X.append([_q, _a])\n",
    "#         self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return self.X.shape[0]\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset2(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create train dataset\n",
    "val_dataset = MEDIQA_Dataset2(X=sentences_val, y=labels_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset2(X=sentences_test, y=labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model_bioELMo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model_bioELMo, self).__init__()\n",
    "        self.bioelmo = Elmo(\n",
    "            options_file='bioelmo/biomed_elmo_options.json', \n",
    "            weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "            num_output_representations=3,\n",
    "            dropout=0\n",
    "        )\n",
    "        for param in self.bioelmo.parameters():\n",
    "            param.requires_grad = False\n",
    "#         self.bioelmo = bioelmo.to(device)\n",
    "#         modules = [self.bert.embeddings, *self.bert.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "#         for module in modules:\n",
    "#             for param in module.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*1024, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        q_emb = self.get_elmo_embedding(q)\n",
    "        a_emb = self.get_elmo_embedding(a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([q_emb, a_emb], dim=0)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear2(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, q_emb, a_emb\n",
    "\n",
    "\n",
    "    def get_elmo_embedding(self, sentence):\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "#         sentences = [tokens]\n",
    "#         character_ids = batch_to_ids(sentence).to(device)\n",
    "        return self.bioelmo(sentence)['elmo_representations'][2].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "bioelmo_clf = MEDIQA_Model_bioELMo()\n",
    "bioelmo_clf = bioelmo_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,(q,a) in tqdm.tqdm(zip(test_dataset.y, test_dataset.X)):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(labels_test, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bioelmo_clf.parameters(), lr=1e-3)\n",
    "bioelmo_clf.train()\n",
    "EPOCHS = 100\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "train_losses, test_losses, test_acc = [], [], []\n",
    "N = len(train_dataset.y)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    \n",
    "    for step_num, batch_data in enumerate(list(zip(train_dataset.y, train_dataset.X))):\n",
    "        y_true, (questions, answers) = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        logits, CLS1, CLS2 = bioelmo_clf(questions.to(device), answers.to(device))\n",
    "        y_true = torch.from_numpy(np.array([y_true], dtype=np.float32))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "        \n",
    "        bioelmo_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f'step {step_num}/{N}', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1}:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "#     acc = get_test_acc(bioelmo_clf)\n",
    "    acc, probs_labels, _ = get_test_acc(bioelmo_clf, return_probs_and_labels=True)\n",
    "    test_acc.append(acc)\n",
    "    test_loss = loss_func(torch.from_numpy(probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(acc)\n",
    "    print(f'Test acc:', acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_acc) > 5 and test_acc[-6] > max(test_acc[-5:]):\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}