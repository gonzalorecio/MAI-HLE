{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xml.dom.minidom import parse, parseString\n",
    "from nltk import tokenize as tk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class Question(object):\n",
    "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
    "        self.question_id = q_id\n",
    "        self.question = q\n",
    "        self.answer_ids = a_ids\n",
    "        self.answers = a\n",
    "        self.reference_rank = r\n",
    "        self.system_rank = s\n",
    "        self.labels = l\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class QuestionsAndAnswers(list):\n",
    "    def __init__(self, dataset='Train', load_external_data=False):\n",
    "        ''' dataset = {Train,Test,Validation} '''\n",
    "        list.__init__(self)\n",
    "        self.PATH = 'MEDIQA2019_datasets/MEDIQA_Task3_QA/'\n",
    "        p = self.read_dataset(dataset)\n",
    "        self.extend(self.read_dataset(dataset))\n",
    "        if load_external_data:\n",
    "            self.extend(self.read_external_dataset())\n",
    "        \n",
    "        self.references = [np.array(q.reference_rank) for q in self]\n",
    "        self.labels = [np.array(q.labels) for q in self]\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "        return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "    def get_answers(self, answers):\n",
    "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
    "        for answer in answers:\n",
    "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "            a_id = answer.getAttribute('AID')\n",
    "            reference = int(answer.getAttribute('ReferenceRank'))\n",
    "            system = int(answer.getAttribute('SystemRank'))\n",
    "            label = answer.getAttribute('ReferenceScore')\n",
    "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "        return answs, answs_ids, rank, chiqa, y\n",
    "    \n",
    "    def get_system_ranks(self):\n",
    "          return [q.system_rank for q in self]\n",
    "        \n",
    "    def get_reference_ranks(self):\n",
    "          return [q.reference_rank for q in self]\n",
    "        \n",
    "    def get_labels(self):\n",
    "          return [q.labels for q in self]\n",
    "\n",
    "    def read_dataset(self, dataset='Train'):\n",
    "        i = 0\n",
    "        indx2id = []\n",
    "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
    "        for filename in os.listdir(self.PATH):\n",
    "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
    "            tree = parse(self.PATH + filename)\n",
    "            questions = tree.getElementsByTagName('Question')\n",
    "            for question in questions:\n",
    "                qelem = question.getElementsByTagName('QuestionText')\n",
    "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "                # print(q) # --> questions\n",
    "                answers = question.getElementsByTagName('Answer')\n",
    "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
    "                QA.append([q,answers_list, rank, labels])\n",
    "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
    "                # QA2.append([q,answers_list, rank, system, labels])\n",
    "                QA2.append(question)\n",
    "                indx2id.append(q_id); i+=1;\n",
    "                # break\n",
    "        return QA2\n",
    "    \n",
    "    def read_external_dataset(self):\n",
    "        QA = []\n",
    "        PATH_EXTRA = 'MedQuAD/'\n",
    "        for filename in os.listdir(PATH_EXTRA + '/'):\n",
    "            if any(s in filename for s in ('CDC', 'SeniorHealth', 'GARD', 'GHR', 'NIDDK')): # CDC, SeniorHealth, GARD,\n",
    "                dirname = PATH_EXTRA + '/' + filename\n",
    "                for file in os.listdir(dirname):\n",
    "                    fullname = dirname + '/' + file\n",
    "                    tree = parse(fullname)\n",
    "                    questions = tree.getElementsByTagName('QAPair')\n",
    "                    Q, QT, = [], []; QTypes = {}\n",
    "                    for question in questions:\n",
    "                        qelem = question.getElementsByTagName('Question')\n",
    "                        q, qid = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('qid')\n",
    "                        qtype = qelem[0].getAttribute('qtype')\n",
    "                        if question.getElementsByTagName('Answer')[0].firstChild is None: continue\n",
    "                        a = self.preprocess_text(question.getElementsByTagName('Answer')[0].firstChild.nodeValue)\n",
    "                        if qtype not in QTypes: \n",
    "                            QTypes[qtype] = {'q': q, 'a': [a]}\n",
    "                        else: \n",
    "                            QTypes[qtype]['a'].append(a)\n",
    "                        Q.append(q); QT.append(q + qtype)\n",
    "\n",
    "                    assert len(set(Q)) == len(set(QT)), 'Error reading MedQuAD dataset'\n",
    "                    for qtype in QTypes:\n",
    "                        q = QTypes[qtype]['q']\n",
    "                        # positive examples\n",
    "                        ans = QTypes[qtype]['a']\n",
    "                        question = Question(q_id=-1, q=q, a_ids=-1, a=ans, \n",
    "                                            r=[1]*len(ans), \n",
    "                                            s=[], l=[1]*len(ans))\n",
    "                        QA.append(question)\n",
    "                        # negative examples\n",
    "                        for qtype_other in QTypes:\n",
    "                            if qtype_other != qtype:\n",
    "                                ans_wrong = QTypes[qtype_other]['a']\n",
    "                                question = Question(q_id=-1, q=q, a_ids=[], a=ans_wrong, \n",
    "                                                    r=[int(len(ans))+1]*len(ans_wrong), \n",
    "                                                    s=[], l=[0]*len(ans_wrong))\n",
    "                                QA.append(question)\n",
    "                                \n",
    "        return QA\n",
    "\n",
    "    def output_predictions(self, predictions, labels, file=''):\n",
    "        assert len(predictions) == len(self)\n",
    "        print('question_id,answer_id,label')\n",
    "        with open(f'task3/sample_submission_round_2_{file}.csv', mode='w') as csv_file:\n",
    "            for i, p in enumerate(predictions):\n",
    "                q_id = self[i].question_id\n",
    "                answers = self[i].answer_ids\n",
    "                assert len(p) == len(answers), f'{len(p)} != {len(answers)}'\n",
    "                # order = np.array(a)[np.argsort(p)]\n",
    "                p = self.normalize_sequence(p)\n",
    "                order = np.array(answers)[np.argsort(p)]\n",
    "                # order = np.array(answers)[np.array(p)-1]\n",
    "                lab = labels[i]\n",
    "                ordered_lab = np.array(lab)[np.argsort(p)]\n",
    "                if file == '':\n",
    "                    \n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        print(f\"{q_id},{a_id},{int(l)}\")\n",
    "                else:\n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        csv_file.write(f\"{q_id},{a_id},{int(l)}\\n\")\n",
    "            \n",
    "    def normalize_sequence(self, seq):\n",
    "        seq = np.array(seq)\n",
    "        a = np.argsort(seq)\n",
    "        seq[a] = list(range(1,len(seq)+1))\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        preds = np.concatenate(predictions)\n",
    "        true  = np.concatenate(self.labels) \n",
    "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
    "        return accuracy_score(true, preds)\n",
    "\n",
    "    def precision(self, predictions):\n",
    "        precisions = []\n",
    "        num_answers = []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
    "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
    "            if len(p) == 0:\n",
    "                print(predictions[i])\n",
    "            correct = sum([a == b for a,b in zip(p, r)])\n",
    "            # for a,b in zip(p, r)\n",
    "            # num_answers.append(len(p))\n",
    "            precisions.append(correct/len(p))\n",
    "        return np.mean(precisions)\n",
    "        # return np.average(np.array(precisions), weights=num_answers)\n",
    "\n",
    "    def mean_spearmanr(self, predictions):\n",
    "        assert len(predictions) == len(self.references)\n",
    "        count, total = 0, 0\n",
    "        preds, refs = [], []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
    "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
    "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
    "            preds += p; refs += r\n",
    "            if len(r) == 1:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            elif len(r) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                total += 1\n",
    "                count += spearmanr(p, r)[0]\n",
    "        return spearmanr(preds, refs)[0]\n",
    "        # return count/total\n",
    "\n",
    "    def mean_reciprocal_rank(self, predicted):\n",
    "        rs = []\n",
    "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
    "            res = np.array(a)[np.argsort(b)]\n",
    "            labels = self[k].labels\n",
    "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
    "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = QuestionsAndAnswers(dataset = 'Train', load_external_data=True) \n",
    "QA_val = QuestionsAndAnswers(dataset = 'Validation')\n",
    "QA_test = QuestionsAndAnswers(dataset = 'Test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52297, 25, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA), len(QA_val), len(QA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_ranks = QA_test.get_system_ranks()\n",
    "reference_ranks = [q.reference_rank for q in QA_test]\n",
    "labels = [q.labels for q in QA_test]\n",
    "system_labels = [np.ones(len(l)) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA.output_predictions(reference_ranks, labels)\n",
    "# QA.output_predictions(system_ranks, system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "QA_test.output_predictions(system_ranks, system_labels, file='test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test2.csv\n",
      "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}\n"
     ]
    }
   ],
   "source": [
    "import evaluator\n",
    "\n",
    "def evaluate(filename):\n",
    "    for task in [3]:\n",
    "        print(f\"Testing Task (Round-2) : {task}\")\n",
    "        answer_file_path = f\"task{task}/ground_truth_round_2.csv\"\n",
    "        _client_payload = {}\n",
    "        _client_payload[\"submission_file_path\"] = f\"task{task}/sample_submission_round_2_{filename}.csv\"\n",
    "\n",
    "        # Instaiate a dummy context\n",
    "        _context = {}\n",
    "        # Instantiate an evaluator\n",
    "        aicrowd_evaluator = evaluator.MediqaEvaluator(answer_file_path, task=task, round=2)\n",
    "        # Evaluate\n",
    "        result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "        print(result)\n",
    "\n",
    "evaluate('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline\n",
    "\n",
    "Testing Task (Round-2) : 3\n",
    "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "# model_name = 'dmis-lab/biobert-large-cased-v1.1'\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# model = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
    "#                                   output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_sentence_embedding(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        CLS = outputs[0][0]\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # print(len(hidden_states.shape))\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all n token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "\n",
    "    return sentence_embedding\n",
    "\n",
    "def get_CLS(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    CLS = outputs[0][:,0,:]\n",
    "    return CLS\n",
    "\n",
    "def get_full_sentence_embedding(sentence):\n",
    "    embeddings = []\n",
    "    e = 0\n",
    "    max_size = 1024#512\n",
    "    for i in range(int(len(sentence)/max_size)+1):\n",
    "#         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "#         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "        e = get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "#         print(e)\n",
    "        embeddings.append(e)\n",
    "    embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    print(embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 7\n",
    "# q = get_bert_sentence_embedding(QA[K].question)\n",
    "# ans = [get_full_sentence_embedding(a) for a in QA[K].answers] # 512 is the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8469bc35fcb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label,Rank,Similarity'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ans' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach(), a.detach())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "marked_text = \"[CLS] \" + QA[K].question + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text, add_special_tokens=True)\n",
    "print(tokenized_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "a = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2280, -0.4502,  0.1192,  ...,  0.1038,  0.2135,  0.4945],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][:,0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "# lr_clf = LogisticRegression()\n",
    "# lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "rankings  = flatten([q.reference_rank for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val]) \n",
    "rankings_val  = flatten([q.reference_rank for q in QA_val])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test])\n",
    "rankings_test  = flatten([q.reference_rank for q in QA_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 32#64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset(Dataset):\n",
    "    def __init__(self, X, y, r, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        self.r = np.array(r)\n",
    "        for q, a in X:\n",
    "            _q = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + q + \" [SEP]\"))[:max_len_seq]\n",
    "            _q += [0]*(max_len_seq-len(_q))\n",
    "            _a = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + a + \" [SEP]\"))[:max_len_seq]\n",
    "            _a += [0]*(max_len_seq-len(_a))\n",
    "            self.X.append([_q, _a])\n",
    "        self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "        rank  = torch.FloatTensor([self.r[index]])\n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, rank, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset(X=sentences, y=labels, r=rankings)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create validation dataset\n",
    "val_dataset = MEDIQA_Dataset(X=sentences_val, y=labels_val, r=rankings_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset(X=sentences_test, y=labels_test, r=rankings_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_clf.bert.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "#         self.bert_q = AutoModel.from_pretrained(model_name)\n",
    "#         self.bert_a = AutoModel.from_pretrained(model_name)\n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-2]]\n",
    "#         modules = [self.bert_q.embeddings, *self.bert_q.encoder.layer[:-1],\n",
    "#                   self.bert_a.embeddings, *self.bert_a.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*self.bert.config.hidden_size, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        CLS1 = self.get_CLS(self.bert, q)\n",
    "        CLS2 = self.get_CLS(self.bert, a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([CLS1, CLS2], dim=1)\n",
    "#         print('concat:', x.shape, x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = nn.SELU()(x)\n",
    "#         x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.15)\n",
    "        x = self.linear2(x)\n",
    "        x = nn.SELU()(x)\n",
    "        x = F.dropout(x, 0.15)\n",
    "        x = self.linear3(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, CLS1, CLS2\n",
    "    \n",
    "    def set_train(self):\n",
    "        self.train()\n",
    "        self.bert.train()\n",
    "#         self.bert_a.train()\n",
    "#         self.bert_q.train()\n",
    "        \n",
    "    def set_eval(self):\n",
    "        self.eval()\n",
    "        self.bert.eval()\n",
    "#         self.bert_a.eval()\n",
    "#         self.bert_q.eval()\n",
    "\n",
    "    def get_CLS(self, model, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#         segments_ids = [1] * len(indexed_tokens)\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = model(tokens_tensor)\n",
    "        CLS = outputs[0][:,0,:]\n",
    "        return CLS\n",
    "    \n",
    "    def get_hidden_state_average(self, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = self.bert(tokens_tensor)\n",
    "#         print(outputs.shape)\n",
    "        hidden_state = torch.mean(outputs[0][:,:,:], dim=1)\n",
    "#         print(hidden_state.shape)\n",
    "        return hidden_state\n",
    "\n",
    "    def get_full_sentence_embedding(self, sentence):\n",
    "        embeddings = []\n",
    "        e = 0\n",
    "        max_size = 1024#512\n",
    "        for i in range(int(len(sentence)/max_size)+1):\n",
    "    #         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "    #         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "            e = self.get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "    #         print(e)\n",
    "            embeddings.append(e)\n",
    "        embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "        print(embedding)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del bert_clf\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_clf = MEDIQA_Model()\n",
    "bert_clf = bert_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bert_clf.bert.encoder.layer)\n",
    "# bert_clf.bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, data_loader, true_labels, return_probs_and_labels=False):\n",
    "    model.set_eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,r,q,a in tqdm.tqdm(data_loader):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_loss(x1, x2, y):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        return 1-cos(a,b)\n",
    "    margin = torch.tensor(1.0).to(device)\n",
    "    loss = y*dist(x1,x2) + (1-y)*torch.max(torch.tensor(0.0).to(device), margin - dist(x1,x2))\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def ranking_loss2(x1, x2, y, rank):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        return 1-cos(a,b)\n",
    "    margin = torch.tensor(0.75).to(device)\n",
    "    mini_margin = 0.05*(rank-1.0)\n",
    "    loss = y*torch.max(torch.tensor(0.0).to(device), mini_margin - dist(x1,x2)) + (1-y)*torch.max(torch.tensor(0.0).to(device), margin - dist(x1,x2))\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in np.array(list(bert_clf.parameters())):\n",
    "#     print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.53794145584106456\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.6571298241615295\n",
      "Epoch 1 mean loss: 0.5474659464184644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.66it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5982905982905983    Val loss:  0.738619858152392\n",
      "Test acc: 0.4832881662149955   Test loss: 0.8417277050873954\n",
      "\n",
      "step 0.56159788370132453\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.22253745794296265\n",
      "Epoch 2 mean loss: 0.5413857674493342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5982905982905983    Val loss:  0.725190596349631\n",
      "Test acc: 0.48148148148148145   Test loss: 0.8413347367258055\n",
      "\n",
      "step 0.277003347873687745\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.8372031450271606\n",
      "Epoch 3 mean loss: 0.4876113094713597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5854700854700855    Val loss:  0.8181029799673036\n",
      "Test acc: 0.4869015356820235   Test loss: 0.9434174953009321\n",
      "\n",
      "step 0.2611778080463409465\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.009181246161460876\n",
      "Epoch 4 mean loss: 0.2590569324073154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.62it/s]\n",
      "100%|██████████| 35/35 [00:53<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.6410256410256411    Val loss:  0.8949429866444565\n",
      "Test acc: 0.5302619692863595   Test loss: 1.1591606748280971\n",
      "\n",
      "step 0.1227335333824157746\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-bd750a14fd0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# loss = loss_func(logits, y_true.to(device))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#         loss = 0.2*ranking_loss2(CLS1, CLS2, y_true.to(device), rank.to(device)) + 0.8*loss_func(logits, y_true.to(device))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=5e-5, weight_decay=0)\n",
    "bert_clf.set_train()\n",
    "EPOCHS = 200\n",
    "EARLY_STOPPING = 10\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "train_losses, test_losses, val_losses, val_accs, test_accs = [], [], [], [], []\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    bert_clf.set_train()\n",
    "    for step_num, batch_data in enumerate(train_loader):\n",
    "        y_true, rank, questions, answers = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        if questions.shape != answers.shape: continue\n",
    "        logits, CLS1, CLS2 = bert_clf(questions.to(device), answers.to(device))\n",
    "        # loss = loss_func(logits, y_true.to(device))\n",
    "#         loss = 0.2*ranking_loss2(CLS1, CLS2, y_true.to(device), rank.to(device)) + 0.8*loss_func(logits, y_true.to(device))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "\n",
    "\n",
    "        bert_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print('step', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    val_acc, val_probs_labels, _   = get_test_acc(bert_clf, val_loader,  labels_val,  return_probs_and_labels=True)\n",
    "    test_acc, test_probs_labels, _ = get_test_acc(bert_clf, test_loader, labels_test, return_probs_and_labels=True)\n",
    "    val_accs.append(val_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    val_loss  = loss_func(torch.from_numpy(val_probs_labels),  torch.from_numpy(np.array(labels_val, dtype=np.double))).item()\n",
    "    test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Val acc: ', val_acc, '   Val loss: ', val_loss)\n",
    "    print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_accs) <= 1 or test_acc > max(test_accs[:-1]):\n",
    "        torch.save(bert_clf.state_dict(), 'checkpoints/model')\n",
    "    if len(val_losses) > EARLY_STOPPING and val_losses[-(EARLY_STOPPING+1)] < min(val_losses[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model()\n",
    "        model.load_state_dict(torch.load('checkpoints/model'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_accs, label='test acc')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.plot(val_accs, label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('figures/biobert_loss_lr_small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/mediqa_model_clinicalbert_finetune_2_layer_61_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "# model = MEDIQA_Model()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "model = MEDIQA_Model()\n",
    "model.load_state_dict(torch.load('checkpoints/model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [04:25<00:00,  7.60s/it]\n"
     ]
    }
   ],
   "source": [
    "acc, probs, y_pred = get_test_acc(model.to(device), test_loader, labels_test, return_probs_and_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_predictions(probs, y):\n",
    "    rankings  = []\n",
    "    entailed = []\n",
    "    i_start  = 0\n",
    "    for i, q in enumerate(QA_test):\n",
    "        rankings.append(1- np.array(probs[i_start:i_start+len(q.answers)]))\n",
    "        entailed.append(y[i_start:i_start+len(q.answers)])\n",
    "        i_start += len(q.answers)\n",
    "        assert len(rankings[i] == len(QA_test[i].answer_ids))\n",
    "        assert len(entailed[i] == len(QA_test[i].answers))\n",
    "    return rankings, entailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = (probs >= 0.45).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "ranking_pred, labels_pred = get_ranking_predictions(probs, y_pred_2)\n",
    "csv_name = 'test_biobert_50k'\n",
    "QA_test.output_predictions(ranking_pred, labels_pred, file=csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test_biobert_50k.csv\n",
      "{'score_acc': 0.5338753387533876, 'score_secondary_spearman': -0.018604651162790704, 'meta': {'MRR': 0.5166666666666667, 'Precision': 0.6037037037037037}}\n"
     ]
    }
   ],
   "source": [
    "evaluate(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5k-> {'score_acc': 0.5663956639566395, 'score_secondary_spearman': 0.011531841652323562, 'meta': {'MRR': 0.6802222222222222, 'Precision': 0.5954356846473029}}\n",
    "\n",
    "\n",
    "20k-> {'score_acc': 0.6115627822944896, 'score_secondary_spearman': -0.004830917874396123, 'meta': {'MRR': 0.7074444444444444, 'Precision': 0.6898395721925134}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:51<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "pred_labels = []\n",
    "bert_clf.to(device)\n",
    "with torch.no_grad():\n",
    "    for s,q,a in tqdm.tqdm(test_loader):\n",
    "        logits = bert_clf(q.to(device),a.to(device))\n",
    "        pred_labels.extend(logits.to('cpu'))\n",
    "    pred_labels = np.array([x.item() for x in pred_labels])\n",
    "    pred = (pred_labels > 0.5).astype(np.int16)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971093044263776"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([1,2,3]), torch.tensor([1,2,3])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101,   193,   118,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3073, 10294,  ...,  1110,  1136,  2276],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101, 14051, 16026,  ...,     0,     0,     0],\n",
      "        [  101,  1887,  8006,  ...,  2039,   119,  1142],\n",
      "        [  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1221, 1167,  ...,    0,    0,    0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1187,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 19640,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,  2975,  1115,  1138],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 32180, 20939,  ...,  1132,  1160,  1514],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36359, 31630,  ...,  7604,  1137,  8192],\n",
      "        [  101, 44511,  1596,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 15355, 15491,  ...,  1128,  1444,  1106],\n",
      "        [  101, 16638,  1822,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  4333,  1183,  ...,  1240,  2027,  1144],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101, 58456, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 20557, 22214,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,     0,     0,     0],\n",
      "        [  101,  3607, 14255,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  2016,  1104,  4182],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41844,  1162,  ..., 17713,   120, 37553],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]]), tensor([[  101, 20844,  6575,  ...,   170,   119,   173],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 24443, 20497,  ...,   118, 29346,  2149],\n",
      "        [  101, 14255, 43199,  ..., 43199, 48974, 20484]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  3924,  9304,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14947,   113,  ...,     0,     0,     0],\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  3252,  6665,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 45648, 11098,  ...,  2332,  2094,  4822],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 16374,   117, 23658],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,  1104,  2094,  1106],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101, 19245,  1105,  ...,  2914,   119,  2367]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 35810,  ...,  2116,   118,  7930],\n",
      "        [  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,  1165,  1106,  1840]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 27410, 29261,  ..., 29261, 10306,  3252],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 39960, 41482,  ...,     0,     0,     0],\n",
      "        [  101,  4457,   118,  ...,  5173, 24034,  8341]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,  5800,  2109, 14255],\n",
      "        [  101, 14255, 43199,  ...,  1274,   112,   189],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,  1128,  4330,  1315],\n",
      "        [  101, 43760, 21459,  ...,  8006,  1336,  7907],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,  2612,  1105,  2450],\n",
      "        [  101, 15604, 16420,  ..., 23658,  1175,  1132],\n",
      "        ...,\n",
      "        [  101, 13316, 33391,  ...,  1132,  1276,  1219],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101, 29278, 25453,  ...,   173,   119,   170]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 53109,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3678, 22869,  ...,  1118,   131,   179],\n",
      "        [  101,  1322,  6758,  ...,     0,     0,     0],\n",
      "        [  101, 17972,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 10878, 17972,  ...,  3843, 39241,  8032],\n",
      "        [  101, 34754,  1643,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 39241,  8032,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,  2633,   119,  1191],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1110,  1122,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101,  5153, 29284,  ...,  1191,  1115,  2086],\n",
      "        [  101, 53685, 35810,  ...,   170,  2960,  1104],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        ...,\n",
      "        [  101, 14434,   193,  ...,     0,     0,     0],\n",
      "        [  101,  7753, 22869,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ...,  6028,  2445,   117]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,  3490,  1107,   170],\n",
      "        [  101,  3245, 40739,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,  1116,  3652,  1105],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6245,  1104,  ...,  2922,   117, 37521],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0]]), tensor([[  101,  5354, 20939,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,  1353,  6556,  1104],\n",
      "        [  101, 47433, 10024,  ...,  1936,  1334,  3154],\n",
      "        ...,\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 44648, 32219,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  3252,  1111,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 12809,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35929, 42193,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ..., 24259,  1116,   119],\n",
      "        [  101, 33869, 31719,  ...,  2769,  1104,  1142]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9947,  1181,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1322,  6758,  ...,   185,  8057,  2225],\n",
      "        [  101,  1940,  1233,  ...,   176,   117,  2027]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101, 43165,   113,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  5837, 17953,  ...,  1107,  1199,  2740],\n",
      "        [  101,  3245, 40680,  ...,   119,   177,   119],\n",
      "        [  101,  6898,  1161,  ..., 36431,  8043,  4626],\n",
      "        ...,\n",
      "        [  101, 29261, 10306,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 37521, 55658,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1716,  2445,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101, 24181, 29232,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9947,  1158,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101,  2841,  2445,  ...,  1128, 44077,  3798]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0]]), tensor([[  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ..., 57169,  7889, 32704]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,  1712,  1122,  1228],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,  1278,   117,  1934],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 35750,  1465,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1725,  1169,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0]]), tensor([[  101, 17291, 36647,  ...,   113, 30322, 20713],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,  1932, 13974,  1234],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 8805, 1399,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  178, 1138,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 31015,  4559,  ...,     0,     0,     0],\n",
      "        [  101, 36359, 31630,  ...,  6986,  1170,  1425],\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  7209,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 29346,  2149,  ...,  2812,  6059,  1137],\n",
      "        [  101, 12104, 24928,  ...,  1129,  1694,  1511],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 30560,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 10507,   113,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0]]), tensor([[  101,  3245, 40739,  ..., 29660,  4371,   114],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4107,  1164,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9077,  1105,  ...,  1152,  1145,  1494],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 18419,  2765,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 13316, 33391,  ...,     0,     0,     0],\n",
      "        [  101, 13316, 33391,  ..., 13782,  2225,   119],\n",
      "        [  101,  1662,  4777,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 46407,  4060,  ...,  1137, 48117,  6108],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0]]), tensor([[  101,  1301, 13523,  ...,   119,  1128,  1336],\n",
      "        [  101, 53685, 35810,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1139,  1401,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 36431,  5168,  ...,  1173,  9711,  1111],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,  1443,  3634,  1807],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,  1510,  1431,   178],\n",
      "        [  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1110,  ...,  1128,  1169,  1321],\n",
      "        [  101, 13316,  9028,  ...,  1103,  1378,   131],\n",
      "        [  101, 19245, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,  1106, 12434,  1103],\n",
      "        [  101,  4106,  6997,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0]]), tensor([[  101, 22214, 10507,  ...,  5199,   119,  1128],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35041, 42490,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1690,  1114,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  8856,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  3995,  1105, 46657],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,  5837, 17953,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0]]), tensor([[  101,  9304, 34581,  ...,  1240, 16212,   119],\n",
      "        [  101,  3196,  2841,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  1267,  1293,  1218],\n",
      "        ...,\n",
      "        [  101, 36344,  2042,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5557,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101,  1344, 47310,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]]), tensor([[  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 25506, 37041,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0]]), tensor([[  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,  1673,   113,  1185],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1674,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 6898, 1161,  ...,    0,    0,    0]]), tensor([[  101, 13306, 16042,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1114, 29123,  4759],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ..., 29660, 15243, 12633],\n",
      "        [  101,  6898,  1161,  ...,  1825,   119,   118]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 20968, 14051,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        [  101, 17972,   118,  ...,     0,     0,     0],\n",
      "        [  101, 44676,  4182,  ...,  1110,  1270, 45758]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 14837, 20673,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ..., 29056,   117,  1639],\n",
      "        [  101, 50352,  1733,  ...,  4607,  1105,  3843],\n",
      "        ...,\n",
      "        [  101,  4809,  1513,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1510,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 29193, 16838,  ..., 16838, 12736, 22992],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ..., 30177,   178,   118]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1132, 1175,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0],\n",
      "        [ 101, 4680, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 3252,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,  1404,   118,   170],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,   119,   170,  3112]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0]]), tensor([[  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 11552, 46789, 12571],\n",
      "        [  101, 29056,  4455,  ...,  1874, 20192,  1566]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0]]), tensor([[  101, 23123,  4184,  ...,     0,     0,     0],\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 26600, 58355,  ...,  2612,   119,  1372],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,  1128,  1132,  1253],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  3245, 40739,  ...,  5735, 12362,  1116],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  2218, 16565,   119],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 51541, 41482,  ..., 11478,  2217,  1110],\n",
      "        [  101,  1762,  2035,  ..., 30216,  6951,  1106]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,  1219,  1103, 12104],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 26707, 32304,  ...,  1162,  1114, 19035],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 24762,  6575,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4287,  1240,  ...,     0,     0,     0],\n",
      "        [  101, 10507, 11759,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1887,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1494, 1114,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,  5363,  1114,  1142],\n",
      "        [  101, 35929, 42193,  ...,  1110,  1126, 55496],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 14051, 16026,  ...,  1138,  1137,  1138]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 54074, 14196,  ...,     0,     0,     0],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0]]), tensor([[  101, 57481, 12602,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1202,   178,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        [  101,  1169,   178,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ..., 13753,   117,  1321],\n",
      "        [  101, 16320,  1116,  ...,     0,     0,     0],\n",
      "        [  101,  6730,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 11200,  1111,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,  3870,  1157,  3053],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,  1103,   118,  4073],\n",
      "        [  101, 32401,  5132,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 52549, 15355,  ...,     0,     0,     0],\n",
      "        [  101,  4267, 15284,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ..., 11009,  1201,   117],\n",
      "        [  101,  6307, 24662,  ...,  2241,  1112,  1936]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,     0,     0,     0]]), tensor([[  101, 41437,  1204,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,   113,  2824,  1103],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,  2645,  1235,  1103]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0]]), tensor([[  101, 24259, 23897,  ...,  1110,   175,  1810],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  1120,  1240, 19328],\n",
      "        ...,\n",
      "        [  101, 11536,  1106,  ...,  1296,  3420,   119],\n",
      "        [  101, 29156, 18208,  ...,  1431,  5427,  1107],\n",
      "        [  101,  3073, 10294,  ...,  1240,  1148, 10203]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 56401,  8840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 42193, 16071,  ...,  2218, 13558,  1107],\n",
      "        [  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,  1114, 35929, 42193],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  1105,  8006,   119]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 8006, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1129,  1694,  1106],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,   118,  3987,  1892],\n",
      "        [  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1184, 2774,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 9987,  ...,    0,    0,    0],\n",
      "        [ 101, 1165, 1105,  ...,    0,    0,    0]]), tensor([[  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6857,  1964,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101,   193,   118,  ...,  2747,  7459,  2975]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 4107, 1164,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1195, 1138,  ...,    0,    0,    0]]), tensor([[  101, 18419,  2765,  ..., 31033, 21180,   113],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1156, 8856,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10211,  1111,  ...,  1142,  2076,  1104],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101,  6857,  1964,  ...,  1104,  6857,  1964]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 51632,  1200,  ...,  4567,   117,  1134],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        [  101, 11019, 31086,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 41156, 11955,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  8204,  9987,  1127],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 46789, 12571,  ...,     0,     0,     0],\n",
      "        [  101, 29261, 10306,  ...,  1336,  1494,  3843],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23123,  4184,  ...,   119,  1164,   122],\n",
      "        [  101, 15355,   118,  ...,  8054,  1118,   131],\n",
      "        [  101, 26600, 32514,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 11111,  1825,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 13306,  1139,  ...,     0,     0,     0],\n",
      "        [  101, 14947,   118,  ...,     0,     0,     0]])]\n"
     ]
    }
   ],
   "source": [
    "for b in train_loader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [00:07<00:00, 51.2MB/s] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-277-251332b25f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mrepresentations_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu\n",
    "\n",
    "model_names = [\n",
    "    'bert-base-nli-stsb-mean-tokens',\n",
    "    'bert-large-nli-stsb-mean-tokens',\n",
    "    'roberta-base-nli-stsb-mean-tokens',\n",
    "    'roberta-large-nli-stsb-mean-tokens',\n",
    "    'distilbert-base-nli-stsb-mean-tokens'\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = SentenceTransformer(name)\n",
    "    model = model.to(cuda)\n",
    "\n",
    "    representations_a = []\n",
    "    representations_b = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sent_a, sent_b) in tqdm(test_sentences, desc='Embedding Sentences', ncols=800):\n",
    "            sentences_embeddings = model.encode([sent_a, sent_b])\n",
    "            representations_a.append(sentences_embeddings[0])\n",
    "            representations_b.append(sentences_embeddings[1])\n",
    "\n",
    "    obtained_scores = []\n",
    "    for idx, (repr_a, repr_b) in enumerate(zip(representations_a, representations_b)):\n",
    "        score = 1 - cosine(repr_a, repr_b)\n",
    "        obtained_scores.append(score)\n",
    "\n",
    "    corr_score = pearsonr(test_scores[:len(obtained_scores)], obtained_scores)[0]\n",
    "    print(f'{name}: {corr_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioELMo\n",
    "\n",
    "https://docs.allennlp.org/v1.0.0rc5/tutorials/how_to/elmo/\n",
    "\n",
    "https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp\n",
    "# ! pip install allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonre\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo\n",
    "# elmo = Elmo(\n",
    "#     options_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json', \n",
    "#     weight_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "#     num_output_representations=3,\n",
    "#     dropout=0\n",
    "    \n",
    "# )\n",
    "\n",
    "bioelmo = Elmo(\n",
    "    options_file='bioelmo/biomed_elmo_options.json', \n",
    "    weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "    num_output_representations=3,\n",
    "    dropout=0\n",
    ")\n",
    "bioelmo = bioelmo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  71, 106, 115, 116, 117, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 116, 102, 111, 117, 102, 111, 100, 102, 260, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  66, 111, 112, 117, 105, 102, 115, 260, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  74, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 117, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 100,  98, 115, 115, 112, 117, 260, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 103, 112, 115, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  99, 115, 102,  98, 108, 103,  98, 116, 117, 260, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [['First', 'sentence', '.'], ['Another', '.'], [\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"]]\n",
    "character_ids = batch_to_ids(sentences).to(device)\n",
    "embeddings = bioelmo(character_ids)\n",
    "character_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_embedding(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    sentences = [tokens]\n",
    "    character_ids = batch_to_ids(sentences).to(device)\n",
    "    return bioelmo(character_ids)['elmo_representations'][2].mean(dim=0).mean(dim=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1981, -0.2493,  0.1472,  ...,  0.0856,  0.0514,  0.0953],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['elmo_representations'][0].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0\n",
    "q = get_elmo_embedding(QA[K].question)\n",
    "ans = [get_elmo_embedding(a) for a in QA[K].answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n",
      "1 2 0.7145789861679077\n",
      "0 7 0.6949490308761597\n",
      "1 3 0.7414701581001282\n",
      "0 8 0.6276549696922302\n",
      "1 5 0.7520613670349121\n",
      "0 6 0.6759256720542908\n",
      "0 10 0.6990264654159546\n",
      "1 4 0.740582287311554\n",
      "0 9 0.6365541219711304\n",
      "1 1 0.7022466659545898\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach().cpu(), a.detach().cpu())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset2(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = batch_to_ids([nltk.word_tokenize(q)])\n",
    "            _a = batch_to_ids([nltk.word_tokenize(a)])\n",
    "            self.X.append([_q, _a])\n",
    "#         self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return self.X.shape[0]\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset2(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create train dataset\n",
    "val_dataset = MEDIQA_Dataset2(X=sentences_val, y=labels_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset2(X=sentences_test, y=labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model_bioELMo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model_bioELMo, self).__init__()\n",
    "        self.bioelmo = Elmo(\n",
    "            options_file='bioelmo/biomed_elmo_options.json', \n",
    "            weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "            num_output_representations=3,\n",
    "            dropout=0\n",
    "        )\n",
    "        for param in self.bioelmo.parameters():\n",
    "            param.requires_grad = False\n",
    "#         self.bioelmo = bioelmo.to(device)\n",
    "#         modules = [self.bert.embeddings, *self.bert.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "#         for module in modules:\n",
    "#             for param in module.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*1024, 256)\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        q_emb = self.get_elmo_embedding(q)\n",
    "        a_emb = self.get_elmo_embedding(a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([q_emb, a_emb], dim=0)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.SELU()(x)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear2(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, q_emb, a_emb\n",
    "\n",
    "\n",
    "    def get_elmo_embedding(self, sentence):\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "#         sentences = [tokens]\n",
    "#         character_ids = batch_to_ids(sentence).to(device)\n",
    "        return self.bioelmo(sentence)['elmo_representations'][2].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioelmo_clf = MEDIQA_Model_bioELMo()\n",
    "bioelmo_clf = bioelmo_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, dataset, true_labels, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,(q,a) in tqdm.tqdm(zip(dataset.y, dataset.X)):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonre\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1699/1701 1.71011781692504887838951975107192993 0.23533932864665985 0.43557727336883545 0.47481733560562134 0.6460447907447815 0.36849457025527954 0.33953002095222473 0.3474850654602051 0.8418510556221008 0.05722641572356224 0.2941003441810608 2.123321056365967 0.6593480110168457 0.32470789551734924 0.9396703839302063 1.138655424118042 0.4479018449783325 0.31677868962287903 0.5760351419448853 1.1472036838531494 0.3642497956752777 0.655806303024292 0.13179482519626617 0.14221100509166718 0.03715140372514725 0.03710370883345604 0.5069848895072937 0.12469686567783356 0.2872546911239624 0.30459126830101013 0.1827237755060196 0.05583462119102478 0.17570139467716217 0.2522789537906647 0.5008960366249084 0.1498612016439438 0.27536070346832275 0.8094481825828552 0.35863804817199707 0.007488503586500883 0.272317498922348 0.665442168712616 1.0090411901474 0.2127843052148819 0.37714487314224243 0.6983405351638794 0.5069541931152344 0.50309818983078 0.8695306777954102 0.35794731974601746 0.33450114727020264 0.6171535849571228 0.312409371137619 0.2712901532649994 1.6810646057128906 0.36910927295684814 0.4692544937133789 1.75895357131958 0.2932157814502716 0.5372257232666016 0.027927039191126823 0.1249619871377945 1.7608225345611572 0.6221458315849304 0.523066520690918 0.19671142101287842 0.08420790731906891 0.28924253582954407 0.2556413412094116 0.8796494007110596 0.2936345338821411\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.7862160205841064\n",
      "Epoch 1 mean loss: 0.5470765709035484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.7001965673588473\n",
      "\n",
      "step 1699/1701 0.889972448348999379362247467041016 2.4180185794830322 0.8195332288742065 0.1406424194574356 0.3818170428276062 0.12095547467470169 1.107313871383667 0.4588475525379181 0.30129575729370117 0.1594342440366745 0.5645102262496948 0.22144408524036407 1.3693127632141113 0.5619590282440186 0.984674870967865 0.25585871934890747 0.159635528922081 1.1690434217453003 0.7233050465583801 0.3393656611442566 0.4672911465167999 0.4082551598548889 0.010942566208541393 0.5697507858276367 0.45417967438697815 0.976703405380249 0.43082624673843384 0.40804970264434814 0.6283698081970215 0.5590319037437439 0.5463050007820129 0.17585323750972748 1.9180209636688232 0.1507309079170227 0.16022297739982605 0.3079458177089691 0.585024356842041 0.6884199380874634 0.1709163784980774 0.12889130413532257 1.140803575515747 0.0848105326294899 0.102312833070755 0.2131572663784027 0.1793561726808548 0.24677921831607819 0.42515799403190613 1.9360604286193848 0.26598498225212097 0.32448360323905945 0.02179734967648983 0.11528331786394119 0.09603890776634216 2.30022931098938 0.25486281514167786 0.38218000531196594 0.4269558787345886 0.005665106233209372 0.010114147327840328 0.3151859641075134 0.004863566253334284 0.6314024329185486 0.0034754399675875902 0.3721623122692108 0.16351556777954102 0.02171304263174534 0.2702646255493164 0.8254010677337646 0.4055841863155365 0.35664498805999756 0.5073227882385254 0.18946605920791626 0.19136051833629608 0.8475819826126099 0.444319486618042\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 2.181504011154175\n",
      "Epoch 2 mean loss: 0.529938168631952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:25,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.7974151839641529\n",
      "\n",
      "step 1699/1701 0.41434207558631897263915131688117981 0.9628956317901611 0.24819764494895935 0.11368143558502197 0.009933050721883774 1.7809391021728516 0.20588482916355133 0.5801113247871399 0.18976131081581116 0.18153975903987885 0.09791207313537598 0.6856088638305664 0.2436830699443817 0.6077970266342163 0.9067908525466919 0.3573295474052429 0.261269748210907 0.43519073724746704 0.035383690148591995 0.3175675570964813 0.40281152725219727 0.8080476522445679 1.1279242038726807 0.06454793363809586 0.08964324742555618 0.11496498435735703 0.34422388672828674 0.3302593529224396 0.30213016271591187 0.5582733750343323 0.11403423547744751 0.025494778528809547 0.22439706325531006 0.1942361295223236 0.3218885660171509 0.38328227400779724 0.3474422097206116 0.591511607170105 0.5341475009918213 0.9155266284942627 0.6099256277084351 0.04416247084736824 0.17114566266536713 2.753002882003784 0.33806395530700684 0.23099620640277863 0.13612425327301025 0.6084839105606079 0.18443503975868225 0.9233198761940002 0.10553042590618134 0.08178785443305969 0.18648673593997955 1.1546802520751953 1.0944827795028687 0.46894216537475586 0.035146962851285934 1.5655255317687988 0.3664795458316803 0.1681874841451645 0.3270869255065918 0.16005577147006989 0.9876587390899658 1.0515607595443726 0.023649878799915314 0.7049729228019714 0.5459180474281311 0.08879972994327545 0.0736125111579895 1.1838246583938599 0.10638335347175598 0.08499325066804886 0.27606233954429626 0.08877693116664886 0.368268758058548 0.1517312228679657 0.2657988965511322 0.04590384662151337\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.8204247951507568\n",
      "Epoch 3 mean loss: 0.5066695220493052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:23,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.594017094017094    Val loss:  0.7729332350682371\n",
      "\n",
      "step 1699/1701 1.02016639709472665945155510902404785 0.9498398303985596 0.7538938522338867 0.1204020082950592 0.018345903605222702 0.50141441822052 0.19695845246315002 2.406003475189209 0.12421474605798721 1.3062564134597778 0.31245163083076477 0.1351374387741089 0.21758130192756653 0.051666878163814545 0.00689355842769146 0.22147607803344727 0.8355936408042908 0.31978416442871094 0.4892957806587219 0.7420252561569214 0.37604981660842896 0.01990683749318123 1.5804355144500732 0.3210747539997101 0.17524363100528717 0.1193753108382225 0.5383833646774292 0.7556830644607544 0.23284731805324554 0.7645964622497559 0.09769280254840851 0.458678662776947 0.3774259090423584 0.03356626629829407 0.002019177656620741 0.3063775300979614 0.10143554210662842 0.5013996362686157 0.3172861933708191 0.23143619298934937 0.017878498882055283 0.6789623498916626 1.3744012117385864 0.13206802308559418 0.3482886850833893 0.43610742688179016 0.06548921018838882 2.3220913410186768 0.5073582530021667 0.41193434596061707 0.3297608196735382 0.2516810894012451 0.09014491736888885 0.3283924460411072 0.6229130029678345 2.7852869033813477 0.2821197807788849 0.467916876077652 0.38540294766426086 0.5687879920005798 2.4258742332458496 0.6067729592323303 0.09536181390285492 0.15364407002925873 0.38345280289649963 0.0032215097453445196 0.11213231831789017 0.050964657217264175 1.028831958770752 1.5352181196212769 1.4901396036148071 0.10352567583322525 0.09727811813354492 0.318237841129303 0.32114696502685547\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.08944638073444366\n",
      "Epoch 4 mean loss: 0.49869779664185393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.594017094017094    Val loss:  0.7232423270883489\n",
      "\n",
      "step 1699/1701 0.2726880609989166775622889757156372 0.09958454221487045 1.8078936338424683 0.2114657759666443 0.29803892970085144 0.6668585538864136 0.8017431497573853 0.3002769947052002 0.16318193078041077 0.4067121148109436 1.2046217918395996 0.7431590557098389 0.25896599888801575 0.3740696907043457 0.7046976685523987 0.11357986927032471 0.36742278933525085 0.43471062183380127 0.1049271747469902 0.9634199142456055 0.13613572716712952 0.00929176900535822 0.4955126643180847 0.23669834434986115 0.17487984895706177 0.17407813668251038 0.24432750046253204 0.5651242733001709 0.637417197227478 0.15414440631866455 0.500500500202179 0.16484253108501434 0.9877283573150635 0.2954854369163513 0.1111513078212738 0.051510728895664215 1.3193895816802979 0.10662323236465454 0.1555909514427185 0.394194632768631 0.6640473008155823 0.13379696011543274 1.151511788368225 0.3434983491897583 0.010252881795167923 0.4451039433479309 0.29776450991630554 0.3904978334903717 0.31823399662971497 0.08536314219236374 0.14886145293712616 0.5255555510520935 0.15992043912410736 0.311166375875473 0.6172075271606445 1.68224036693573 0.45624902844429016 0.21711649000644684 0.003368501551449299 0.36613360047340393 1.6167963743209839 0.17248676717281342 0.24137040972709656 0.19896288216114044 0.8744179606437683 0.1407156139612198 0.8655014038085938 2.7615697383880615 0.15726089477539062 0.355825275182724 1.5809736251831055 0.29863134026527405 0.2104003131389618 0.4045359492301941 0.6428289413452148 0.4174315333366394 0.055678706616163254 0.02433396503329277 0.12021639943122864 0.2188158631324768\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.06284432113170624\n",
      "Epoch 5 mean loss: 0.4878300085998053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.757634205137173\n",
      "\n",
      "step 166/1701 0.1658745855093002365.09681869298219681 0.0020957482047379017 0.1784224659204483 0.6737553477287292 0.13414056599140167\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-830fd82e781c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;31m#tuple(t.to(device) for t in batch_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLS1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLS2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbioelmo_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c1835a3c65c0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q, a)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         print(q.shape, a.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mq_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0ma_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m#         print('CLS:', CLS1.shape, CLS2.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c1835a3c65c0>\u001b[0m in \u001b[0;36mget_elmo_embedding\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#         sentences = [tokens]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#         character_ids = batch_to_ids(sentence).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbioelmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elmo_representations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# run the biLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mbilm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"activations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_embedding\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[0mlstm_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# Prepare the output.  The first layer is duplicated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         stacked_sequence_output, final_states, restoration_indices = self.sort_and_run_forward(\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         )\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[1;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36m_lstm_forward\u001b[1;34m(self, inputs, initial_state)\u001b[0m\n\u001b[0;32m    229\u001b[0m             )\n\u001b[0;32m    230\u001b[0m             backward_output_sequence, backward_state = backward_layer(\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mbackward_output_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             )\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# Skip connections, just adding the input to the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\lstm_cell_with_projection.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, batch_lengths, initial_state)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;31m# shape (current_length_index, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[0mtimestep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_projection_timestep_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_projection_clip_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bioelmo_clf.parameters(), lr=5e-5)\n",
    "bioelmo_clf.train()\n",
    "EPOCHS = 100\n",
    "EARLY_STOPPING = 5\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "train_losses, test_losses, val_losses, val_accs, test_accs = [], [], [], [], []\n",
    "N = len(train_dataset.y)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bioelmo_clf.train()\n",
    "    \n",
    "    train_samples = list(zip(train_dataset.y, train_dataset.X))\n",
    "    losses = []\n",
    "    for step_num, batch_data in enumerate(random.sample(train_samples, len(train_samples))):\n",
    "        y_true, (questions, answers) = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        logits, CLS1, CLS2 = bioelmo_clf(questions.to(device), answers.to(device))\n",
    "        y_true = torch.from_numpy(np.array([y_true], dtype=np.float32))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "\n",
    "        bioelmo_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f'step {step_num}/{N}', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    val_acc, val_probs_labels, _   = get_test_acc(bioelmo_clf, val_dataset, labels_val,  return_probs_and_labels=True)\n",
    "#     test_acc, test_probs_labels, _ = get_test_acc(bioelmo_clf, test_loader, labels_test, return_probs_and_labels=True)\n",
    "    val_accs.append(val_acc)\n",
    "#     test_accs.append(test_acc)\n",
    "    \n",
    "    val_loss  = loss_func(torch.from_numpy(val_probs_labels),  torch.from_numpy(np.array(labels_val, dtype=np.double))).item()\n",
    "#     test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    val_losses.append(val_loss)\n",
    "#     test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Val acc: ', val_acc, '   Val loss: ', val_loss)\n",
    "#     print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "#     print(f'Epoch {epoch_num+1}:', np.mean(losses))\n",
    "#     train_losses.append(np.mean(losses))\n",
    "# #     acc = get_test_acc(bioelmo_clf)\n",
    "#     acc, probs_labels, _ = get_test_acc(bioelmo_clf, return_probs_and_labels=True)\n",
    "#     test_acc.append(acc)\n",
    "#     test_loss = loss_func(torch.from_numpy(probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "#     test_losses.append(test_loss)\n",
    "#     test_acc.append(acc)\n",
    "#     print(f'Test acc:', acc, '  Test loss:', test_loss)\n",
    "#     print()\n",
    "    \n",
    "    if len(test_acc) > 5 and test_acc[-6] > max(test_acc[-5:]):\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    if len(test_accs) <= 1 or test_acc > max(test_accs[:-1]):\n",
    "        torch.save(bioelmo_clf.state_dict(), 'checkpoints/model_elmo')\n",
    "    if len(val_losses) > EARLY_STOPPING and val_losses[-(EARLY_STOPPING+1)] < min(val_losses[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model_bioELMo()\n",
    "        model.load_state_dict(torch.load('checkpoints/model_elmo'))\n",
    "        \n",
    "        test_acc, test_probs_labels, _ = get_test_acc(model, test_loader, labels_test, return_probs_and_labels=True)\n",
    "        test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "        print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7RElEQVR4nO3dd3hUVfrA8e87k0nvhSQkAUITlSbSLBR/KKJUO4oNCyL2VQQ7Lrvq2sWy2AA7ImtdXER2EXSlsyAiKBBKElo66WXm/P6YIQZIzACZTDJ5P8/Dk7n9vQnz3nPPPedcMcaglFLKd1m8HYBSSinP0kSvlFI+ThO9Ukr5OE30Sinl4zTRK6WUj/PzdgC1iY2NNe3atfN2GEop1WysXbs22xgTV9uyJpno27Vrx5o1a7wdhlJKNRsisquuZVp1o5RSPk4TvVJK+ThN9Eop5ePcqqMXkWHAS4AVeMsY89QRyyOA94E2rn0+a4yZ7c62SqmWpbKykoyMDMrKyrwdSrMUGBhIcnIyNpvN7W3qTfQiYgVeBc4DMoDVIvKlMeaXGqvdBvxijBkpInHAryLyAWB3Y1ulVAuSkZFBWFgY7dq1Q0S8HU6zYowhJyeHjIwMUlNT3d7OnaqbvsA2Y0yaMaYCmAuMPvL4QJg4/2qhQC5Q5ea2SqkWpKysjJiYGE3yx0FEiImJOea7IXcSfRKQXmM6wzWvpleAk4E9wEbgLmOMw81tlVItjCb543c8vzt3En1tez1ybOPzgfVAa6An8IqIhLu5rfMgIhNEZI2IrMnKynIjLNUSOUpLyZv7MUVLl2IvKvZ2OEo1C+4k+gwgpcZ0Ms6Se03jgU+N0zZgB9DFzW0BMMa8YYzpbYzpHRdXa+cu1cI5yspInzSJfdOmkX7LRH7r14+dY6/kwIsvUrx8OQ59uKfqkZ+fz2uvvXZc21544YXk5+e7vf60adN49tlnj+tYDc2dVjergU4ikgpkAmOBq45YZzcwBPheROKBk4A0IN+NbZWql6O8nIzb76BkxUoS/zIdW+vWFK9cRcmKFeS8+RY5M19HbDaCTjuN4P79COnXj6Bu3RB/f2+HrpqQQ4l+0qRJRy2z2+1YrdY6t/366689GZpH1ZvojTFVInI78A3OJpKzjDGbRGSia/lMYDowR0Q24qyumWKMyQaobVvPnIryVY6KCjLvvIviH34g8a9/IfKSSwAIOfNMAOxFRZSsWUPJipUUr1pJ9suvkD3jZSQoiODTTyekfz+C+/Uj8JRTkD/4IivfN3XqVLZv307Pnj0577zzGD58OI8//jiJiYmsX7+eX375hTFjxpCenk5ZWRl33XUXEyZMAH4fmqWoqIgLLriAs88+mx9//JGkpCS++OILgoKC6jzu+vXrmThxIiUlJXTo0IFZs2YRFRXFjBkzmDlzJn5+fpxyyinMnTuXpUuXctdddwHO+vhly5YRFhZ2QuctTfFVgr179zY61o0CMJWVZNx9D0X//jcJjz9O1BWX17tNVV4eJatXVyf+im3bAbCEhRHcpw8h/foS3L8/AZ06IRbtM9jYNm/ezMknnwzA419t4pc9Bxt0/6e0DuexkafWumznzp2MGDGCn3/+GYDvvvuO4cOH8/PPP1c3V8zNzSU6OprS0lL69OnD0qVLiYmJOSzRd+zYkTVr1tCzZ08uv/xyRo0axdVXX33YsaZNm0ZoaCj33Xcf3bt35+WXX2bQoEE8+uijHDx4kBdffJHWrVuzY8cOAgICyM/PJzIykpEjRzJ16lTOOussioqKCAwMxM/v8DJ5zd/hISKy1hjTu7bzbpKDmikFziSfee99FP3738Q/8rBbSR7ALyqK8KFDCR86FICqrCxnNc/KlRSvXEnRf/4DgDUqiuB+/Zwl/r798E/Vdt0tUd++fQ9rkz5jxgw+++wzANLT09m6dSsxMTGHbZOamkrPnj0BOP3009m5c2ed+y8oKCA/P59BgwYBcN1113HZZZcB0L17d8aNG8eYMWMYM2YMAGeddRZ/+tOfGDduHBdffDHJycknfI6a6FWTZKqq2DNlCoWLFhH/4ANEjxt33Pvyi4sjYsRwIkYMB6AyM/P3xL9iBYULFzrXa9XKVb/fn+B+/fBP1pbAnlZXybsxhYSEVH/+7rvvWLx4McuXLyc4OJjBgwfX2mY9ICCg+rPVaqW0tPS4jr1gwQKWLVvGl19+yfTp09m0aRNTp05l+PDhfP311/Tv35/FixfTpUuX49r/IZroVZNj7Hb2PPAgB7/+F60mTyb62msbdP+2pCQiL76IyIsvwhhD5a5dFK9YScmqlRT/8F8OfvmVc73k5OoHu8F9+2GLb9WgcajGFxYWRmFhYZ3LCwoKiIqKIjg4mC1btrBixYoTPmZERARRUVF8//33DBgwgPfee49BgwbhcDhIT0/nnHPO4eyzz+bDDz+kqKiInJwcunXrRrdu3Vi+fDlbtmzRRK98i3E42PvwIxz86ivi7rmHmBtv8OjxRAT/du3wb9eOqLFXYIyhfOvW6vr9wkXfUjD/HwD4t29fXc0T3K8vflFRHo1NNbyYmBjOOussunbtygUXXMDw4cMPWz5s2DBmzpxJ9+7dOemkk+jfv3+DHPedd96pfhjbvn17Zs+ejd1u5+qrr6agoABjDPfccw+RkZE88sgjLFmyBKvVyimnnMIFF1xwwsfXh7GqyTAOB/see4z8T+YTe8ftxN12m7dDwtjtlG3eQsnKFRSvXEnJmrWYkhIAArp0cZb2+/UjuE9vrCfYMqKlqO1Bojo2+jBWNUvGGPZNn07+J/OJuXVik0jyAGK1EtT1VIK6nkrMjTdiKisp3fizK/GvIu+jj8h95x2wWAjs2tWZ+Pv3I7hXLyx/0NxOqcakiV55nTGG/X99gvyP5hJz803E3Xmnt0Oqk9hsBPc6jeBepxF76604yssp/d96ileuoGTlKnJmzybnzTfBZiOoR3fXg92+BPXsiUU7bykv0USvvMoYw4Gn/kbe++8Tff31xP3pT82qiaMlIICQ/s4mmgCO4mJK1q2jeIUz8We/9hq8+ioSGOi8QPTrT0i/vgR27Yr46ddPNQ79n6a8xhhD1nPPkfvOO0Rdcw2tptzfrJJ8bSwhIYQOGEDogAEA2AsKKFmzxlm/v2IlWS+8QJZrveDevQnu70z8AV26aOct5TGa6JVXGGPIeuklct56m8grxxL/4APNPsnXxhoRQdiQIYQNGQJAVU4OJatWVSf+oqVLq9cL7tu3ujmnf4cOPvn7UN6hiV55Rfarr5Ez83UiL7uUhEceaTFJzS8mhvALLiDc1WSuct8+V4/dVRSvWE7ht98CYI2NdbXo6UtI//7YUlJazO9INTy9V1SNLnvm62S/8goRF11EwuOPt+gqC1tCAhGjR9P6ib/S8d//psO3i0iY/mdC+vWjeNVK9j36GNuHns/2oeeTN3cuprLS2yE3aycyTDHAiy++SImree2RBg8eTFNtFt5yv2HKK3LefpusF18kfNRIEv8yvUUn+SOJCP4pKURddhlJzz1Lp2XLaL/gn8Q/8jB+MTHsm/Y42y8cTsEXX2Dsdm+H2yx5MtE3ZfotU40mZ84cDjzzLOEXXkjrJ57QIYPrISIEdOhA9LhxtP3oQ1Jen4klNJQ9U6aSNno0Bxctoil2eGzKag5TPHnyZACeeeYZ+vTpQ/fu3XnssccAKC4uZvjw4fTo0YOuXbvy8ccfM2PGDPbs2cM555zDOeec84fH+eijj+jWrRtdu3ZlypQpgHO8++uvv56uXbvSrVs3XnjhBcA5iNopp5xC9+7dGTt2rEfOW+voVaPIff8DDjz1N8KGDqX103/TpoXHSEQIHTSIkAEDKFy0iKyXZpB5510Edu1K3F13EXL2Wc2zDv9fU2HfxobdZ0I3uOCpWhc99dRT/Pzzz6xfvx6ARYsWsXXrVlatWoUxhlGjRrFs2TKysrJo3bo1CxYsAJxj4ERERPD888+zZMkSYmNj6zz8nj17mDJlCmvXriUqKoqhQ4fy+eefk5KSQmZmZvUQyYfeVvXUU08dNlSxJ2iJXnlc3tyP2f+XvxA6ZAhJzz2rSf4EiMVC+LBhtP/qSxKfeAJ7bi7pN9/MrmuuoaSJ1g83ZYsWLWLRokWcdtpp9OrViy1btrB161a6devG4sWLmTJlCt9//z0RERFu73P16tUMHjyYuLg4/Pz8GDduHMuWLaN9+/akpaVxxx13sHDhQsLDw4Hfhyp+//33jxp3vqHoN055VP78+eybNo3QQYNIeuF5xGbzdkg+Qfz8iLz4IsJHDCf/k0/InjmTXVdfQ8iAAcTddRdBXb0//K9b6ih5NxZjDA888AC33HLLUcvWrl3L119/zQMPPMDQoUN59NFH3d5nbaKiotiwYQPffPMNr776KvPmzWPWrFm1DlXc0AlfS/TKY/I/+5y9jzxKyIABJM14SYcA8ACLvz/R48bRcdEiWt13L2U//cTOSy8l4867KN+2zdvhNTlHDlN8/vnnM2vWLIqKigDIzMzkwIED7Nmzh+DgYK6++mruu+8+1q1bV+v2tenXrx9Lly4lOzsbu93ORx99xKBBg8jOzsbhcHDJJZcwffp01q1bd9hQxU8//TT5+fnVsTQknyrR57w9i5CzzyLwpJO8HUqLV/DVP9n74IOEnNGf5JdnYKnxogbV8CxBQcTcdBORV1xB7uw55M6ZQ+HixUSMHEnsHbfj3wBvKfIFRw5T/Mwzz7B582bOOOMMAEJDQ3n//ffZtm0bkydPxmKxYLPZ+Pvf/w7AhAkTuOCCC0hMTGTJkiW1HiMxMZEnn3ySc845B2MMF154IaNHj2bDhg2MHz8eh8MBwJNPPlnnUMUNzWeGKbYXFLB9+Ajs+fnE3HgjsZNu1eTiJQf/9S8y772P4D59SJn5dx3F0Quq8vLIefMt8j74AONwEHnpJcROvLVJvDxFhyk+ccc6TLHPVN1YIyJo/9WXRIwYQc7rr7Nj9BhKVq/2dlgtzsFFi8i8bzJBvU4j5e+vaZL3Er+oKOLvn0yHRd8Qeekl5H8yn+1Dh7L/6WeoysvzdniqFsYYHOXlHtm3zyR6cP7nbv3Uk6S8/RamspJd11zL3semYa+nTk01jML//IfMP91LUPfupMx8HUtwsLdDavFs8fEkPvYYHf71NeHDhpE7ezbbzz2PrBkv6/eiCTDG4CgtpXLvXsp//ZWKHTs80jfCpxL9IaFnnUX7r74kevx48j/5hLThIyhcvNjbYfm0oqVLybjrbgJPOYWUN9/AGhpS/0aq0finpND6b0/R/qsvCTnrLLJfe43t555Hzltv4TjOF1ur4+eoqKDyQBbl27ZRvn07Vbm5WIKDsbVu7ZHjuZXoRWSYiPwqIttEZGotyyeLyHrXv59FxC4i0a5lO0Vko2tZozX0tQQHEz/lftp9/DHWqCgybr+DjDvvovLAgcYKocUo+uG/ZNxxJ4GdO9PmrTexhoZ6OyRVh4COHUme8RLt5s8nsHt3Djz7HNuGDiX3gw8wFRXeDs+nmaoqqnJzKU9Lo/y336g6sB+xWrG1bk3gSSfh36YN1vBwj3R8q/dhrIhYgd+A84AMYDVwpTHmlzrWHwncY4z5P9f0TqC3MSbb3aAa+p2xprKSnFmzyXa9ACL+/slEXHJJ8+xJ2MQUL19O+sRb8W/fnrazZ2H1QIsB5Tkla9Zw4MUXKV2zFltSErG33UbEqJEe7dTWkh7GGocDR1ER9vx8Z1WZMYh/ANbICKyRkcfd5NgTD2P7AtuMMWnGmApgLjD6D9a/EvjIzXgbhdhsxN4ygdQvPiewc2f2PvwIu68fT8WuXd4OrVkrXrWK9Fsn4d+2LW1mva1JvhkK7t2btu+9R8qbb2KNjGTvgw+SNnIUBxcuxLiaAapjY4zBXlxMxZ49znr33btxlJTgFx1NQIcOBHTqiK1Vq0btV+JOok8C0mtMZ7jmHUVEgoFhwD9qzDbAIhFZKyITjjfQhhCQmkqbd98h4fHHKdu0ibRRo8l+801MVZU3w2qWStauJX3irdiSk2gzexZ+UVHeDkkdJxEhdMDZtJv/CUkzXgKLhcy772HHJZdStHSpTw2c5snRKx3l5VTu30/5b1up2LEDe14+ltBQ/Nu2JeCkk7AlJmIJCvJKTYI7ib62qOr6y48E/muMya0x7yxjTC/gAuA2ERlY60FEJojIGhFZk5WV5UZYx0csFqKuuJz2CxYQOnAAWc89z47LL6d00yaPHdPXlK5fT/rNE7DFx9N29mz8YmK8HZJqACJC+NChtP/yC1r/7SkchYWk3zKRXVeNo3jVKm+H1yAaOtGbqiqqcnIo376d8q1bqcrKQgL8sSUnE9jlJPxTUrCGhXm9mtidRJ8BpNSYTgb21LHuWI6otjHG7HH9PAB8hrMq6CjGmDeMMb2NMb3j4uLcCOvE2OJbkfzyyyTNeImqrCx2Xn4F+595Rlsg1KN040Z233Qz1rhY2syZg18j/K1U4xKrlYjRo+nw9QISpj1GZWYmu6+9jt033EjpxgYeabKRNdQwxYMHDKB81y7KtvxK5d69YAx/e/99Bl5/PaePGMGk++8H17sWtm3bxrnnnkuPHj3o1asX27dvB+Dpp5+mW7du9OjRg6lTj2rj0qDceRjrh/Nh7BAgE+fD2KuMMZuOWC8C2AGkGGOKXfNCAIsxptD1+Vvgz8aYhX90zIZ+GFsf+8GDHHjmWfI/+QRbSgqJf36cEFeXaPW70k2b2D3+Bqzh4bR9711siYneDkk1AkdZGXkfzSXn9dex5+cTeu4Q4u50trI6HjUfJP5t1d/YkrulIcOlS3QXpvSdUuuynTt3MmLEiOqhghctWsT8+fN5/fXXq4cpvv/++8nKymLhwoW8+eabgPNOIMzPjw4nn8wPc+cSExGB2GxYI1wPVQMDyc3NJTo6GoBrrrmGyy+/nJEjR9KvXz+mTp3KRRddRFlZGQ6Hg6VLlzJ9+nQWL15McHDwYdu6o8EfxhpjqoDbgW+AzcA8Y8wmEZkoIhNrrHoRsOhQkneJB34QkQ3AKmBBfUneG6zh4SRO/zNt5swBi7B7/A3sefAh7B4aG7o5KtuyhfQbbsQaGkrbd+Zokm9BLIGBxIy/ng6LFxN75x2UrFjJjtFjyJx8f7Nv0FDfMMX333svSz7/nMB9+6nYuRPjcGAJD8e/XSoBnTtjS0jAEhgIwJIlS+jXrx/dunXjP//5D5s2baKwsJDMzEwuuugiAAIDAwkODmbx4sWMHz+eYFenwmNJ8sfDrTZUxpivga+PmDfziOk5wJwj5qUBPU4owkYU0r8f7b/4wvni6lmzKFq2jISHHyLs/PO9XsfmTWW//cbu8TcgQUG0eWcOtqRan8UrH2cNDSFu0iSirryS3FmzyH3vfQ5+/TWRF19M7KRbj+viX1fJu7HUNkyxo7ISR34+P877hH8t/paH/vxnzhs8mEcfewyx2fBPTDyqQ2BZWRmTJk1izZo1pKSkMG3aNMrKyup8kG2MadSc4pM9Y0+EJTCQVvf+idT5n2CLjyfz7nvIuO12Kvft83ZoXlG+fbszydtstH1nDv4pKfVvpHyaX1QUre69lw6LviFq7FjyP/+c7ecPY/+TT1KVk+Pt8P5QXcMUFxYUUJWXR9ry5aT/+CO7Nm4kOCSYaydMYPJDD7EhLQ1rRESdwxSXlZUBEBsbS1FREfPnzwcgPDyc5ORkPv/8cwDKy8spKSlh6NChzJo1q/rBbm5u7lH7bEia6OsQePLJtPt4Lq3uv5/iH38kbfgI8j76qEW1LS7fsYNd118PFqHNnDn4t23r7ZBUE2Jr1YqERx6mw7/+RfiIEeS+9z7bzhvKgRdfxH7woLfDq1XNYYrvu+8+hpxxBpdfcAFn9OlDz759uXLSJEoDg/itpIQBY8fSe8gQnnjqKR5++GHg92GKj3xnbGRkJDfffDPdunVjzJgx9OnTp3rZe++9x4wZM+jevTtnnnkm+/btY9iwYYwaNYrevXvTs2dPnn32WY+et88MU+xJFenp7HvsMYp/XE7Q6aeTOP3PBLRv7+2wPKpi9252XXMtprKStu++Q0DHjt4OSTVx5WlpZL38MoX/WoglPJyYG28k+pqrjxrczps9Y40xmNJSZ0/VggKM3Y5YrdUPVcVL7dyPVYsdptiT/FNSSHn7bRKfeILybdvYMXoM2X//u8+ODVKRkcGu667HlJfTZs5sTfLKLQHt25P8wgukfvYpwaedRtYLL7Bt6PnkvvseDi9/V5yDiB2gfOtWytPSqMrLc3ZmatPG2ZmpdWsswcHNIskfD030bhIRIi++iA4L/knYeeeS9dIMdlxyKaUbNng7tAZ1qM20o6SENrNnHXcTOtVyBZ58Mimvz6Tthx8S0L49+594gu3nDyN//vxG7YV+9CBiBxCbDVtSEoFdujg7M4WHIxbfT4O+f4YNzC82lqTnnyf5tdewFxayc+yV7HviCRzFxfVv3MRV7tvHruvHYy8spM3bbxPYQgaeUp4R3Os02rwzhzaz3sYvNpa9Dz9C2vAROEpLPTasgnE4sBcUULFrN2W//krlnj1gt+MXH09A584EpKbiFxWFWK0eOX5TpYn+OIX93zm0/+dXRF15JXnvvkfayFEUff+9t8M6bpX7D7Druuuw5+XR5u23COp6qrdDUj5ARAg580zazfuY5FdfQfz9seflUbF9O/aDBxsk4VcPIpaZSfmWX6lIT8dR+vsgYv4dO2KLi2vRL6fXh7ENoGTdOvY+/AgVaWmEjxpJ/AMPNKtBvqqysth17XVU7d9PyttvEXzaad4OSfkoY7fzy/oNdAgLxVRUYAkKwi8+/rjeYeAoK8OeX4C9IB9TWQkWC9bwcGdP1ZAQn61vh2N/GOu5QadbkOBevUj9/DNyZr5O9ptvUvz9D8Q/+CDhI4Y3+f9sVTk57Bo/nsp9+2jz5hua5JVHidWKJTiIgI4dsefnU5WVRcXOnVhCQrDFx9f7+klTWYm9oAB7fj6OsjJAsISGOC8WYWEtrkrGXVp100As/v7E3XkHqf+Yj61NCnsmTyb9lluozMz0dmh1qsrLY/f4G6jMyCRl5kyCe9daGFCqwYnF4qxa6dQJW0ICpqyc8rQ0KnbtOmpgQWO3U5WfT/nOnc569337AMGWkEDgSZ0JaNcOv8hIjyX50DruNuqa3xRpib6BBXbuTLsPPyTvgw858OKLbB85ilZ3303UuKuaVGnDnp/P7htupGLXLlL+/hoh/WodVFQpjxKLBb/YWKxRUVTl5GLPzqZ8+3Znu/bwcOyFhc7OVw4HYrPhFxeHNSKienwZ5R4t0XuAWK1EX3sNHb76kuDep7P/iSfYedVVlP32m7dDA5yjde6+8SYqtm0j+ZVXCDnzTG+HpFo4sVqxtYojoHMn/OLisBcWOh+qFhZijYjAP9U1iFh8/Akl+SlTphw2Hv20adN47rnnKCoqYsiQIfTq1Ytu3brxxRdfuL1PYwyTJ0+ma9eudOvWjY8//hiAvXv3MnDgQHr27EnXrl35/vvvsdvtXH/99dXrvvDCC8d9LsdCS/QeZEtKIuX11zn4zwXsf+IJdlxyKbE330TMxIleawFgLypi9803U/bbbyS/PIPQAWd7JQ6lAPY98QTlm48eptgYAw4HWK21vvnojwSc3IWEBx+sddnYsWO5++67mTRpEgDz5s1j4cKFBAYG8tlnnxEeHk52djb9+/dn1KhRbj1j+/TTT1m/fj0bNmwgOzubPn36MHDgQD788EPOP/98HnroIex2OyUlJaxfv57MzMzqYZLzG2mEXC3Re5iIEDFyBO2/XkD4BcPIfu3v7BhzESXr1jV6LPaiYtJvnkDZpl9IfvEFwgYPbvQYlHKHiCDHkeTrc9ppp3HgwAH27NnDhg0biIqKok2bNhhjePDBB+nevTvnnnsumZmZ7N+/3619/vDDD1x55ZVYrVbi4+MZNGgQq1evpk+fPsyePZtp06axceNGwsLCaN++PWlpadxxxx0sXLiQ8PDwBj7D2mmJvpH4RUWR9PTTRIwcyb7HprHrqnFEXXUlcX/603E1LTtWjpIS0ifeQulPP5H0/POEDRni8WMqVZ+6St6edOmllzJ//nz27dvH2LFjAfjggw/Iyspi7dq12Gw22rVrVz0iZX3qaqI+cOBAli1bxoIFC7jmmmuYPHky1157LRs2bOCbb77h1VdfZd68ecyaNavBzq0uWqJvZKEDBtD+qy+Jvu5a8j6aS9rwERT+Z4lHj+koLSX91kmUrvsfSc88Tfj5Qz16PKWasrFjxzJ37lzmz5/PpZdeCkBBQQGtWrXCZrOxZMkSdh3DC1UGDhzIxx9/jN1uJysri2XLltG3b1927dpFq1atuPnmm7nxxhtZt24d2dnZOBwOLrnkEqZPn866Rrqz1xK9F1hCQoh/4AHCL7yQvQ8/QsakSYRdMIyEhx7CLza2QY/lKC8n47bbKVm1itZ/e4rwCy9s0P0r1dyceuqpFBYWkpSURKLrZSnjxo1j5MiR1cMGd+nSxe39XXTRRSxfvpwePXogIjz99NMkJCTwzjvv8Mwzz2Cz2QgNDeXdd98lMzOT8ePH43ANd/7kk0965ByPpD1jvcxUVJAzaxbZr76GBAcTP2UKEReNaZCOVo6KCjJuu53iH34g8a9/JfLiixogYqVOjDeHKfYVOkxxMyP+/sROnEjqF58T0LEjex98kN033EBFevoJ7ddUVJB5510Uf/89CX9+XJO8Ui2YJvomIqB9e9q+9y4J0x6j7KeNpI0cRc6s2cc1rKuprCTz3nsp+u47EqY9RtRll3kgYqVUc6GJvgkRi4WosWNpv+CfhJx5JgeefpqdV4ylbPNmt/dhqqrInHw/hd8uJv7hh4lytSpQSrVcmuibIFtCAsmvvkLSiy9SuX8/Oy69jAPPPe8axKluxm5nz5SpFC5cSKupU4i+elwjRayUaso00TdRIkL4sPPp8M+viBgzmpw33yRt9GiKV66qdX1jt7P3wQc5uGABre67l5jrr2/cgJVSTZZbiV5EhonIryKyTUSm1rJ8soisd/37WUTsIhLtzrbqj1kjI2n917/SZvYscBh2X3cdex95xDnQk4txONj7yKMUfPElcXffRcxNN3kxYqVUU1NvohcRK/AqcAFwCnCliJxScx1jzDPGmJ7GmJ7AA8BSY0yuO9sq94SccQbtv/yC6BtvIP8fn7J9+HAOLlqEcTjYN+1xCj79lNjbbiN24kRvh6qUT2lOwxHXxZ0SfV9gmzEmzRhTAcwFRv/B+lcCHx3ntuoPWIKCiJ88mXafzMMvLo7MO+8ibcRI8ufNI+aWW4i9/TZvh6iUaoLcSfRJQM1G3RmueUcRkWBgGPCP49h2goisEZE1WVlZboTVcgWdeiqp8+bR6r57qdy7l5ibbyLu7rua/NuslPK2hhymeMyYMZx++umceuqpvPHGG9XzFy5cSK9evejRowdDXGNKFRUVMX78eLp160b37t35xz/+UdduPcKdIRBqyx51dacdCfzXGJN7rNsaY94A3gBnz1g34mrRxM+PmJtuIvr66xE/HclCNU/fz/uN7PSiBt1nbEooAy7vXOuyhhymeNasWURHR1NaWkqfPn245JJLcDgc3HzzzSxbtozU1FRyc52pcPr06URERLBx40YA8vLyGvSc6+NOhsgAUmpMJwN76lh3LL9X2xzrtuo4aJJXyn01hynOysqqHqa4srKSBx98kGXLlmGxWKqHKU5ISKhzXzNmzOCzzz4DID09na1bt5KVlcXAgQNJTU0FIDo6GoDFixczd+7c6m2joqI8eJZHcydLrAY6iUgqkIkzmV915EoiEgEMAq4+1m2VUi1TXSVvT2qIYYq/++47Fi9ezPLlywkODmbw4MGUlZVhjKn1LqCu+Y2l3jp6Y0wVcDvwDbAZmGeM2SQiE0WkZhOPi4BFxpji+rZtyBNQSqlj0RDDFBcUFBAVFUVwcDBbtmxhxYoVAJxxxhksXbqUHTt2AFRX3QwdOpRXXnmlevvGrrpxqx29MeZrY0xnY0wHY8xfXfNmGmNm1lhnjjHmqP72tW2rlFLeUtcwxWvWrKF379588MEH9Q5TPGzYMKqqqujevTuPPPII/fv3ByAuLo433niDiy++mB49enDFFVcA8PDDD5OXl0fXrl3p0aMHS5Z49h0UR9JhipVSjUqHKT5xOkyxUkqpw2iiV0opH6eJXinV6JpilXFzcTy/O030SqlGFRgYSE5Ojib742CMIScnh8DAwGPaTnvbKKUaVXJyMhkZGehQJ8cnMDCQ5OTkY9pGE71SqlHZbLbqnqOqcWjVjVJK+ThN9Eop5eM00SullI/TRK+UUj5OE71SSvk4TfRKKeXjNNErpZSP00SvlFI+ThO9Ukr5OE30Sinl4zTRK6WUj9NEr5RSPk4TvVJK+ThN9Eop5eM00SullI/TRK+UUj7OrUQvIsNE5FcR2SYiU+tYZ7CIrBeRTSKytMb8nSKy0bVsTUMFrpRSyj31vmFKRKzAq8B5QAawWkS+NMb8UmOdSOA1YJgxZreItDpiN+cYY7IbLmyllFLucqdE3xfYZoxJM8ZUAHOB0UescxXwqTFmN4Ax5kDDhqmUUup4uZPok4D0GtMZrnk1dQaiROQ7EVkrItfWWGaARa75E+o6iIhMEJE1IrJGXxqslFINx52Xg0st80wt+zkdGAIEActFZIUx5jfgLGPMHld1zrcissUYs+yoHRrzBvAGQO/evY/cv1JKqePkTok+A0ipMZ0M7KllnYXGmGJXXfwyoAeAMWaP6+cB4DOcVUFKKaUaiTuJfjXQSURSRcQfGAt8ecQ6XwADRMRPRIKBfsBmEQkRkTAAEQkBhgI/N1z4Siml6lNv1Y0xpkpEbge+AazALGPMJhGZ6Fo+0xizWUQWAj8BDuAtY8zPItIe+ExEDh3rQ2PMQk+djFJKqaOJMU2vOrx3795mzRptcq+UUu4SkbXGmN61LdOesUop5eM00SullI/TRK+UUj5OE71SSvk4TfRKKeXjNNErpZSP00SvlFI+ThO9Ukr5OE30Sinl4zTRK6WUj9NEr5RSPk4TvVJK+ThN9Eop5eM00SullI/TRK+UUj5OE71SSvk4TfRKKeXjNNErpZSP00SvlFI+ThO9Ukr5OE30Sinl4zTRK6WUj9NEr5RSPs6tRC8iw0TkVxHZJiJT61hnsIisF5FNIrL0WLZVSinlOX71rSAiVuBV4DwgA1gtIl8aY36psU4k8BowzBizW0RaubutUkopz3KnRN8X2GaMSTPGVABzgdFHrHMV8KkxZjeAMebAMWyrlFLKg9xJ9ElAeo3pDNe8mjoDUSLynYisFZFrj2FbAERkgoisEZE1WVlZ7kWvlFKqXu4keqllnjli2g84HRgOnA88IiKd3dzWOdOYN4wxvY0xvePi4twI62jPL/qVH7dnH9e2Sinlq9xJ9BlASo3pZGBPLessNMYUG2OygWVADze3bRAHyyqZvzaDq95cydVvrWR9er4nDqOUUs2OGFNrAfv3FUT8gN+AIUAmsBq4yhizqcY6JwOv4CzN+wOrgLHAlvq2rU3v3r3NmjVrjvlkyirtfLByN68u2UZucQVDT4nn3qEncVJC2DHvSylPsNsdVJXbqSx3UFleRVWF86dz2l79r6ri98+VFc7plkZEsPlbsQVY8QuwOj8HWrH5W7AF+OEX4PxpC7A413Gta/O3IpbaKhN8m4isNcb0rm1Zva1ujDFVInI78A1gBWYZYzaJyETX8pnGmM0ishD4CXAAbxljfnYd/KhtG+SsahFos3Lj2alc0SeF2T/s4I1laQx7aRljeiZx97mdaBsT4qlDKx9ijMFe5aCq3EFFeRVVh5Jwhd2VpJ2fK8tcP8uPmF9z+oj5jqo/LlgdRvg90fm3vC4vxkH177yq0nFM2/r5O5P/YReAmtOB1urfbV3rHb2+BYu1ef4d6i3Re8PxluiPlF9Swcylacz5cQdVdsMVfVK44/86kRAR2ABRKm8zxrhKxLWUgusqHdeSlI+e78A43P9eWCziLHEelhwOL20eKo26nXQCrPjZLIi0vJJpbRwOU+/fsarcTsURf8fK6gu1666plgtz7U8Na2f1s7juJA7/m1X//f1rmQ6sf77FT074b/1HJXqfSvTvPvRjrVd+h8NQUmGnrNJ5+xvkbyXY36pfoubKGCorHM7qjGP8kjq/bK4k7G/5wy/hUSW8OuZb/ZpnKU+5CguVjtrvwMpqKSQccSdXWe6ocx3HMRQWxCLYAqyERgVw5aP9jutcTqjqpjlp1z0WR1Xdt3hF5VVszChgY3YxflVCl8RwTk4Iw9ZMb8daLJHfb81rKQnXPq/53nYrz6l+DuBvJaiBH+XZq2p57nLYReLo+VYP/R/1qUQ/8IrO9a4zAti6v5Dnv/2N53/eR1RZAZMGd+SaM9oSaLN6PkilVItg9bNg9bMQGGLzdii+VXVzrH7KyOfZRb+x7Lcs4sMDuHNIJy7vnaIlfKVUs/NHVTctOqN1T47k3Rv6MndCf5Kjgnnos58Z8txSPv9fJvZjqF9TSqmmrEUn+kP6t49h/sQzmH19H0IC/Lj74/Vc+NL3LNq0j6Z4x6OUUsdCE72LiHBOl1YsuONsXrnqNCrtDia8t5Yxr/3If7fpsApKqeZLE/0RLBZhRPfWLLpnIE9f0p2sg2WMe2slV725gnW787wdnlJKHbMW/TDWHeVVdj50DauQXVTBuSfHc9/5nemSEO7t0JRSqlqL6TDlScXlVcz5cSczl26nqLyKUT1ac8+5nWkXq8MqKKW8TxN9AyooqeT1ZduZ/d+dVNgdXN47hTuHdCQxIsjboSmlWjBN9B5woLCM15Zs54OVuxARru3fllsHdyAmNMDboSmlWiBN9B6UnlvCjH9v5R/rMgiyWblxQHtuGpBKeKD3e8MppVoOTfSNYNuBIl749jcWbNxLZLCNWwd14Noz2hHkr8MqKKU8TxN9I/o5s4BnF/3Kd79m0SosgDuGdOKK3in46wiHSikP0kTvBat25PLMN1tYvTOPlOgg7jm3M6N7JmFtgW++UUp5no514wV9U6OZd8sZzBnfh/BAG3+at4FhLy5j4c86rIJSqnFpovcgEWHwSa346vazeW1cL+zGMPH9tYx+9b98vzVLE75SqlFoom8EFotwYbdEFt09kGcu7U5OUQXXvL2KK99cwdpdud4OTynl47SO3gvKq+zMXZXOy//ZRnZROUO6tOLeoSdxSmsdVkEpdXz0YWwTVVLhGlbhu+0cLKtiZI/W3HNuJ9rHhXo7NKVUM6OJvokrKK3kzWVpvP3DDirsDi47PZk7h3SidaQOq6CUco8m+mYiq7CcV5ds48OVuwG4un9bJp3TgVgdVkEpVY8Tbl4pIsNE5FcR2SYiU2tZPlhECkRkvevfozWW7RSRja75LS97H4O4sACmjTqV/9w3iDGntWbOjzsY+PQSnlv0KwWlld4OTynVTNVbohcRK/AbcB6QAawGrjTG/FJjncHAfcaYEbVsvxPobYxx+zVNLbVEf6TtWc5hFf75014igmxMHNSB685sS7C/n7dDU0o1MSdaou8LbDPGpBljKoC5wOiGDFDVrkNcKK9c1YsFd57N6W2j+NvCLQx65jveXb6TiiqHt8NTSjUT7iT6JCC9xnSGa96RzhCRDSLyLxE5tcZ8AywSkbUiMqGug4jIBBFZIyJrsrKy3Aq+pTi1dQSzru/D/IlnkBobwqNfbOL/nvuO+WszsDua3jMWpVTT4k7VzWXA+caYm1zT1wB9jTF31FgnHHAYY4pE5ELgJWNMJ9ey1saYPSLSCvgWuMMYs+yPjqlVN3UzxvD91mye+eZXNmYW0CEuhKGnJtAlIYyTE8NJjQ3BZtV+cEq1NH9UdeNOZW8GkFJjOhnYU3MFY8zBGp+/FpHXRCTWGJNtjNnjmn9ARD7DWRX0h4le1U1EGNg5jgGdYvlm0z7+vjSNt75Po9LuvGD7Wy10bBVKl8QwTk4Ip0tiGF0SwokL05Y7SrVU7iT61UAnEUkFMoGxwFU1VxCRBGC/McaISF+cVUI5IhICWIwxha7PQ4E/N+gZtFAiwrCuiQzrmkhFlYO07CK27C1k876DbNlbyH+3ZfPpuszq9WND/emSEE6XhDC6JDp/dmwVSqBNx8tXytfVm+iNMVUicjvwDWAFZhljNonIRNfymcClwK0iUgWUAmNdST8e+ExEDh3rQ2PMQg+dS4vl72dxJfFwxtR4fJJbXMEWV+Lfsu8gW/YV8t6KXZS7HuRaLUL72JDqxH+yq/SfGBGI62+mlPIB2mGqhbE7DDtziquT/+a9hWzee5DM/NLqdcID/eiSGM7JrtL/yYnhdI4P1WadSjVhJ1pHr3yI1SJ0iAulQ1wow7snVs8/WFbJr/sK2bL3IJtdP+evzaC4wg6ACLSLCXFW/bjq/k9OCCc5KgiLvkxFqSZNE70CIDzQRp920fRpF109z+EwZOSVVtf7H6r+WbhpH4duBEP8rZx0qOTv+nlSQpi+HF2pJkSrbtQxK6mo4rf9RWzZ60z8m10/aw7TkBQZVF3nf6jlT7uYYPy06adSHqFVN6pBBfv70TMlkp4pkdXzjDHsO1h2WMufLfsOsuTXrOpOXQF+FjrHh1W3/Dl0BxAd4u+lM1GqZdBErxqEiJAYEURiRBDndGlVPb+s0s72rKLDqn6W/HqAT9ZmVK/TKiygRuJ3lv47xIXi76elf6UagiZ65VGBNiunto7g1NYRh83PKiyvbvp56A5g9vYcKuzOpp9+FnF2/KrR7v+URGfHL236qdSx0USvvCIuLIC4sDgGdIqrnldpd7Aju7i6zn/L3oOs3JHL5+t/74gdHeJPl4QwereNom9qDL3aRmqzT6XqoQ9jVZOXX1JRnfi37Cvk5z0F/LLnIA7jLPl3S46gX2oM/VKjOb1dlLb4US2SvmFK+ZzCskrW7spj5Y5cVu3I5aeMfCrtBovAKa3D6dsuhn7to+nbLpoofdirWgBN9MrnlVbY+d/uPFbsyGXVjhz+tzu/eqiHk+LD6Jsa7Uz8qdG0Cgv0crRKNTxN9KrFKa+y81NGAat25LIiLYe1u/IocfXybR8bUiPxx5CkL2FXPkATvWrxKu0ONu05yKodOaxMy2XVzlwKy6oASI4Kom9qNP1TY+ibGk3bmGBt2aOaHU30Sh3B7jBs2XeQVTtyqxN/bnEFAPHhAfR1PdztlxpNx1ahmvhVk6eJXql6GGPYdqCIlTtynf/ScjhQWA44m3T2bfd7HX+XhHCsOpCbamJ0CASl6iEidIoPo1N8GFf3b4sxhl05Jc46/h05rNqRy8JN+wDnMM592v1ex9+1dbiO4aOaNE30StVCRGgXG0K72BAu7+N8k2ZmfimrXEl/ZVou/95yAIBgfyunt41yVvW0j6F7cgQBfvrmLtV0aNWNUsfpQGEZq1zt+Fem5fLr/kLAOXjbaW0i6ZsaQ//UaE5rE0WQvyZ+5VlaR69UI8grrmDVTlfi35FT3XvXZhW6J0c6m3SmRnN62yjCtPeuamCa6JXygoNllazdmed6wJvDxowCqhzO3rtdkyJcD3hj6NMuishg7b2rTowmeqWagJKKKtbtymfVjhxW7MhlfXo+FVUORJy9dw/V8fdpF01cWIC3w1XNjCZ6pZqgsko7G9LzXVU9uazdlUdppbP3boe4kN/b8rePJjFCe++qP6aJXqlmoNLuYGNmgevhbg5rduZRWO7svds6IpD4iEBiQvyJCQkgOtTf+TnUn+iQgBqf/bXFTwuliV6pZsjuMGx2jcm/MSOfnOIKsosqyC0uJ6eogipH7d/dsAC/6gtBdEgAsa4LQHSIP7GhAUS7LgoxIc7P+iYv33DCHaZEZBjwEmAF3jLGPHXE8sHAF8AO16xPjTF/dmdbpVTtrBaha1IEXZMijlpmjOFgWRU5ReXkFleQU1xBjusi4LwYOP9l5JXwU0Y+ucV/cGEI9HPdEbguAjXuFA5dJGJCAogJ9ScqWC8MzVG9iV5ErMCrwHlABrBaRL40xvxyxKrfG2NGHOe2SqljICJEBNmICLLRPq7+9Y0xHCytIqe4vPqikFNcTm6R6yJR7LxIpOeWsD7deWGw13FhCA/0IyY0wHXHcPjdQc3PsaH+RIX4Y9New17nTom+L7DNGJMGICJzgdGAO8n6RLZVSjUQESEi2EZEsHsXBofDcLCsss47hWzXncSunBLW7c4nr6TuC0NEkO2wi8IfVSdFB/vrcBIe4E6iTwLSa0xnAP1qWe8MEdkA7AHuM8ZsOoZtEZEJwASANm3auBGWUspTLBYhMtifyGB/Orh5YSgoPXRhcF4EsosryD10kXB93pFdzNpdeeQWV1DHdcF5YQh1XgASIwJpHRlE64hAEiOCSIwMpHVEEJHBNh1R9Bi4k+hr+20e+SdaB7Q1xhSJyIXA50AnN7d1zjTmDeANcD6MdSMupVQTYbEIUSHOqpqOrULrXd/hMOSXVh52p1DzIpFTVEFWYTlrd+Xx9ca9VNoPTwlBNmt10k+MCCQxMoikSOfFoLXrZ0iADuV1iDu/iQwgpcZ0Ms5SezVjzMEan78WkddEJNadbZVSLY/FItVVNx1b/fG6Dochu6icPQVl7M0vJTO/lL0FZewtKGVPfhnLtmZxoLCcIxsQhgf6Oe8GIoOq7wwSXXcGSZFBxEcEtJimqO4k+tVAJxFJBTKBscBVNVcQkQRgvzHGiEhfwALkAPn1bauUUn/EYhFahQfSKjyQnimRta5TaXewr6DssAuA86fz8/9255FXUnnUdrGhAa47gENVRM7qoUN3Bq3CAn3i3QP1JnpjTJWI3A58g7OJ5CxjzCYRmehaPhO4FLhVRKqAUmCscTbQr3VbD52LUqqFslktpEQHkxIdXOc6pRX26ovAnoJS9h66GBSUkZZVzA9bsyl2vVf4EKtFSAgPrK4ecj4rCDzsTiE6xL/JPy/QDlNKKcXvfRP2ui4Ce1x3BIc+7y0oY29+GRV2x2HbBfhZalQN/f6MIDEykCTXxaAxRivVN0wppVQ9avZN6JIQXus6xhhyiiuqq4T2ui4AzulSftyezf6DZUe1KAoL8KtRJeS6M6jxMzEikECb554XaKJXSik3iQixoQHEhgbQPbn2darsDg4Ulv9eTZT/+8Vgb0EZm/YUkF1UcdR2MSH+dIgLZd7EMxo8bk30SinVgPysluo6/NPb1r5OWaWdfQWHPyvIzC/DU1XpmuiVUqqRBdqs1e8kbgza11gppXycJnqllPJxmuiVUsrHaaJXSikfp4leKaV8nCZ6pZTycZrolVLKx2miV0opH9ckBzUTkSxg13FuHgtkN2A4zYGes+9raecLes7Hqq0xptb3gTXJRH8iRGRNXSO4+So9Z9/X0s4X9JwbklbdKKWUj9NEr5RSPs4XE/0b3g7AC/ScfV9LO1/Qc24wPldHr5RS6nC+WKJXSilVgyZ6pZTycT6T6EVkmIj8KiLbRGSqt+NpDCIyS0QOiMjP3o6lMYhIiogsEZHNIrJJRO7ydkyeJiKBIrJKRDa4zvlxb8fUWETEKiL/E5F/ejuWxiAiO0Vko4isF5E1DbpvX6ijFxEr8BtwHpABrAauNMb84tXAPExEBgJFwLvGmK7ejsfTRCQRSDTGrBORMGAtMMaX/84iIkCIMaZIRGzAD8BdxpgVXg7N40TkT0BvINwYM8Lb8XiaiOwEehtjGryTmK+U6PsC24wxacaYCmAuMNrLMXmcMWYZkOvtOBqLMWavMWad63MhsBlI8m5UnmWcilyTNte/5l86q4eIJAPDgbe8HYsv8JVEnwSk15jOwMcTQEsnIu2A04CVXg7F41xVGOuBA8C3xhifP2fgReB+wOHlOBqTARaJyFoRmdCQO/aVRC+1zPP5Uk9LJSKhwD+Au40xB70dj6cZY+zGmJ5AMtBXRHy6mk5ERgAHjDFrvR1LIzvLGNMLuAC4zVU12yB8JdFnACk1ppOBPV6KRXmQq576H8AHxphPvR1PYzLG5APfAcO8G4nHnQWMctVZzwX+T0Te925InmeM2eP6eQD4DGeVdIPwlUS/GugkIqki4g+MBb70ckyqgbkeTL4NbDbGPO/teBqDiMSJSKTrcxBwLrDFq0F5mDHmAWNMsjGmHc7v8n+MMVd7OSyPEpEQVwMDRCQEGAo0WGs6n0j0xpgq4HbgG5wP6OYZYzZ5NyrPE5GPgOXASSKSISI3ejsmDzsLuAZnCW+969+F3g7KwxKBJSLyE84CzbfGmBbR3LCFiQd+EJENwCpggTFmYUPt3CeaVyqllKqbT5TolVJK1U0TvVJK+ThN9Eop5eM00SullI/TRK+UUj5OE71SSvk4TfRKKeXj/h9eLM4Fdg0TjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_accs, label='test acc')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.plot(val_accs, label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('figures/bioelmo_loss_lr_small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
