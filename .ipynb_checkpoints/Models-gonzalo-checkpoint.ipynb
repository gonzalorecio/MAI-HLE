{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xml.dom.minidom import parse, parseString\n",
    "from nltk import tokenize as tk\n",
    "import nltk\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "\n",
    "class Question(object):\n",
    "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
    "        self.question_id = q_id\n",
    "        self.question = q\n",
    "        self.answer_ids = a_ids\n",
    "        self.answers = a\n",
    "        self.reference_rank = r\n",
    "        self.system_rank = s\n",
    "        self.labels = l\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "class QuestionsAndAnswers(list):\n",
    "    def __init__(self, dataset='Train', load_external_data=False):\n",
    "        ''' dataset = {Train,Test,Validation} '''\n",
    "        list.__init__(self)\n",
    "        self.PATH = 'MEDIQA2019_datasets/MEDIQA_Task3_QA/'\n",
    "        p = self.read_dataset(dataset)\n",
    "        self.extend(self.read_dataset(dataset))\n",
    "        if load_external_data:\n",
    "            self.extend(self.read_external_dataset())\n",
    "        \n",
    "        self.references = [np.array(q.reference_rank) for q in self]\n",
    "        self.labels = [np.array(q.labels) for q in self]\n",
    "\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
    "        return re.sub(r'\\[\\d\\]', '', s)\n",
    "\n",
    "    def get_answers(self, answers):\n",
    "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
    "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
    "        for answer in answers:\n",
    "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
    "            a_id = answer.getAttribute('AID')\n",
    "            reference = int(answer.getAttribute('ReferenceRank'))\n",
    "            system = int(answer.getAttribute('SystemRank'))\n",
    "            label = answer.getAttribute('ReferenceScore')\n",
    "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
    "        return answs, answs_ids, rank, chiqa, y\n",
    "    \n",
    "    def get_system_ranks(self):\n",
    "          return [q.system_rank for q in self]\n",
    "        \n",
    "    def get_reference_ranks(self):\n",
    "          return [q.reference_rank for q in self]\n",
    "        \n",
    "    def get_labels(self):\n",
    "          return [q.labels for q in self]\n",
    "\n",
    "    def read_dataset(self, dataset='Train'):\n",
    "        i = 0\n",
    "        indx2id = []\n",
    "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
    "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
    "        for filename in os.listdir(self.PATH):\n",
    "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
    "            tree = parse(self.PATH + filename)\n",
    "            questions = tree.getElementsByTagName('Question')\n",
    "            for question in questions:\n",
    "                qelem = question.getElementsByTagName('QuestionText')\n",
    "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
    "                # print(q) # --> questions\n",
    "                answers = question.getElementsByTagName('Answer')\n",
    "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
    "                QA.append([q,answers_list, rank, labels])\n",
    "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
    "                # QA2.append([q,answers_list, rank, system, labels])\n",
    "                QA2.append(question)\n",
    "                indx2id.append(q_id); i+=1;\n",
    "                # break\n",
    "        return QA2\n",
    "    \n",
    "    def read_external_dataset(self):\n",
    "        QA = []\n",
    "        PATH_EXTRA = 'MedQuAD/'\n",
    "        for filename in os.listdir(PATH_EXTRA + '/'):\n",
    "            if any(s in filename for s in ('CDC', 'SeniorHealth', 'GARD', 'GHR', 'NIDDK')): # CDC, SeniorHealth, GARD,\n",
    "                dirname = PATH_EXTRA + '/' + filename\n",
    "                for file in os.listdir(dirname):\n",
    "                    fullname = dirname + '/' + file\n",
    "                    tree = parse(fullname)\n",
    "                    questions = tree.getElementsByTagName('QAPair')\n",
    "                    Q, QT, = [], []; QTypes = {}\n",
    "                    for question in questions:\n",
    "                        qelem = question.getElementsByTagName('Question')\n",
    "                        q, qid = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('qid')\n",
    "                        qtype = qelem[0].getAttribute('qtype')\n",
    "                        if question.getElementsByTagName('Answer')[0].firstChild is None: continue\n",
    "                        a = self.preprocess_text(question.getElementsByTagName('Answer')[0].firstChild.nodeValue)\n",
    "                        if qtype not in QTypes: \n",
    "                            QTypes[qtype] = {'q': q, 'a': [a]}\n",
    "                        else: \n",
    "                            QTypes[qtype]['a'].append(a)\n",
    "                        Q.append(q); QT.append(q + qtype)\n",
    "\n",
    "                    assert len(set(Q)) == len(set(QT)), 'Error reading MedQuAD dataset'\n",
    "                    for qtype in QTypes:\n",
    "                        q = QTypes[qtype]['q']\n",
    "                        # positive examples\n",
    "                        ans = QTypes[qtype]['a']\n",
    "                        question = Question(q_id=-1, q=q, a_ids=-1, a=ans, \n",
    "                                            r=[1]*len(ans), \n",
    "                                            s=[], l=[1]*len(ans))\n",
    "                        QA.append(question)\n",
    "                        # negative examples\n",
    "                        for qtype_other in QTypes:\n",
    "                            if qtype_other != qtype:\n",
    "                                ans_wrong = QTypes[qtype_other]['a']\n",
    "                                question = Question(q_id=-1, q=q, a_ids=[], a=ans_wrong, \n",
    "                                                    r=[int(len(ans))+1]*len(ans_wrong), \n",
    "                                                    s=[], l=[0]*len(ans_wrong))\n",
    "                                QA.append(question)\n",
    "                                \n",
    "        return QA\n",
    "\n",
    "    def output_predictions(self, predictions, labels, file=''):\n",
    "        assert len(predictions) == len(self)\n",
    "        print('question_id,answer_id,label')\n",
    "        with open(f'task3/sample_submission_round_2_{file}.csv', mode='w') as csv_file:\n",
    "            for i, p in enumerate(predictions):\n",
    "                q_id = self[i].question_id\n",
    "                answers = self[i].answer_ids\n",
    "                assert len(p) == len(answers), f'{len(p)} != {len(answers)}'\n",
    "                # order = np.array(a)[np.argsort(p)]\n",
    "                p = self.normalize_sequence(p)\n",
    "                order = np.array(answers)[np.argsort(p)]\n",
    "                # order = np.array(answers)[np.array(p)-1]\n",
    "                lab = labels[i]\n",
    "                ordered_lab = np.array(lab)[np.argsort(p)]\n",
    "                if file == '':\n",
    "                    \n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        print(f\"{q_id},{a_id},{int(l)}\")\n",
    "                else:\n",
    "                    for a_id, l in zip(order,ordered_lab):\n",
    "                        csv_file.write(f\"{q_id},{a_id},{int(l)}\\n\")\n",
    "            \n",
    "    def normalize_sequence(self, seq):\n",
    "        seq = np.array(seq)\n",
    "        a = np.argsort(seq)\n",
    "        seq[a] = list(range(1,len(seq)+1))\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, predictions):\n",
    "        preds = np.concatenate(predictions)\n",
    "        true  = np.concatenate(self.labels) \n",
    "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
    "        return accuracy_score(true, preds)\n",
    "\n",
    "    def precision(self, predictions):\n",
    "        precisions = []\n",
    "        num_answers = []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
    "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
    "            if len(p) == 0:\n",
    "                print(predictions[i])\n",
    "            correct = sum([a == b for a,b in zip(p, r)])\n",
    "            # for a,b in zip(p, r)\n",
    "            # num_answers.append(len(p))\n",
    "            precisions.append(correct/len(p))\n",
    "        return np.mean(precisions)\n",
    "        # return np.average(np.array(precisions), weights=num_answers)\n",
    "\n",
    "    def mean_spearmanr(self, predictions):\n",
    "        assert len(predictions) == len(self.references)\n",
    "        count, total = 0, 0\n",
    "        preds, refs = [], []\n",
    "        for i in range(len(predictions)):\n",
    "            labels = self.labels[i]\n",
    "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
    "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
    "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
    "            preds += p; refs += r\n",
    "            if len(r) == 1:\n",
    "                total += 1\n",
    "                count += 1\n",
    "            elif len(r) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                total += 1\n",
    "                count += spearmanr(p, r)[0]\n",
    "        return spearmanr(preds, refs)[0]\n",
    "        # return count/total\n",
    "\n",
    "    def mean_reciprocal_rank(self, predicted):\n",
    "        rs = []\n",
    "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
    "            res = np.array(a)[np.argsort(b)]\n",
    "            labels = self[k].labels\n",
    "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
    "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
    "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = QuestionsAndAnswers(dataset = 'Train', load_external_data=True) \n",
    "QA_val = QuestionsAndAnswers(dataset = 'Validation')\n",
    "QA_test = QuestionsAndAnswers(dataset = 'Test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52297, 25, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(QA), len(QA_val), len(QA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_ranks = QA_test.get_system_ranks()\n",
    "reference_ranks = [q.reference_rank for q in QA_test]\n",
    "labels = [q.labels for q in QA_test]\n",
    "system_labels = [np.ones(len(l)) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA.output_predictions(reference_ranks, labels)\n",
    "# QA.output_predictions(system_ranks, system_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "QA_test.output_predictions(system_ranks, system_labels, file='test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test2.csv\n",
      "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}\n"
     ]
    }
   ],
   "source": [
    "import evaluator\n",
    "\n",
    "def evaluate(filename):\n",
    "    for task in [3]:\n",
    "        print(f\"Testing Task (Round-2) : {task}\")\n",
    "        answer_file_path = f\"task{task}/ground_truth_round_2.csv\"\n",
    "        _client_payload = {}\n",
    "        _client_payload[\"submission_file_path\"] = f\"task{task}/sample_submission_round_2_{filename}.csv\"\n",
    "\n",
    "        # Instaiate a dummy context\n",
    "        _context = {}\n",
    "        # Instantiate an evaluator\n",
    "        aicrowd_evaluator = evaluator.MediqaEvaluator(answer_file_path, task=task, round=2)\n",
    "        # Evaluate\n",
    "        result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
    "        print(result)\n",
    "\n",
    "evaluate('test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline\n",
    "\n",
    "Testing Task (Round-2) : 3\n",
    "{'score_acc': 0.5167118337850045, 'score_secondary_spearman': 0.3149635036496349, 'meta': {'MRR': 0.895, 'Precision': 0.5167118337850045}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "model_name = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "# model_name = 'dmis-lab/biobert-large-cased-v1.1'\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-large-cased-v1.1\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# model = BertModel.from_pretrained('dmis-lab/biobert-large-cased-v1.1',\n",
    "#                                   output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "#                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bert_sentence_embedding(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        CLS = outputs[0][0]\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    # print(len(hidden_states.shape))\n",
    "    token_vecs = hidden_states[-2][0]\n",
    "\n",
    "    # Calculate the average of all n token vectors.\n",
    "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "\n",
    "    return sentence_embedding\n",
    "\n",
    "def get_CLS(sentence):\n",
    "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    CLS = outputs[0][:,0,:]\n",
    "    return CLS\n",
    "\n",
    "def get_full_sentence_embedding(sentence):\n",
    "    embeddings = []\n",
    "    e = 0\n",
    "    max_size = 1024#512\n",
    "    for i in range(int(len(sentence)/max_size)+1):\n",
    "#         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "#         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "        e = get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "#         print(e)\n",
    "        embeddings.append(e)\n",
    "    embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "    print(embedding)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 7\n",
    "# q = get_bert_sentence_embedding(QA[K].question)\n",
    "# ans = [get_full_sentence_embedding(a) for a in QA[K].answers] # 512 is the maximum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8469bc35fcb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Label,Rank,Similarity'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ans' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach(), a.detach())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "marked_text = \"[CLS] \" + QA[K].question + \" [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(marked_text, add_special_tokens=True)\n",
    "print(tokenized_text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "a = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2280, -0.4502,  0.1192,  ...,  0.1038,  0.2135,  0.4945],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][:,0,:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels)\n",
    "# lr_clf = LogisticRegression()\n",
    "# lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "rankings  = flatten([q.reference_rank for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val]) \n",
    "rankings_val  = flatten([q.reference_rank for q in QA_val])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test])\n",
    "rankings_test  = flatten([q.reference_rank for q in QA_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 32#64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset(Dataset):\n",
    "    def __init__(self, X, y, r, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        self.r = np.array(r)\n",
    "        for q, a in X:\n",
    "            _q = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + q + \" [SEP]\"))[:max_len_seq]\n",
    "            _q += [0]*(max_len_seq-len(_q))\n",
    "            _a = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[CLS] \" + a + \" [SEP]\"))[:max_len_seq]\n",
    "            _a += [0]*(max_len_seq-len(_a))\n",
    "            self.X.append([_q, _a])\n",
    "        self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "        rank  = torch.FloatTensor([self.r[index]])\n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, rank, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset(X=sentences, y=labels, r=rankings)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create validation dataset\n",
    "val_dataset = MEDIQA_Dataset(X=sentences_val, y=labels_val, r=rankings_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset(X=sentences_test, y=labels_test, r=rankings_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_clf.bert.config.output_attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "#         self.bert_q = AutoModel.from_pretrained(model_name)\n",
    "#         self.bert_a = AutoModel.from_pretrained(model_name)\n",
    "        modules = [self.bert.embeddings, *self.bert.encoder.layer[:-2]]\n",
    "#         modules = [self.bert_q.embeddings, *self.bert_q.encoder.layer[:-1],\n",
    "#                   self.bert_a.embeddings, *self.bert_a.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "        for module in modules:\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*self.bert.config.hidden_size, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        CLS1 = self.get_CLS(self.bert, q)\n",
    "        CLS2 = self.get_CLS(self.bert, a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([CLS1, CLS2], dim=1)\n",
    "#         print('concat:', x.shape, x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = nn.SELU()(x)\n",
    "#         x = nn.LeakyReLU(0.1)(x)\n",
    "        x = F.dropout(x, 0.15)\n",
    "        x = self.linear2(x)\n",
    "        x = nn.SELU()(x)\n",
    "        x = F.dropout(x, 0.15)\n",
    "        x = self.linear3(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, CLS1, CLS2\n",
    "    \n",
    "    def set_train(self):\n",
    "        self.train()\n",
    "        self.bert.train()\n",
    "#         self.bert_a.train()\n",
    "#         self.bert_q.train()\n",
    "        \n",
    "    def set_eval(self):\n",
    "        self.eval()\n",
    "        self.bert.eval()\n",
    "#         self.bert_a.eval()\n",
    "#         self.bert_q.eval()\n",
    "\n",
    "    def get_CLS(self, model, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "#         indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#         segments_ids = [1] * len(indexed_tokens)\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = model(tokens_tensor)\n",
    "        CLS = outputs[0][:,0,:]\n",
    "        return CLS\n",
    "    \n",
    "    def get_hidden_state_average(self, indexed_tokens):\n",
    "        # Map the token strings to their vocabulary indeces.\n",
    "        tokens_tensor = indexed_tokens\n",
    "#         segments_tensors = torch.tensor([segments_ids])\n",
    "        outputs = self.bert(tokens_tensor)\n",
    "#         print(outputs.shape)\n",
    "        hidden_state = torch.mean(outputs[0][:,:,:], dim=1)\n",
    "#         print(hidden_state.shape)\n",
    "        return hidden_state\n",
    "\n",
    "    def get_full_sentence_embedding(self, sentence):\n",
    "        embeddings = []\n",
    "        e = 0\n",
    "        max_size = 1024#512\n",
    "        for i in range(int(len(sentence)/max_size)+1):\n",
    "    #         print(i, max_size*(i+1), len(sentence)/max_size)\n",
    "    #         e = get_bert_sentence_embedding(sentence[i*max_size:max_size*(i+1)])\n",
    "            e = self.get_CLS(sentence[i*max_size:max_size*(i+1)])\n",
    "    #         print(e)\n",
    "            embeddings.append(e)\n",
    "        embedding = torch.mean(torch.stack(embeddings), dim=0)\n",
    "        print(embedding)\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del bert_clf\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.max_memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_clf = MEDIQA_Model()\n",
    "bert_clf = bert_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bert_clf.bert.encoder.layer)\n",
    "# bert_clf.bert.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58836"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, data_loader, true_labels, return_probs_and_labels=False):\n",
    "    model.set_eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,r,q,a in tqdm.tqdm(data_loader):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_loss(x1, x2, y):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        return 1-cos(a,b)\n",
    "    margin = torch.tensor(1.0).to(device)\n",
    "    loss = y*dist(x1,x2) + (1-y)*torch.max(torch.tensor(0.0).to(device), margin - dist(x1,x2))\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def ranking_loss2(x1, x2, y, rank):\n",
    "    def dist(a,b):\n",
    "        cos = nn.CosineSimilarity(dim=1)\n",
    "        return 1-cos(a,b)\n",
    "    margin = torch.tensor(0.75).to(device)\n",
    "    mini_margin = 0.05*(rank-1.0)\n",
    "    loss = y*torch.max(torch.tensor(0.0).to(device), mini_margin - dist(x1,x2)) + (1-y)*torch.max(torch.tensor(0.0).to(device), margin - dist(x1,x2))\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in np.array(list(bert_clf.parameters())):\n",
    "#     print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.53794145584106456\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.6571298241615295\n",
      "Epoch 1 mean loss: 0.5474659464184644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.66it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5982905982905983    Val loss:  0.738619858152392\n",
      "Test acc: 0.4832881662149955   Test loss: 0.8417277050873954\n",
      "\n",
      "step 0.56159788370132453\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.22253745794296265\n",
      "Epoch 2 mean loss: 0.5413857674493342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5982905982905983    Val loss:  0.725190596349631\n",
      "Test acc: 0.48148148148148145   Test loss: 0.8413347367258055\n",
      "\n",
      "step 0.277003347873687745\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.8372031450271606\n",
      "Epoch 3 mean loss: 0.4876113094713597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "100%|██████████| 35/35 [00:52<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5854700854700855    Val loss:  0.8181029799673036\n",
      "Test acc: 0.4869015356820235   Test loss: 0.9434174953009321\n",
      "\n",
      "step 0.2611778080463409465\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0.009181246161460876\n",
      "Epoch 4 mean loss: 0.2590569324073154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.62it/s]\n",
      "100%|██████████| 35/35 [00:53<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.6410256410256411    Val loss:  0.8949429866444565\n",
      "Test acc: 0.5302619692863595   Test loss: 1.1591606748280971\n",
      "\n",
      "step 0.1834899038076400877\r"
     ]
    }
   ],
   "source": [
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bert_clf.parameters(), lr=5e-5, weight_decay=0)\n",
    "bert_clf.set_train()\n",
    "EPOCHS = 200\n",
    "EARLY_STOPPING = 10\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "train_losses, test_losses, val_losses, val_accs, test_accs = [], [], [], [], []\n",
    "for epoch_num in range(EPOCHS):\n",
    "    losses = []\n",
    "    bert_clf.set_train()\n",
    "    for step_num, batch_data in enumerate(train_loader):\n",
    "        y_true, rank, questions, answers = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        if questions.shape != answers.shape: continue\n",
    "        logits, CLS1, CLS2 = bert_clf(questions.to(device), answers.to(device))\n",
    "        # loss = loss_func(logits, y_true.to(device))\n",
    "#         loss = 0.2*ranking_loss2(CLS1, CLS2, y_true.to(device), rank.to(device)) + 0.8*loss_func(logits, y_true.to(device))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "\n",
    "\n",
    "        bert_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print('step', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    val_acc, val_probs_labels, _   = get_test_acc(bert_clf, val_loader,  labels_val,  return_probs_and_labels=True)\n",
    "    test_acc, test_probs_labels, _ = get_test_acc(bert_clf, test_loader, labels_test, return_probs_and_labels=True)\n",
    "    val_accs.append(val_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    val_loss  = loss_func(torch.from_numpy(val_probs_labels),  torch.from_numpy(np.array(labels_val, dtype=np.double))).item()\n",
    "    test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Val acc: ', val_acc, '   Val loss: ', val_loss)\n",
    "    print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "    if len(test_accs) <= 1 or test_acc > max(test_accs[:-1]):\n",
    "        torch.save(bert_clf.state_dict(), 'checkpoints/model')\n",
    "    if len(val_losses) > EARLY_STOPPING and val_losses[-(EARLY_STOPPING+1)] < min(val_losses[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model()\n",
    "        model.load_state_dict(torch.load('checkpoints/model'))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_accs, label='test acc')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.plot(val_accs, label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('figures/biobert_loss_lr_small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/mediqa_model_clinicalbert_finetune_2_layer_61_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "# model = MEDIQA_Model()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "model = MEDIQA_Model()\n",
    "model.load_state_dict(torch.load('checkpoints/model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:50<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "acc, probs, y_pred = get_test_acc(model.to(device), test_loader, labels_test, return_probs_and_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranking_predictions(probs, y):\n",
    "    rankings  = []\n",
    "    entailed = []\n",
    "    i_start  = 0\n",
    "    for i, q in enumerate(QA_test):\n",
    "        rankings.append(1- np.array(probs[i_start:i_start+len(q.answers)]))\n",
    "        entailed.append(y[i_start:i_start+len(q.answers)])\n",
    "        i_start += len(q.answers)\n",
    "        assert len(rankings[i] == len(QA_test[i].answer_ids))\n",
    "        assert len(entailed[i] == len(QA_test[i].answers))\n",
    "    return rankings, entailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_id,answer_id,label\n"
     ]
    }
   ],
   "source": [
    "ranking_pred, labels_pred = get_ranking_predictions(probs, y_pred)\n",
    "csv_name = 'test_biobert_50k'\n",
    "QA_test.output_predictions(ranking_pred, labels_pred, file=csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Task (Round-2) : 3\n",
      "Ground truth: task3/ground_truth_round_2.csv\n",
      "Submission file: task3/sample_submission_round_2_test_biobert3.csv\n",
      "{'score_acc': 0.6115627822944896, 'score_secondary_spearman': -0.004830917874396123, 'meta': {'MRR': 0.7074444444444444, 'Precision': 0.6898395721925134}}\n"
     ]
    }
   ],
   "source": [
    "evaluate(csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5k-> {'score_acc': 0.5663956639566395, 'score_secondary_spearman': 0.011531841652323562, 'meta': {'MRR': 0.6802222222222222, 'Precision': 0.5954356846473029}}\n",
    "\n",
    "\n",
    "20k-> {'score_acc': 0.6115627822944896, 'score_secondary_spearman': -0.004830917874396123, 'meta': {'MRR': 0.7074444444444444, 'Precision': 0.6898395721925134}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:51<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_clf.eval()\n",
    "pred_labels = []\n",
    "bert_clf.to(device)\n",
    "with torch.no_grad():\n",
    "    for s,q,a in tqdm.tqdm(test_loader):\n",
    "        logits = bert_clf(q.to(device),a.to(device))\n",
    "        pred_labels.extend(logits.to('cpu'))\n",
    "    pred_labels = np.array([x.item() for x in pred_labels])\n",
    "    pred = (pred_labels > 0.5).astype(np.int16)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971093044263776"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([1,2,3]), torch.tensor([1,2,3])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101,   193,   118,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3073, 10294,  ...,  1110,  1136,  2276],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101, 14051, 16026,  ...,     0,     0,     0],\n",
      "        [  101,  1887,  8006,  ...,  2039,   119,  1142],\n",
      "        [  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1221, 1167,  ...,    0,    0,    0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1187,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 19640,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,  2975,  1115,  1138],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 32180, 20939,  ...,  1132,  1160,  1514],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 36359, 31630,  ...,  7604,  1137,  8192],\n",
      "        [  101, 44511,  1596,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 15355, 15491,  ...,  1128,  1444,  1106],\n",
      "        [  101, 16638,  1822,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  4333,  1183,  ...,  1240,  2027,  1144],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        [  101, 58456, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 20557, 22214,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,     0,     0,     0],\n",
      "        [  101,  3607, 14255,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  2016,  1104,  4182],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 41844,  1162,  ..., 17713,   120, 37553],\n",
      "        [  101, 29193, 16838,  ...,     0,     0,     0],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]]), tensor([[  101, 20844,  6575,  ...,   170,   119,   173],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 24443, 20497,  ...,   118, 29346,  2149],\n",
      "        [  101, 14255, 43199,  ..., 43199, 48974, 20484]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0]]), tensor([[  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        [  101,  3924,  9304,  ...,     0,     0,     0],\n",
      "        [  101, 29077, 10436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14947,   113,  ...,     0,     0,     0],\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  3252,  6665,  ...,     0,     0,     0],\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 45648, 11098,  ...,  2332,  2094,  4822],\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 16374,   117, 23658],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,  1104,  2094,  1106],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101, 19245,  1105,  ...,  2914,   119,  2367]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 53685, 35810,  ...,  2116,   118,  7930],\n",
      "        [  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,  1165,  1106,  1840]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 27410, 29261,  ..., 29261, 10306,  3252],\n",
      "        ...,\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 39960, 41482,  ...,     0,     0,     0],\n",
      "        [  101,  4457,   118,  ...,  5173, 24034,  8341]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1165,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0]]), tensor([[  101, 12365, 41527,  ...,  5800,  2109, 14255],\n",
      "        [  101, 14255, 43199,  ...,  1274,   112,   189],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,  1128,  4330,  1315],\n",
      "        [  101, 43760, 21459,  ...,  8006,  1336,  7907],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,  2612,  1105,  2450],\n",
      "        [  101, 15604, 16420,  ..., 23658,  1175,  1132],\n",
      "        ...,\n",
      "        [  101, 13316, 33391,  ...,  1132,  1276,  1219],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0],\n",
      "        [  101, 29278, 25453,  ...,   173,   119,   170]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 53109,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29034,  1548,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  3678, 22869,  ...,  1118,   131,   179],\n",
      "        [  101,  1322,  6758,  ...,     0,     0,     0],\n",
      "        [  101, 17972,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 10878, 17972,  ...,  3843, 39241,  8032],\n",
      "        [  101, 34754,  1643,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 39241,  8032,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]]), tensor([[  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,  2633,   119,  1191],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0],\n",
      "        [  101, 11111,  1825,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1110,  1122,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101,  5153, 29284,  ...,  1191,  1115,  2086],\n",
      "        [  101, 53685, 35810,  ...,   170,  2960,  1104],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        ...,\n",
      "        [  101, 14434,   193,  ...,     0,     0,     0],\n",
      "        [  101,  7753, 22869,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ...,  6028,  2445,   117]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,  3490,  1107,   170],\n",
      "        [  101,  3245, 40739,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,  1116,  3652,  1105],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6245,  1104,  ...,  2922,   117, 37521],\n",
      "        [  101, 41625, 30628,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101, 33659, 22494,  ...,     0,     0,     0]]), tensor([[  101,  5354, 20939,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,  1353,  6556,  1104],\n",
      "        [  101, 47433, 10024,  ...,  1936,  1334,  3154],\n",
      "        ...,\n",
      "        [  101, 47606,   131,  ...,  1150,  3531, 47606],\n",
      "        [  101, 44648, 32219,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        [  101,  3252,  1111,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 33869, 31719,  ...,     0,     0,     0]]), tensor([[  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36217, 12809,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35929, 42193,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ..., 24259,  1116,   119],\n",
      "        [  101, 33869, 31719,  ...,  2769,  1104,  1142]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9947,  1181,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1322,  6758,  ...,   185,  8057,  2225],\n",
      "        [  101,  1940,  1233,  ...,   176,   117,  2027]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1169,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101, 43165,   113,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 30460,  3984,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  6898,  1161,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  5884, 20752,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  5837, 17953,  ...,  1107,  1199,  2740],\n",
      "        [  101,  3245, 40680,  ...,   119,   177,   119],\n",
      "        [  101,  6898,  1161,  ..., 36431,  8043,  4626],\n",
      "        ...,\n",
      "        [  101, 29261, 10306,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 37521, 55658,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 20844,  1139,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1716,  2445,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101, 24181, 29232,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,     0,     0,     0],\n",
      "        [  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  9947,  1158,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101,  2841,  2445,  ...,  1128, 44077,  3798]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0]]), tensor([[  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9947,  1181,  ..., 57169,  7889, 32704]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,  1712,  1122,  1228],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,  1278,   117,  1934],\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 35750,  1465,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1725,  1169,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  9987,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0]]), tensor([[  101, 17291, 36647,  ...,   113, 30322, 20713],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 50352,  1733,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,  1932, 13974,  1234],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 8805, 1399,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101,  178, 1138,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  8805,  1399,  ...,     0,     0,     0],\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 31015,  4559,  ...,     0,     0,     0],\n",
      "        [  101, 36359, 31630,  ...,  6986,  1170,  1425],\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  7209,  4182,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 29346,  2149,  ...,  2812,  6059,  1137],\n",
      "        [  101, 12104, 24928,  ...,  1129,  1694,  1511],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4841, 30560,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 10507,   113,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1169,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101,  178,  112,  ...,    0,    0,    0]]), tensor([[  101,  3245, 40739,  ..., 29660,  4371,   114],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4107,  1164,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0],\n",
      "        [  101,  1940,  1233,  ...,     0,     0,     0]]), tensor([[  101,  9077,  1105,  ...,  1152,  1145,  1494],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 18419,  2765,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101, 13316, 33391,  ...,     0,     0,     0],\n",
      "        [  101, 13316, 33391,  ..., 13782,  2225,   119],\n",
      "        [  101,  1662,  4777,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 46407,  4060,  ...,  1137, 48117,  6108],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 53685, 52892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1110, 44511,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0]]), tensor([[  101,  1301, 13523,  ...,   119,  1128,  1336],\n",
      "        [  101, 53685, 35810,  ...,     0,     0,     0],\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  7466,  4257,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1139,  1401,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 36431,  5168,  ...,  1173,  9711,  1111],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,  1443,  3634,  1807],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,  1510,  1431,   178],\n",
      "        [  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1110,  ...,  1128,  1169,  1321],\n",
      "        [  101, 13316,  9028,  ...,  1103,  1378,   131],\n",
      "        [  101, 19245, 16320,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,  1106, 12434,  1103],\n",
      "        [  101,  4106,  6997,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  2213,  ...,     0,     0,     0]]), tensor([[  101, 22214, 10507,  ...,  5199,   119,  1128],\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 35041, 42490,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1690,  1114,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  8856,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0]]), tensor([[  101, 48341, 33916,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  3995,  1105, 46657],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101,  5837, 17953,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101,  1209, 18331,  ...,     0,     0,     0]]), tensor([[  101,  9304, 34581,  ...,  1240, 16212,   119],\n",
      "        [  101,  3196,  2841,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,  1267,  1293,  1218],\n",
      "        ...,\n",
      "        [  101, 36344,  2042,  ...,     0,     0,     0],\n",
      "        [  101, 35929, 42193,  ...,  3879,  1107,  1134],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  3252,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 17972,   113,  ...,     0,     0,     0],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5557,  1105,  ...,     0,     0,     0],\n",
      "        [  101,  9323, 26466,  ...,     0,     0,     0],\n",
      "        [  101,  1344, 47310,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1103,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]]), tensor([[  101,  2495, 46353,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 25506, 37041,  ...,     0,     0,     0],\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 41625, 39300,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101,  1132,  1175,  ...,     0,     0,     0],\n",
      "        [  101,  1156,  1128,  ...,     0,     0,     0]]), tensor([[  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  2495, 46353,  ...,  1673,   113,  1185],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16259,  7772,  ...,     0,     0,     0],\n",
      "        [  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 29169,  3840,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[ 101, 1184, 1674,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 6898, 1161,  ...,    0,    0,    0]]), tensor([[  101, 13306, 16042,  ...,     0,     0,     0],\n",
      "        [  101, 23448,  2941,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1114, 29123,  4759],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ..., 29660, 15243, 12633],\n",
      "        [  101,  6898,  1161,  ...,  1825,   119,   118]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 20968, 14051,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0],\n",
      "        [  101, 17972,   118,  ...,     0,     0,     0],\n",
      "        [  101, 44676,  4182,  ...,  1110,  1270, 45758]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101,  4841, 38955,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1164, 43165,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 14837, 20673,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ..., 29056,   117,  1639],\n",
      "        [  101, 50352,  1733,  ...,  4607,  1105,  3843],\n",
      "        ...,\n",
      "        [  101,  4809,  1513,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1510,  ...,     0,     0,     0]]), tensor([[  101, 13093,  4182,  ...,     0,     0,     0],\n",
      "        [  101, 29193, 16838,  ..., 16838, 12736, 22992],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        [  101, 10552,  7222,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ..., 30177,   178,   118]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1132, 1175,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 4680,  ...,    0,    0,    0],\n",
      "        [ 101, 4680, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 3252,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,  1404,   118,   170],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,   119,   170,  3112]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 39310,  2193,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0]]), tensor([[  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 46789, 12571,  ..., 11552, 46789, 12571],\n",
      "        [  101, 29056,  4455,  ...,  1874, 20192,  1566]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1191, 30247,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1180, 38782,  ...,     0,     0,     0]]), tensor([[  101, 23123,  4184,  ...,     0,     0,     0],\n",
      "        [  101,  5183,  5300,  ...,  1336,  4430,  1603],\n",
      "        [  101, 26600, 58355,  ...,  2612,   119,  1372],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,  1128,  1132,  1253],\n",
      "        [  101,  1184,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 38782, 20387,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,   178,  1821,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  3245, 40739,  ...,  5735, 12362,  1116],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  2218, 16565,   119],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 51541, 41482,  ..., 11478,  2217,  1110],\n",
      "        [  101,  1762,  2035,  ..., 30216,  6951,  1106]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]]), tensor([[  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16557, 41482,  ...,     0,     0,     0],\n",
      "        [  101, 42791, 11745,  ...,  1219,  1103, 12104],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 36217,  1320,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 26707, 32304,  ...,  1162,  1114, 19035],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        [  101, 24762,  6575,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4287,  1240,  ...,     0,     0,     0],\n",
      "        [  101, 10507, 11759,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1169,  178,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1887,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1494, 1114,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0]]), tensor([[  101, 26707, 32304,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,  5363,  1114,  1142],\n",
      "        [  101, 35929, 42193,  ...,  1110,  1126, 55496],\n",
      "        ...,\n",
      "        [  101,  2076,   123,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 14051, 16026,  ...,  1138,  1137,  1138]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184,  2774,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  2213,  2184,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101,  8006,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]]), tensor([[  101, 47433, 10024,  ...,     0,     0,     0],\n",
      "        [  101, 54074, 14196,  ...,     0,     0,     0],\n",
      "        [  101,  2184, 21430,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17972,  2076,  ...,     0,     0,     0],\n",
      "        [  101, 48117,  6108,  ...,     0,     0,     0],\n",
      "        [  101, 14255, 43199,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  8175,  2765,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,   178,   112,  ...,     0,     0,     0]]), tensor([[  101, 57481, 12602,  ...,     0,     0,     0],\n",
      "        [  101,  3245, 40680,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16864,   118,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101,  1202,   178,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101,  1184, 23897,  ...,     0,     0,     0],\n",
      "        [  101,  1169,   178,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1277,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0]]), tensor([[  101,  9304, 15776,  ...,     0,     0,     0],\n",
      "        [  101, 29101, 25890,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 54087,  8043,  ..., 13753,   117,  1321],\n",
      "        [  101, 16320,  1116,  ...,     0,     0,     0],\n",
      "        [  101,  6730,  1105,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  4268,  1519,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1221,  1167,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,     0,     0,     0],\n",
      "        [  101, 11200,  1111,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0]]), tensor([[  101, 17688, 42782,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,     0,     0,     0],\n",
      "        [  101,   188,  1233,  ...,  3870,  1157,  3053],\n",
      "        ...,\n",
      "        [  101, 15604, 16420,  ...,  1103,   118,  4073],\n",
      "        [  101, 32401,  5132,  ...,     0,     0,     0],\n",
      "        [  101, 24443, 20497,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 23481, 40269,  ...,     0,     0,     0],\n",
      "        [  101,  1167,  1869,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  4680,  1104,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1821,  ...,     0,     0,     0]]), tensor([[  101, 52549, 15355,  ...,     0,     0,     0],\n",
      "        [  101,  4267, 15284,  ...,     0,     0,     0],\n",
      "        [  101,  1202,  1128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 17963, 42774,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ..., 11009,  1201,   117],\n",
      "        [  101,  6307, 24662,  ...,  2241,  1112,  1936]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,     0,     0,     0]]), tensor([[  101, 41437,  1204,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,   113,  2824,  1103],\n",
      "        ...,\n",
      "        [  101, 26600, 58355,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 34760, 15901,  ...,  2645,  1235,  1103]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1494,  1114,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1106,  ...,     0,     0,     0],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0]]), tensor([[  101, 24259, 23897,  ...,  1110,   175,  1810],\n",
      "        [  101, 29156, 18208,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  1120,  1240, 19328],\n",
      "        ...,\n",
      "        [  101, 11536,  1106,  ...,  1296,  3420,   119],\n",
      "        [  101, 29156, 18208,  ...,  1431,  5427,  1107],\n",
      "        [  101,  3073, 10294,  ...,  1240,  1148, 10203]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[  101, 56401,  8840,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1887,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 19082,   117,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0]]), tensor([[  101, 42193, 16071,  ...,  2218, 13558,  1107],\n",
      "        [  101, 16638,   118,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,  1114, 35929, 42193],\n",
      "        ...,\n",
      "        [  101, 30264, 24079,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 12365, 30705,  ...,  1105,  8006,   119]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 8006, 1104,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101,  178, 1821,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0]]), tensor([[  101,  1301, 13523,  ...,     0,     0,     0],\n",
      "        [  101, 29123,  4759,  ...,  1129,  1694,  1106],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1184,  1110,  ...,   118,  3987,  1892],\n",
      "        [  101, 43500, 11535,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1110,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]]), tensor([[ 101, 1184, 2774,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1110,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 9987,  ...,    0,    0,    0],\n",
      "        [ 101, 1165, 1105,  ...,    0,    0,    0]]), tensor([[  101, 47433, 10024,  ...,  1229,  1240,  9077],\n",
      "        [  101, 29284,  8830,  ...,     0,     0,     0],\n",
      "        [  101, 42936, 41527,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  6857,  1964,  ...,     0,     0,     0],\n",
      "        [  101,  9987,  1105,  ...,  6059,  1110,  1136],\n",
      "        [  101,   193,   118,  ...,  2747,  7459,  2975]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]]), tensor([[ 101, 4107, 1164,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1202,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1110,  ...,    0,    0,    0],\n",
      "        [ 101, 1195, 1138,  ...,    0,    0,    0]]), tensor([[  101, 18419,  2765,  ..., 31033, 21180,   113],\n",
      "        [  101, 35929, 42193,  ...,  2037,  1114,  1240],\n",
      "        [  101, 22214, 10507,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139, 57872,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[ 101, 1156, 8856,  ...,    0,    0,    0],\n",
      "        [ 101, 1184, 1132,  ...,    0,    0,    0],\n",
      "        [ 101, 1139, 5009,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1293, 1106,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1277,  ...,    0,    0,    0],\n",
      "        [ 101, 1293, 1510,  ...,    0,    0,    0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101,  5153, 29284,  ...,     0,     0,     0],\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10211,  1111,  ...,  1142,  2076,  1104],\n",
      "        [  101, 54087,  8043,  ...,     0,     0,     0],\n",
      "        [  101,  6857,  1964,  ...,  1104,  6857,  1964]])]\n",
      "[tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1195,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101,  1139,  5009,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]]), tensor([[  101, 51632,  1200,  ...,  4567,   117,  1134],\n",
      "        [  101,  7958,  2342,  ...,     0,     0,     0],\n",
      "        [  101, 11019, 31086,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 51632,  1200,  ...,     0,     0,     0],\n",
      "        [  101, 41156, 11955,  ...,     0,     0,     0],\n",
      "        [  101, 29127,  7854,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101, 43234, 11096,  ...,     0,     0,     0],\n",
      "        [  101,   178,  1138,  ...,     0,     0,     0],\n",
      "        [  101,  1293, 38472,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101,  1184,  4680,  ...,     0,     0,     0],\n",
      "        [  101,  4268,  1519,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1110,  ...,     0,     0,     0],\n",
      "        [  101, 16664,  7596,  ...,     0,     0,     0],\n",
      "        [  101, 38472,  3329,  ...,  8204,  9987,  1127],\n",
      "        ...,\n",
      "        [  101, 36256, 27547,  ...,     0,     0,     0],\n",
      "        [  101, 43760, 21459,  ...,     0,     0,     0],\n",
      "        [  101, 17688, 42782,  ...,     0,     0,     0]])]\n",
      "[tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.]]), tensor([[  101,  1184,  1892,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0],\n",
      "        [  101, 13347,  1104,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1293,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1150,  1110,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101, 46789, 12571,  ...,     0,     0,     0],\n",
      "        [  101, 29261, 10306,  ...,  1336,  1494,  3843],\n",
      "        [  101,  3073, 10294,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 23123,  4184,  ...,   119,  1164,   122],\n",
      "        [  101, 15355,   118,  ...,  8054,  1118,   131],\n",
      "        [  101, 26600, 32514,  ...,     0,     0,     0]])]\n",
      "[tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]]), tensor([[  101, 11111,  1825,  ...,     0,     0,     0],\n",
      "        [  101,  1933,   119,  ...,     0,     0,     0],\n",
      "        [  101,  1293,  1202,  ...,     0,     0,     0]]), tensor([[  101,  1184,  1132,  ...,     0,     0,     0],\n",
      "        [  101, 13306,  1139,  ...,     0,     0,     0],\n",
      "        [  101, 14947,   118,  ...,     0,     0,     0]])]\n"
     ]
    }
   ],
   "source": [
    "for b in train_loader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405M/405M [00:07<00:00, 51.2MB/s] \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-277-251332b25f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mrepresentations_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    379\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu\n",
    "\n",
    "model_names = [\n",
    "    'bert-base-nli-stsb-mean-tokens',\n",
    "    'bert-large-nli-stsb-mean-tokens',\n",
    "    'roberta-base-nli-stsb-mean-tokens',\n",
    "    'roberta-large-nli-stsb-mean-tokens',\n",
    "    'distilbert-base-nli-stsb-mean-tokens'\n",
    "]\n",
    "\n",
    "for name in model_names:\n",
    "    model = SentenceTransformer(name)\n",
    "    model = model.to(cuda)\n",
    "\n",
    "    representations_a = []\n",
    "    representations_b = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (sent_a, sent_b) in tqdm(test_sentences, desc='Embedding Sentences', ncols=800):\n",
    "            sentences_embeddings = model.encode([sent_a, sent_b])\n",
    "            representations_a.append(sentences_embeddings[0])\n",
    "            representations_b.append(sentences_embeddings[1])\n",
    "\n",
    "    obtained_scores = []\n",
    "    for idx, (repr_a, repr_b) in enumerate(zip(representations_a, representations_b)):\n",
    "        score = 1 - cosine(repr_a, repr_b)\n",
    "        obtained_scores.append(score)\n",
    "\n",
    "    corr_score = pearsonr(test_scores[:len(obtained_scores)], obtained_scores)[0]\n",
    "    print(f'{name}: {corr_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BioELMo\n",
    "\n",
    "https://docs.allennlp.org/v1.0.0rc5/tutorials/how_to/elmo/\n",
    "\n",
    "https://github.com/allenai/allennlp/blob/main/allennlp/modules/elmo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install allennlp\n",
    "# ! pip install allennlp-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device('cpu')\n",
    "cuda = torch.device('cuda')\n",
    "device = cuda if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonre\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.elmo import Elmo\n",
    "# elmo = Elmo(\n",
    "#     options_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json', \n",
    "#     weight_file='https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5',\n",
    "#     num_output_representations=3,\n",
    "#     dropout=0\n",
    "    \n",
    "# )\n",
    "\n",
    "bioelmo = Elmo(\n",
    "    options_file='bioelmo/biomed_elmo_options.json', \n",
    "    weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "    num_output_representations=3,\n",
    "    dropout=0\n",
    ")\n",
    "bioelmo = bioelmo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  71, 106, 115, 116, 117, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 116, 102, 111, 117, 102, 111, 100, 102, 260, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  66, 111, 112, 117, 105, 102, 115, 260, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "\n",
       "        [[259,  74, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 117, 102, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  98, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 100,  98, 115, 115, 112, 117, 260, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 103, 112, 115, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  99, 115, 102,  98, 108, 103,  98, 116, 117, 260, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [['First', 'sentence', '.'], ['Another', '.'], [\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"]]\n",
    "character_ids = batch_to_ids(sentences).to(device)\n",
    "embeddings = bioelmo(character_ids)\n",
    "character_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_embedding(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "    sentences = [tokens]\n",
    "    character_ids = batch_to_ids(sentences).to(device)\n",
    "    return bioelmo(character_ids)['elmo_representations'][2].mean(dim=0).mean(dim=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1981, -0.2493,  0.1472,  ...,  0.0856,  0.0514,  0.0953],\n",
       "       device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['elmo_representations'][0].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 0\n",
    "q = get_elmo_embedding(QA[K].question)\n",
    "ans = [get_elmo_embedding(a) for a in QA[K].answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label,Rank,Similarity\n",
      "1 2 0.7145789861679077\n",
      "0 7 0.6949490308761597\n",
      "1 3 0.7414701581001282\n",
      "0 8 0.6276549696922302\n",
      "1 5 0.7520613670349121\n",
      "0 6 0.6759256720542908\n",
      "0 10 0.6990264654159546\n",
      "1 4 0.740582287311554\n",
      "0 9 0.6365541219711304\n",
      "1 1 0.7022466659545898\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print('Label,Rank,Similarity')\n",
    "for i,a in enumerate(ans):\n",
    "    sim = 1-cosine(q.detach().cpu(), a.detach().cpu())\n",
    "    print(QA.labels[K][i], QA.references[K][i], sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten   = lambda t: [item for sublist in t for item in sublist]\n",
    "\n",
    "sentences = [[q.question, a]  for q in QA for a in q.answers]\n",
    "labels    = flatten([q.labels for q in QA])\n",
    "\n",
    "sentences_val = [[q.question, a]  for q in QA_val for a in q.answers]\n",
    "labels_val    = flatten([q.labels for q in QA_val])\n",
    "\n",
    "sentences_test = [[q.question, a]  for q in QA_test for a in q.answers]\n",
    "labels_test    = flatten([q.labels for q in QA_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BATCH_SIZE_TEST = 64\n",
    "max_len_seq = 512\n",
    "\n",
    "class MEDIQA_Dataset2(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = []\n",
    "        self.y = np.array(y)\n",
    "        for q, a in X:\n",
    "            _q = batch_to_ids([nltk.word_tokenize(q)])\n",
    "            _a = batch_to_ids([nltk.word_tokenize(a)])\n",
    "            self.X.append([_q, _a])\n",
    "#         self.X = np.array(self.X)\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return self.X.shape[0]\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        score = torch.FloatTensor([self.y[index]])\n",
    "    \n",
    "        q = torch.LongTensor(self.X[index][0])\n",
    "        a = torch.LongTensor(self.X[index][1])\n",
    "        \n",
    "        return score, q, a\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = MEDIQA_Dataset2(X=sentences, y=labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Create train dataset\n",
    "val_dataset = MEDIQA_Dataset2(X=sentences_val, y=labels_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# Create test dataset\n",
    "test_dataset = MEDIQA_Dataset2(X=sentences_test, y=labels_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MEDIQA_Model_bioELMo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MEDIQA_Model_bioELMo, self).__init__()\n",
    "        self.bioelmo = Elmo(\n",
    "            options_file='bioelmo/biomed_elmo_options.json', \n",
    "            weight_file='bioelmo/biomed_elmo_weights.hdf5',\n",
    "            num_output_representations=3,\n",
    "            dropout=0\n",
    "        )\n",
    "        for param in self.bioelmo.parameters():\n",
    "            param.requires_grad = False\n",
    "#         self.bioelmo = bioelmo.to(device)\n",
    "#         modules = [self.bert.embeddings, *self.bert.encoder.layer[:-1]] #Replace 5 by what you want\n",
    "#         for module in modules:\n",
    "#             for param in module.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        self.linear1 = nn.Linear(2*1024, 256)\n",
    "        self.linear2 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, q, a):\n",
    "        \n",
    "#         _, pooled_output = self.bert(tokens, output_all=False)\n",
    "#         print(q.shape, a.shape)\n",
    "        q_emb = self.get_elmo_embedding(q)\n",
    "        a_emb = self.get_elmo_embedding(a)\n",
    "#         print('CLS:', CLS1.shape, CLS2.shape)\n",
    "        x = torch.cat([q_emb, a_emb], dim=0)\n",
    "#         print('concat:', x.shape)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        x = self.linear1(x)\n",
    "        x = nn.SELU()(x)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = self.linear2(x)\n",
    "        prob = self.sigmoid(x)\n",
    "        return prob, q_emb, a_emb\n",
    "\n",
    "\n",
    "    def get_elmo_embedding(self, sentence):\n",
    "#         tokens = nltk.word_tokenize(sentence)\n",
    "#     print(tokens)\n",
    "#         sentences = [tokens]\n",
    "#         character_ids = batch_to_ids(sentence).to(device)\n",
    "        return self.bioelmo(sentence)['elmo_representations'][2].mean(dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioelmo_clf = MEDIQA_Model_bioELMo()\n",
    "bioelmo_clf = bioelmo_clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def get_test_acc(model, dataset, true_labels, return_probs_and_labels=False):\n",
    "    model.eval()\n",
    "    pred_probs = []\n",
    "    with torch.no_grad():\n",
    "        for s,(q,a) in tqdm.tqdm(zip(dataset.y, dataset.X)):\n",
    "            logits, _, _ = model(q.to(device),a.to(device))\n",
    "            pred_probs.extend(logits.to('cpu'))\n",
    "        pred_probs  = np.array([x.item() for x in pred_probs])\n",
    "        pred_labels = (pred_probs > 0.5).astype(np.int16)\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    if return_probs_and_labels:\n",
    "        return acc, pred_probs, pred_labels\n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonre\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1699/1701 1.71011781692504887838951975107192993 0.23533932864665985 0.43557727336883545 0.47481733560562134 0.6460447907447815 0.36849457025527954 0.33953002095222473 0.3474850654602051 0.8418510556221008 0.05722641572356224 0.2941003441810608 2.123321056365967 0.6593480110168457 0.32470789551734924 0.9396703839302063 1.138655424118042 0.4479018449783325 0.31677868962287903 0.5760351419448853 1.1472036838531494 0.3642497956752777 0.655806303024292 0.13179482519626617 0.14221100509166718 0.03715140372514725 0.03710370883345604 0.5069848895072937 0.12469686567783356 0.2872546911239624 0.30459126830101013 0.1827237755060196 0.05583462119102478 0.17570139467716217 0.2522789537906647 0.5008960366249084 0.1498612016439438 0.27536070346832275 0.8094481825828552 0.35863804817199707 0.007488503586500883 0.272317498922348 0.665442168712616 1.0090411901474 0.2127843052148819 0.37714487314224243 0.6983405351638794 0.5069541931152344 0.50309818983078 0.8695306777954102 0.35794731974601746 0.33450114727020264 0.6171535849571228 0.312409371137619 0.2712901532649994 1.6810646057128906 0.36910927295684814 0.4692544937133789 1.75895357131958 0.2932157814502716 0.5372257232666016 0.027927039191126823 0.1249619871377945 1.7608225345611572 0.6221458315849304 0.523066520690918 0.19671142101287842 0.08420790731906891 0.28924253582954407 0.2556413412094116 0.8796494007110596 0.2936345338821411\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.7862160205841064\n",
      "Epoch 1 mean loss: 0.5470765709035484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.7001965673588473\n",
      "\n",
      "step 1699/1701 0.889972448348999379362247467041016 2.4180185794830322 0.8195332288742065 0.1406424194574356 0.3818170428276062 0.12095547467470169 1.107313871383667 0.4588475525379181 0.30129575729370117 0.1594342440366745 0.5645102262496948 0.22144408524036407 1.3693127632141113 0.5619590282440186 0.984674870967865 0.25585871934890747 0.159635528922081 1.1690434217453003 0.7233050465583801 0.3393656611442566 0.4672911465167999 0.4082551598548889 0.010942566208541393 0.5697507858276367 0.45417967438697815 0.976703405380249 0.43082624673843384 0.40804970264434814 0.6283698081970215 0.5590319037437439 0.5463050007820129 0.17585323750972748 1.9180209636688232 0.1507309079170227 0.16022297739982605 0.3079458177089691 0.585024356842041 0.6884199380874634 0.1709163784980774 0.12889130413532257 1.140803575515747 0.0848105326294899 0.102312833070755 0.2131572663784027 0.1793561726808548 0.24677921831607819 0.42515799403190613 1.9360604286193848 0.26598498225212097 0.32448360323905945 0.02179734967648983 0.11528331786394119 0.09603890776634216 2.30022931098938 0.25486281514167786 0.38218000531196594 0.4269558787345886 0.005665106233209372 0.010114147327840328 0.3151859641075134 0.004863566253334284 0.6314024329185486 0.0034754399675875902 0.3721623122692108 0.16351556777954102 0.02171304263174534 0.2702646255493164 0.8254010677337646 0.4055841863155365 0.35664498805999756 0.5073227882385254 0.18946605920791626 0.19136051833629608 0.8475819826126099 0.444319486618042\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 2.181504011154175\n",
      "Epoch 2 mean loss: 0.529938168631952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:25,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.7974151839641529\n",
      "\n",
      "step 1699/1701 0.41434207558631897263915131688117981 0.9628956317901611 0.24819764494895935 0.11368143558502197 0.009933050721883774 1.7809391021728516 0.20588482916355133 0.5801113247871399 0.18976131081581116 0.18153975903987885 0.09791207313537598 0.6856088638305664 0.2436830699443817 0.6077970266342163 0.9067908525466919 0.3573295474052429 0.261269748210907 0.43519073724746704 0.035383690148591995 0.3175675570964813 0.40281152725219727 0.8080476522445679 1.1279242038726807 0.06454793363809586 0.08964324742555618 0.11496498435735703 0.34422388672828674 0.3302593529224396 0.30213016271591187 0.5582733750343323 0.11403423547744751 0.025494778528809547 0.22439706325531006 0.1942361295223236 0.3218885660171509 0.38328227400779724 0.3474422097206116 0.591511607170105 0.5341475009918213 0.9155266284942627 0.6099256277084351 0.04416247084736824 0.17114566266536713 2.753002882003784 0.33806395530700684 0.23099620640277863 0.13612425327301025 0.6084839105606079 0.18443503975868225 0.9233198761940002 0.10553042590618134 0.08178785443305969 0.18648673593997955 1.1546802520751953 1.0944827795028687 0.46894216537475586 0.035146962851285934 1.5655255317687988 0.3664795458316803 0.1681874841451645 0.3270869255065918 0.16005577147006989 0.9876587390899658 1.0515607595443726 0.023649878799915314 0.7049729228019714 0.5459180474281311 0.08879972994327545 0.0736125111579895 1.1838246583938599 0.10638335347175598 0.08499325066804886 0.27606233954429626 0.08877693116664886 0.368268758058548 0.1517312228679657 0.2657988965511322 0.04590384662151337\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.8204247951507568\n",
      "Epoch 3 mean loss: 0.5066695220493052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:23,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.594017094017094    Val loss:  0.7729332350682371\n",
      "\n",
      "step 1699/1701 1.02016639709472665945155510902404785 0.9498398303985596 0.7538938522338867 0.1204020082950592 0.018345903605222702 0.50141441822052 0.19695845246315002 2.406003475189209 0.12421474605798721 1.3062564134597778 0.31245163083076477 0.1351374387741089 0.21758130192756653 0.051666878163814545 0.00689355842769146 0.22147607803344727 0.8355936408042908 0.31978416442871094 0.4892957806587219 0.7420252561569214 0.37604981660842896 0.01990683749318123 1.5804355144500732 0.3210747539997101 0.17524363100528717 0.1193753108382225 0.5383833646774292 0.7556830644607544 0.23284731805324554 0.7645964622497559 0.09769280254840851 0.458678662776947 0.3774259090423584 0.03356626629829407 0.002019177656620741 0.3063775300979614 0.10143554210662842 0.5013996362686157 0.3172861933708191 0.23143619298934937 0.017878498882055283 0.6789623498916626 1.3744012117385864 0.13206802308559418 0.3482886850833893 0.43610742688179016 0.06548921018838882 2.3220913410186768 0.5073582530021667 0.41193434596061707 0.3297608196735382 0.2516810894012451 0.09014491736888885 0.3283924460411072 0.6229130029678345 2.7852869033813477 0.2821197807788849 0.467916876077652 0.38540294766426086 0.5687879920005798 2.4258742332458496 0.6067729592323303 0.09536181390285492 0.15364407002925873 0.38345280289649963 0.0032215097453445196 0.11213231831789017 0.050964657217264175 1.028831958770752 1.5352181196212769 1.4901396036148071 0.10352567583322525 0.09727811813354492 0.318237841129303 0.32114696502685547\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.08944638073444366\n",
      "Epoch 4 mean loss: 0.49869779664185393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.594017094017094    Val loss:  0.7232423270883489\n",
      "\n",
      "step 1699/1701 0.2726880609989166775622889757156372 0.09958454221487045 1.8078936338424683 0.2114657759666443 0.29803892970085144 0.6668585538864136 0.8017431497573853 0.3002769947052002 0.16318193078041077 0.4067121148109436 1.2046217918395996 0.7431590557098389 0.25896599888801575 0.3740696907043457 0.7046976685523987 0.11357986927032471 0.36742278933525085 0.43471062183380127 0.1049271747469902 0.9634199142456055 0.13613572716712952 0.00929176900535822 0.4955126643180847 0.23669834434986115 0.17487984895706177 0.17407813668251038 0.24432750046253204 0.5651242733001709 0.637417197227478 0.15414440631866455 0.500500500202179 0.16484253108501434 0.9877283573150635 0.2954854369163513 0.1111513078212738 0.051510728895664215 1.3193895816802979 0.10662323236465454 0.1555909514427185 0.394194632768631 0.6640473008155823 0.13379696011543274 1.151511788368225 0.3434983491897583 0.010252881795167923 0.4451039433479309 0.29776450991630554 0.3904978334903717 0.31823399662971497 0.08536314219236374 0.14886145293712616 0.5255555510520935 0.15992043912410736 0.311166375875473 0.6172075271606445 1.68224036693573 0.45624902844429016 0.21711649000644684 0.003368501551449299 0.36613360047340393 1.6167963743209839 0.17248676717281342 0.24137040972709656 0.19896288216114044 0.8744179606437683 0.1407156139612198 0.8655014038085938 2.7615697383880615 0.15726089477539062 0.355825275182724 1.5809736251831055 0.29863134026527405 0.2104003131389618 0.4045359492301941 0.6428289413452148 0.4174315333366394 0.055678706616163254 0.02433396503329277 0.12021639943122864 0.2188158631324768\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1700/1701 0.06284432113170624\n",
      "Epoch 5 mean loss: 0.4878300085998053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "234it [03:21,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val acc:  0.5897435897435898    Val loss:  0.757634205137173\n",
      "\n",
      "step 166/1701 0.1658745855093002365.09681869298219681 0.0020957482047379017 0.1784224659204483 0.6737553477287292 0.13414056599140167\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-830fd82e781c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;31m#tuple(t.to(device) for t in batch_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLS1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLS2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbioelmo_clf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c1835a3c65c0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, q, a)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#         print(q.shape, a.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mq_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0ma_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_elmo_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;31m#         print('CLS:', CLS1.shape, CLS2.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mq_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-c1835a3c65c0>\u001b[0m in \u001b[0;36mget_elmo_embedding\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m#         sentences = [tokens]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#         character_ids = batch_to_ids(sentence).to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbioelmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'elmo_representations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# run the biLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mbilm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"activations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    594\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"token_embedding\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[0mlstm_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# Prepare the output.  The first layer is duplicated.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_sequence_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         stacked_sequence_output, final_states, restoration_indices = self.sort_and_run_forward(\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         )\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[1;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\elmo_lstm.py\u001b[0m in \u001b[0;36m_lstm_forward\u001b[1;34m(self, inputs, initial_state)\u001b[0m\n\u001b[0;32m    229\u001b[0m             )\n\u001b[0;32m    230\u001b[0m             backward_output_sequence, backward_state = backward_layer(\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mbackward_output_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             )\n\u001b[0;32m    233\u001b[0m             \u001b[1;31m# Skip connections, just adding the input to the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\allennlp\\modules\\lstm_cell_with_projection.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, batch_lengths, initial_state)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;31m# shape (current_length_index, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             \u001b[0mtimestep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpre_projection_timestep_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_projection_clip_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "import tqdm\n",
    "import random\n",
    "# bert_clf = MEDIQA_Model()\n",
    "# bert_clf = bert_clf.to(device)\n",
    "optimizer = torch.optim.Adam(bioelmo_clf.parameters(), lr=5e-5)\n",
    "bioelmo_clf.train()\n",
    "EPOCHS = 100\n",
    "EARLY_STOPPING = 5\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "train_losses, test_losses, val_losses, val_accs, test_accs = [], [], [], [], []\n",
    "N = len(train_dataset.y)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    bioelmo_clf.train()\n",
    "    \n",
    "    train_samples = list(zip(train_dataset.y, train_dataset.X))\n",
    "    losses = []\n",
    "    for step_num, batch_data in enumerate(random.sample(train_samples, len(train_samples))):\n",
    "        y_true, (questions, answers) = batch_data #tuple(t.to(device) for t in batch_data)\n",
    "        logits, CLS1, CLS2 = bioelmo_clf(questions.to(device), answers.to(device))\n",
    "        y_true = torch.from_numpy(np.array([y_true], dtype=np.float32))\n",
    "        loss = loss_func(logits, y_true.to(device))\n",
    "\n",
    "        bioelmo_clf.zero_grad()\n",
    "        loss.backward()\n",
    "        print(f'step {step_num}/{N}', loss.item(), end=\"\\r\")\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        del y_true\n",
    "        del questions\n",
    "        del answers\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    print(f'Epoch {epoch_num+1} mean loss:', np.mean(losses))\n",
    "    train_losses.append(np.mean(losses))\n",
    "    val_acc, val_probs_labels, _   = get_test_acc(bioelmo_clf, val_dataset, labels_val,  return_probs_and_labels=True)\n",
    "#     test_acc, test_probs_labels, _ = get_test_acc(bioelmo_clf, test_loader, labels_test, return_probs_and_labels=True)\n",
    "    val_accs.append(val_acc)\n",
    "#     test_accs.append(test_acc)\n",
    "    \n",
    "    val_loss  = loss_func(torch.from_numpy(val_probs_labels),  torch.from_numpy(np.array(labels_val, dtype=np.double))).item()\n",
    "#     test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "    val_losses.append(val_loss)\n",
    "#     test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Val acc: ', val_acc, '   Val loss: ', val_loss)\n",
    "#     print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "    print()\n",
    "    \n",
    "#     print(f'Epoch {epoch_num+1}:', np.mean(losses))\n",
    "#     train_losses.append(np.mean(losses))\n",
    "# #     acc = get_test_acc(bioelmo_clf)\n",
    "#     acc, probs_labels, _ = get_test_acc(bioelmo_clf, return_probs_and_labels=True)\n",
    "#     test_acc.append(acc)\n",
    "#     test_loss = loss_func(torch.from_numpy(probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "#     test_losses.append(test_loss)\n",
    "#     test_acc.append(acc)\n",
    "#     print(f'Test acc:', acc, '  Test loss:', test_loss)\n",
    "#     print()\n",
    "    \n",
    "    if len(test_acc) > 5 and test_acc[-6] > max(test_acc[-5:]):\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    if len(test_accs) <= 1 or test_acc > max(test_accs[:-1]):\n",
    "        torch.save(bioelmo_clf.state_dict(), 'checkpoints/model_elmo')\n",
    "    if len(val_losses) > EARLY_STOPPING and val_losses[-(EARLY_STOPPING+1)] < min(val_losses[-EARLY_STOPPING:]):\n",
    "        print('Early stopping')\n",
    "        # recover best execution\n",
    "        model = MEDIQA_Model_bioELMo()\n",
    "        model.load_state_dict(torch.load('checkpoints/model_elmo'))\n",
    "        \n",
    "        test_acc, test_probs_labels, _ = get_test_acc(model, test_loader, labels_test, return_probs_and_labels=True)\n",
    "        test_loss = loss_func(torch.from_numpy(test_probs_labels), torch.from_numpy(np.array(labels_test, dtype=np.double))).item()\n",
    "        print(f'Test acc:', test_acc, '  Test loss:', test_loss)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.plot(test_accs, label='test acc')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.plot(val_accs, label='val acc')\n",
    "plt.legend()\n",
    "plt.savefig('figures/bioelmo_loss_lr_small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
