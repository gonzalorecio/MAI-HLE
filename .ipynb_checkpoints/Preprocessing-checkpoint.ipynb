{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "147abfcfb0ac497a9736336ecf1a5c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff0c4714c57f4cc697301ef2bf58eb28",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2441cd058509472ea3fef74f72b3ba0f",
              "IPY_MODEL_ab9fea5b4c2f4426827ecfbd711097a9"
            ]
          }
        },
        "ff0c4714c57f4cc697301ef2bf58eb28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2441cd058509472ea3fef74f72b3ba0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5493bc3fc0704e3e8ea055de72f52367",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71fb84f8487542429fa488d0c6fef2a6"
          }
        },
        "ab9fea5b4c2f4426827ecfbd711097a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1398398f8aef4f27b93bc85edacdd770",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 597kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9b952cefb264ce28c1988a5d0652459"
          }
        },
        "5493bc3fc0704e3e8ea055de72f52367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71fb84f8487542429fa488d0c6fef2a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1398398f8aef4f27b93bc85edacdd770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9b952cefb264ce28c1988a5d0652459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4961a103212423296653018838aaa87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10eb159905cb4da881e506bea7ef3bf7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a0d610808c54752a01d8fafe188c6a5",
              "IPY_MODEL_98128371afc04f1495643f1524b95c7a"
            ]
          }
        },
        "10eb159905cb4da881e506bea7ef3bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a0d610808c54752a01d8fafe188c6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff2c3058101f4d7b8ec7e6b479ab5924",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a3968f8f4114cbcbd04edb27c82717e"
          }
        },
        "98128371afc04f1495643f1524b95c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4080dd44dc56497eb9585b20104cf45a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e40dd44721f5472baae808befb672eb9"
          }
        },
        "ff2c3058101f4d7b8ec7e6b479ab5924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a3968f8f4114cbcbd04edb27c82717e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4080dd44dc56497eb9585b20104cf45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e40dd44721f5472baae808befb672eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8865f8d7f684edcb9c323c7b30ac7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f8d2fe393ea4898a5d9384974cc7e6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b97b0de7f6684d60a0744f03f63c3510",
              "IPY_MODEL_e7e5210cbf89470d914f0dec74f58fc0"
            ]
          }
        },
        "1f8d2fe393ea4898a5d9384974cc7e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b97b0de7f6684d60a0744f03f63c3510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07b7a135531e43fb8174e780bf4a54e9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c8345c9dea24483a59817527326f1ef"
          }
        },
        "e7e5210cbf89470d914f0dec74f58fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dad2627650c6436fa21d6cf6bb1b2143",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:10&lt;00:00, 43.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85f6584af22b4a1e931aad09f7fe66b2"
          }
        },
        "07b7a135531e43fb8174e780bf4a54e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c8345c9dea24483a59817527326f1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dad2627650c6436fa21d6cf6bb1b2143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85f6584af22b4a1e931aad09f7fe66b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSCGMxajRC9R"
      },
      "source": [
        "## **ACL-BioNLP'19 - MEDIQA 2019 Shared Task**\n",
        "\n",
        "**Task 3: Question Answering (QA): **\n",
        "Filter and improve the ranking of automatically retrieved answers from CHiQA \n",
        "\n",
        "*   Filter and improve the ranking of automatically retrieved answers from CHiQA system (https://chiqa.nlm.nih.gov/)\n",
        "*   CHiQA is an experimental AI system that is learning how to answer health-related questions using reliable sources for patients.\n",
        "\n",
        "\n",
        "Authors: Gonzalo Recio and Jana Reventós \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuaOUX1l3Vsf"
      },
      "source": [
        "Connect with MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nx4y3WMQ5u8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "7970dc32-6f90-40f8-cdf2-b5710d5b7965"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-20-cd0a7580851e>\", line 3, in <module>\n",
            "    get_ipython().magic('cd /gdrive')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
            "    return self.run_line_magic(magic_name, magic_arg_s)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
            "    result = fn(*args,**kwargs)\n",
            "  File \"<decorator-gen-91>\", line 2, in cd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
            "    call = lambda f, *a, **k: f(*a, **k)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/magics/osm.py\", line 288, in cd\n",
            "    oldcwd = py3compat.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2JJ1uKBRBnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4debbbd-fb40-44ee-825e-c514bd629059"
      },
      "source": [
        "! ls \"My Drive/HLE Final Project\"\n",
        "%cd \"My Drive/HLE Final Project/data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'My Drive/HLE Final Project': No such file or directory\n",
            "[Errno 2] No such file or directory: 'My Drive/HLE Final Project/data'\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjNf-ELN4GVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b53629-8a92-4840-d3d0-059100e5f378"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biobert\n",
            "MEDIQA2019-Task3-QA-TestSet-wLabels.xml\n",
            "MEDIQA2019-Task3-QA-TrainingSet1-LiveQAMed.xml\n",
            "MEDIQA2019-Task3-QA-TrainingSet2-Alexa.xml\n",
            "MEDIQA2019-Task3-QA-ValidationSet.xml\n",
            "MEDIQA_Task3_QA_TestSet.xml\n",
            "QA_Task3_README.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDyHrqdYSC8h"
      },
      "source": [
        "from xml.dom.minidom import parse, parseString\n",
        "from nltk import tokenize as tk\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qLMZaDzZCER"
      },
      "source": [
        "## Read data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCcPv2AZZIFN"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    s = unicodedata.normalize(\"NFKD\", text.lower())\n",
        "    return re.sub(r'\\[\\d\\]', '', s)\n",
        "\n",
        "def get_answers(answers):\n",
        "    # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
        "    answs, rank, chiqa, y = [], [], [], []\n",
        "    for answer in answers:\n",
        "        ans = preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
        "        reference = int(answer.getAttribute('ReferenceRank'))\n",
        "        system = int(answer.getAttribute('SystemRank'))\n",
        "        label = answer.getAttribute('ReferenceScore')\n",
        "        answs.append(ans); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
        "    return answs, rank, chiqa, y\n",
        "                                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn1BpQpTOBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4175c239-9b35-4ca0-c7ed-5038f899a019"
      },
      "source": [
        "i = 0\n",
        "indx2id = []\n",
        "QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
        "for filename in os.listdir('./'):\n",
        "    # i += 1\n",
        "    print(filename)\n",
        "    if not filename.endswith('.xml') or 'Training' not in filename: continue\n",
        "    fullname = os.path.join('data/Train', filename)\n",
        "    tree = parse(filename)\n",
        "    questions = tree.getElementsByTagName('Question')\n",
        "    for question in questions:\n",
        "        qelem = question.getElementsByTagName('QuestionText')\n",
        "        q, qid = preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
        "        # print(q) # --> questions\n",
        "        answers = question.getElementsByTagName('Answer')\n",
        "        answers_list, rank, system, labels = get_answers(answers)\n",
        "        QA.append([q,answers_list, rank, labels])\n",
        "        QA2.append([q,answers_list, rank, system, labels])\n",
        "        indx2id.append(qid); i+=1;\n",
        "        # break\n",
        "print(i)\n",
        "print(len(QA))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEDIQA_Task3_QA_TestSet.xml\n",
            "MEDIQA2019-Task3-QA-TrainingSet2-Alexa.xml\n",
            "MEDIQA2019-Task3-QA-TrainingSet1-LiveQAMed.xml\n",
            "QA_Task3_README.txt\n",
            "MEDIQA2019-Task3-QA-ValidationSet.xml\n",
            "MEDIQA2019-Task3-QA-TestSet-wLabels.xml\n",
            "biobert\n",
            "208\n",
            "208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahRCulfbzw_r"
      },
      "source": [
        "QA is an array of tuples <Question, [Answers], [Ranking], [Labels] >"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgcg2QEzYNAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1475672f-33be-4f5a-bd76-f69fbdcfd0d5"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "#s=QA[201][1][0]\n",
        "ranked_answ = []\n",
        "print('Question:',QA[201][0])\n",
        "for i in range(len(QA[201][1])):\n",
        "  answ = QA[201][1]\n",
        "  rank = QA[201][2]\n",
        "  ranked_answ.append((int(rank[i]),answ[i]))\n",
        "\n",
        "ranked_answ = sorted(ranked_answ, key=lambda x: x[0])\n",
        "for i in range(len(ranked_answ)):\n",
        "  print(ranked_answ[i][0],'-',unicodedata.normalize(\"NFKD\", ranked_answ[i][1]))\n",
        "\n",
        "#s=unicodedata.normalize(\"NFKD\", s)\n",
        "#re.sub(r'\\[\\d\\]', '', s)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: specify components. coenzyme q10(100-mg). what are the components of this medicine? is it useable for muslims?\n",
            "1 - hibch deficiency (treatment): treatment of hibch deficiency involves frequent carbohydrate-rich meals, along with coenzyme q10, vitamin c, and vitamin e supplementation.  people with hibch deficiency may also benefit from a low-valine diet with carnitine and n-acetyl-cysteine supplementation.  prompt, supportive, treatment during periods of physical stress and viral illness is vital. this may involve frequent infusions of bicarbonate, plus additional supports as required.  we strongly recommend that these and other treatment options be carefully reviewed with a healthcare provider.\n",
            "2 - essential thrombocythemia (treatment): if you have life-threatening complications, you may have a treatment called platelet pheresis. it quickly reduces platelets in the blood. long-term, medicines are used to decrease the platelet count to avoid complications. the most common medicines used include hydroxyurea, interferon-alpha, or anagrelide. in some people with a jak2 mutation, specific inhibitors of the jak2 protein may be used. in people who are at a high risk of clotting, aspirin at a low dose (81 to 100 mg per day) may decrease clotting episodes. many people do not need any treatment, but they must be followed closely by their provider.\n",
            "3 - myoclonic epilepsy with ragged red fibers (treatment): while there is no cure for merrf, there are various medications and therapies that can be helpful in managing symptoms. this includes: antiseizure medications,  levetiracetam for myoclonus,  physical therapy , and aerobic exercise. standard medication is used to treat cardiac symptoms.  daily use of coenzyme q10 and l-carnitine have been of some benefit to individuals. other supplements that might be utilized include creatinine and lipoic acid.  management guidelines genereviews provides current, expert-authored, peer-reviewed, full-text articles describing the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions.\n",
            "4 - cerebrotendinous xanthomatosis (treatment): cerebrotendinous xanthomatosis may be treated with chenodeoxycholic acid (cdca), which has been shown to normalize levels of cholestonal and improve neurologic symptoms. inhibitors of hmg-coa reductase may be used alone or in combination with cdca. they are also effective in decreasing cholestanol concentration and improving clinical symptoms, however these treatments can lead to muscle damage. coenzyme q10 may improve muscle weakness, and cataract surgery may also be required.  management guidelines genereviews provides current, expert-authored, peer-reviewed, full-text articles describing the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions.\n",
            "5 - essential thrombocythemia (treatment): long-term, different medications are used to decrease the platelet count to avoid complications. the most common medications used include: hydroxyurea, interferon-alpha, or anagrelide. in people who are at a high risk for clotting ( thrombosis), aspirin at a low dose (81 to 100 mg per day) decreases clotting episodes.  many people do not need any treatment, but they must be followed closely by their provider.  management guidelines the nord physician guide for essential thrombocythemia was developed as a free service of the national organization for rare disorders (nord) and it's medical advisors.  the guides provide a resource for clinicians about specific rare disorders to facilitate diagnosis and treatment of their patients with this condition.  fda-approved treatments the medication(s) listed below have been approved by the food and drug administration (fda) as orphan products for treatment of this condition. learn more orphan products. national library of medicine drug information portal medline plus health information\n",
            "6 - chronic progressive external ophthalmoplegia (treatment): ptosis caused by chronic progressive external ophthalmoplegia (cpeo) can be corrected by surgery, or by using glasses that have a “ptosis crutch” to lift the upper eyelids.  strabismus surgery can be helpful in carefully selected patients if diplopia (double vision) occurs.  some individuals with a deficiency of coenzyme q10 have cpeo as an associated abnormality. coenzyme q10 is important for normal mitochondrial function. in individuals with this deficiency, supplemental coenzyme q10 has been found to improve general neurologic function and exercise tolerance. however, coenzyme q10 has not been shown to improve the ophthalmoplegia or ptosis in people who have isolated cpeo.  management guidelines genereviews provides a current, expert-authored, peer-reviewed, full-text article on mitochondrial disorders , including cpeo. genereview articles describe the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions.\n",
            "7 - duchenne muscular dystrophy (treatment): there is no known cure for duchenne muscular dystrophy. treatment aims to control symptoms to improve quality of life. steroid drugs can slow the loss of muscle strength. they may be started when the child is diagnosed or when muscle strength begins to decline. other treatments may include: - albuterol, a drug used for people with asthma - amino acids - carnitine - coenzyme q10 - creatine - fish oil - green tea extracts - vitamin e however, the effects of these treatments have not been proven. stem cells and gene therapy may be used in the future. the use of steroids and the lack of physical activity can lead to excessive weight gain. activity is encouraged. inactivity (such as bedrest) can make the muscle disease worse. physical therapy may help to maintain muscle strength and function. speech therapy is often needed. other treatments may include: - assisted ventilation (used during the day or night) - drugs to help heart function, such as angiotensin converting enzyme inhibitors, beta blockers, and diuretics - orthopedic appliances (such as braces and wheelchairs) to improve mobility - proton pump inhibitors (for people with gastroesophageal reflux) several new treatments are being studied in trials.\n",
            "8 - kearns-sayre syndrome (treatment): treatment for kearns-sayre syndrome  is generally symptomatic and supportive.  management options include placement of cardiac pacemakers in individuals with cardiac conduction blocks, eyelid slings for severe ptosis , cochlear implants and hearing aids for neurosensory hearing loss , hormone replacement for endocrinopathies, dilation of the upper esophageal sphincter to alleviate cricopharyngeal achalasia, folinic acid supplementation in individuals with kearns-sayre syndrome with low cerebral spinal fluid folic acid, administration of coenzyme q10 and l-carnitine, physical and occupational therapy, and treatment of depression. antioxidants may ameliorate damage from reactive oxygen species; percutaneous endoscopic gastrostomy may improve nutritional intake and prevent aspiration pneumonia in individuals with severe dysphagia . surveillance includes ekg and echocardiogram every six to 12 months and yearly audiometry and endocrinologic evaluation.  management guidelines genereviews provides current, expert-authored, peer-reviewed, full-text articles describing the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions.\n",
            "9 - leigh syndrome (treatment): treatment of leigh syndrome is directed toward the specific symptoms present in each person.  supportive care for leigh syndrome includes treatment of acidosis, seizures , dystonia , and cardiomyopathy , and attention to nutritional status.   because anesthesia can potentially aggravate respiratory symptoms and bring on respiratory failure, careful consideration should be given to its use and close monitoring prior to, during, and after its use.   progression and new symptoms should be monitored regularly (typically every 6-12 months). evaluations with a neurologist , ophthalmologist , audiologist , and cardiologist are recommended.   specific treatment is possible for the three nuclear gene -encoded leigh-like syndromes (milder conditions with similar features). these include biotin-thiamine-responsive basal ganglia disease (btbgd), biotinidase deficiency, and coenzyme q10 deficiency caused by mutation of pdss2.  management guidelines genereviews provides current, expert-authored, peer-reviewed, full-text articles describing the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions. mitochondrial dna-associated leigh syndrome nuclear gene-encoded leigh syndrome\n",
            "10 - leber hereditary optic neuropathy (treatment): currently, there is no cure for this disease but there are several ongoing studies aiming to find an effective treatment. management of affected individuals is usually supportive, with provision of visual aids.  high-dose oral idebenone may be considered as a treatment option, especially for individuals with lhon with relatively recent disease onset. some studies have reported a benefit from using idebenone with quinone analogues, such as ubiquinone (coenzyme q10) and with vitamin c and vitamin b12.  in an open-label study of five individuals with acute lhon treated within 90 days of disease onset, the antioxidant α-tocotrienol-quinone (epi-743), a vitamin e derivative, showed good results.  those with established lhon mitochondrial dna mutations are advised not to smoke and to limit their alcohol intake. people with leber hereditary optic neuropathy may also find it helpful to speak with other affected individuals and to seek extra psychosocial or counseling support.  management guidelines genereviews provides current, expert-authored, peer-reviewed, full-text articles describing the application of genetic testing to the diagnosis, management, and genetic counseling of patients with specific inherited conditions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw2KR01dSqfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50b7468-c65c-42c7-f1ef-951f226026c6"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 19.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 14.0MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 15.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 12.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 12.7MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 12.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 12.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 12.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 12.7MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 12.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 12.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 12.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=4fe030dbcaaa6d3ca504420bfc1f877c081c3b9f7892ddd9e880ea321d9c2513\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8OBtYhoELGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "147abfcfb0ac497a9736336ecf1a5c7a",
            "ff0c4714c57f4cc697301ef2bf58eb28",
            "2441cd058509472ea3fef74f72b3ba0f",
            "ab9fea5b4c2f4426827ecfbd711097a9",
            "5493bc3fc0704e3e8ea055de72f52367",
            "71fb84f8487542429fa488d0c6fef2a6",
            "1398398f8aef4f27b93bc85edacdd770",
            "e9b952cefb264ce28c1988a5d0652459"
          ]
        },
        "outputId": "dcfb4d41-073b-41c9-fe0b-78f321b95e71"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147abfcfb0ac497a9736336ecf1a5c7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k52YvadUR_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab41e625-ad5b-436a-962b-dd163a86c979"
      },
      "source": [
        "#QA[13][0]\n",
        "QA[14]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['how to diagnose stroke?',\n",
              " [\"stroke (diagnosis): your doctor will diagnose a stroke based on your signs and symptoms, your medical history, a physical exam, and test results. your doctor will want to find out the type of stroke you’ve had, its cause, the part of the brain that's affected, and whether you have bleeding in the brain. if your doctor thinks you’ve had a transient ischemic attack (tia), he or she will look for its cause to help prevent a future stroke. medical history and physical exam your doctor will ask you or a family member about your risk factors for stroke. examples of risk factors include high blood pressure, smoking, heart disease, and a personal or family history of stroke. your doctor also will ask about your signs and symptoms and when they began. during the physical exam, your doctor will check your mental alertness and your coordination and balance. he or she will check for numbness or weakness in your face, arms, and legs; confusion; and trouble speaking and seeing clearly. your doctor will look for signs of carotid artery disease, a common cause of ischemic stroke. he or she will listen to your carotid arteries with a stethoscope. a whooshing sound called a bruit (broo-e) may suggest changed or reduced blood flow due to plaque buildup in the carotid arteries. diagnostic tests and procedures your doctor may recommend one or more of the following tests to diagnose a stroke or tia. brain computed tomography a brain computed tomography (to-mog-rah-fee) scan, or brain ct scan, is a painless test that uses x rays to take clear, detailed pictures of your brain. this test often is done right after a stroke is suspected. a brain ct scan can show bleeding in the brain or damage to the brain cells from a stroke. the test also can show other brain conditions that may be causing your symptoms. magnetic resonance imaging magnetic resonance imaging (mri) uses magnets and radio waves to create pictures of the organs and structures in your body. this test can detect changes in brain tissue and damage to brain cells from a stroke. an mri may be used instead of, or in addition to, a ct scan to diagnose a stroke. computed tomography arteriogram and magnetic resonance arteriogram a ct arteriogram (cta) and magnetic resonance arteriogram (mra) can show the large blood vessels in the brain. these tests may give your doctor more information about the site of a blood clot and the flow of blood through your brain. carotid ultrasound carotid ultrasound is a painless and harmless test that uses sound waves to create pictures of the insides of your carotid arteries. these arteries supply oxygen-rich blood to your brain. carotid ultrasound shows whether plaque has narrowed or blocked your carotid arteries. your carotid ultrasound test may include a doppler ultrasound. doppler ultrasound is a special test that shows the speed and direction of blood moving through your blood vessels. carotid angiography carotid angiography (an-jee-og-ra-fee) is a test that uses dye and special x rays to show the insides of your carotid arteries. for this test, a small tube called a catheter is put into an artery, usually in the groin (upper thigh). the tube is then moved up into one of your carotid arteries. your doctor will inject a substance (called contrast dye) into the carotid artery. the dye helps make the artery visible on x-ray pictures. heart tests ekg (electrocardiogram) an ekg is a simple, painless test that records the heart's electrical activity. the test shows how fast the heart is beating and its rhythm (steady or irregular). an ekg also records the strength and timing of electrical signals as they pass through each part of the heart. an ekg can help detect heart problems that may have led to a stroke. for example, the test can help diagnose atrial fibrillation or a previous heart attack. echocardiography echocardiography (ek-o-kar-de-og-ra-fee), or echo, is a painless test that uses sound waves to create pictures of your heart. the test gives information about the size and shape of your heart and how well your heart's chambers and valves are working. echo can detect possible blood clots inside the heart and problems with the aorta. the aorta is the main artery that carries oxygen-rich blood from your heart to all parts of your body. blood tests your doctor also may use blood tests to help diagnose a stroke. a blood glucose test measures the amount of glucose (sugar) in your blood. low blood glucose levels may cause symptoms similar to those of a stroke. a platelet count measures the number of platelets in your blood. blood platelets are cell fragments that help your blood clot. abnormal platelet levels may be a sign of a bleeding disorder (not enough clotting) or a thrombotic disorder (too much clotting). your doctor also may recommend blood tests to measure how long it takes for your blood to clot. two tests that may be used are called pt and ptt tests. these tests show whether your blood is clotting normally.\",\n",
              "  \"stroke (diagnosis): to determine the most appropriate treatment for your stroke, your emergency team needs to evaluate the type of stroke you're having and the areas of your brain affected by the stroke. they also need to rule out other possible causes of your symptoms, such as a brain tumor or a drug reaction. your doctor may use several tests to determine your risk of stroke, including: - physical examination. your doctor will ask you or a family member what symptoms you've been having, when they started and what you were doing when they began. your doctor then will evaluate whether these symptoms are still present. your doctor will want to know what medications you take and whether you have experienced any head injuries. you'll be asked about your personal and family history of heart disease, transient ischemic attack and stroke. your doctor will check your blood pressure and use a stethoscope to listen to your heart and to listen for a whooshing sound (bruit) over your neck (carotid) arteries, which may indicate atherosclerosis. your doctor may also use an ophthalmoscope to check for signs of tiny cholesterol crystals or clots in the blood vessels at the back of your eyes. - blood tests. you may have several blood tests, which tell your care team how fast your blood clots, whether your blood sugar is abnormally high or low, whether critical blood chemicals are out of balance, or whether you may have an infection. managing your blood's clotting time and levels of sugar and other key chemicals will be part of your stroke care. - computerized tomography (ct) scan. a ct scan uses a series of x-rays to create a detailed image of your brain. a ct scan can show a hemorrhage, tumor, stroke and other conditions. doctors may inject a dye into your bloodstream to view your blood vessels in your neck and brain in greater detail (computerized tomography angiography). there are different types of ct scans that your doctor may use depending on your situation. - magnetic resonance imaging (mri). an mri uses powerful radio waves and magnets to create a detailed view of your brain. an mri can detect brain tissue damaged by an ischemic stroke and brain hemorrhages. your doctor may inject a dye into a blood vessel to view the arteries and veins and highlight blood flow (magnetic resonance angiography, or magnetic resonance venography). - carotid ultrasound. in this test, sound waves create detailed images of the inside of the carotid arteries in your neck. this test shows buildup of fatty deposits (plaques) and blood flow in your carotid arteries. - cerebral angiogram. in this test, your doctor inserts a thin, flexible tube (catheter) through a small incision, usually in your groin, and guides it through your major arteries and into your carotid or vertebral artery. then your doctor injects a dye into your blood vessels to make them visible under x-ray imaging. this procedure gives a detailed view of arteries in your brain and neck. - echocardiogram. an echocardiogram uses sound waves to create detailed images of your heart. an echocardiogram can find a source of clots in your heart that may have traveled from your heart to your brain and caused your stroke. you may have a transesophageal echocardiogram. in this test, your doctor inserts a flexible tube with a small device (transducer) attached into your throat and down into the tube that connects the back of your mouth to your stomach (esophagus). because your esophagus is directly behind your heart, a transesophageal echocardiogram can create clear, detailed ultrasound images of your heart and any blood clots.\",\n",
              "  'how to diagnose stroke?: doctors have several techniques and imaging tools to help diagnose stroke quickly and accurately. the first step in diagnosis is a short neurological examination, or an evaluation of the nervous system. when a possible stroke patient arrives at a hospital, a health care professional, usually a doctor or nurse, will ask the patient or a companion what happened and when the symptoms began. blood tests, an electrocardiogram, and a brain scan such as computed tomography (ct) or magnetic resonance imaging (mri) will often be done.',\n",
              "  'mitochondrial encephalomyopathy lactic acidosis and stroke-like episodes (diagnosis): making a diagnosis for a genetic or rare disease can often be challenging. healthcare professionals typically look at a person’s medical history, symptoms, physical exam, and laboratory test results in order to make a diagnosis. the following resources provide information relating to diagnosis and testing for this condition. if you have questions about getting a diagnosis, you should contact a healthcare professional. testing resources the genetic testing registry (gtr) provides information about the genetic tests for this condition. the intended audience for the gtr is health care providers and researchers. patients and consumers with specific questions about a genetic test should contact a health care provider or a genetics professional. orphanet lists international laboratories offering diagnostic testing for this condition.',\n",
              "  'how to diagnose stroke?: the doctor will do a physical exam to: - check for problems with vision, movement, feeling, reflexes, understanding, and speaking. your doctor and nurses will repeat this exam over time to see if your stroke is getting worse or improving. - listen to the carotid arteries in the neck with a stethoscope for an abnormal sound, called a bruit, which is caused by abnormal blood flow. - check for high blood pressure. you may have the following tests to help find the type, location, and cause of the stroke and rule out other problems: - angiogram of the head to look for a blood vessel that is blocked or bleeding - carotid duplex (ultrasound) to see if the carotid arteries in your neck have narrowed - echocardiogram to see if the stroke could have been caused by a blood clot from the heart - magnetic resonance angiography (mra) or ct angiography to check for abnormal blood vessels in the brain other tests include: - blood tests - electrocardiogram (ecg) and heart rhythm monitoring',\n",
              "  'stroke (diagnosing and treating stroke): a doctor will diagnose a stroke based on symptoms, medical history, and medical tests such as a ct scan. a ct scan is a test that lets doctors look closely at pictures of the brain.all strokes benefit from immediate medical treatment! but only people with ischemic stroke, the kind caused by a blood clot, can be helped by a drug called t-pa (tissue-plasminogen activator). this drug breaks up blood clots and can greatly lessen the damage caused by an ischemic stroke. starting treatment with t-pa within 3 hours after an ischemic stroke is important to recovery. to be evaluated and receive treatment, patients need to get to the hospital within 60 minutes. getting to a hospital right away allows time for a ct scan of the brain. this scan will show whether the clot-busting medicine is the right treatment choice.with stroke, treatment depends on the stage of the disease. there are three treatment stages for stroke: prevention, therapy immediately after stroke, and rehabilitation after stroke. stroke therapies include medications, surgery, and rehabilitation.medication or drug therapy is the most common treatment for stroke. the most popular kinds of drugs to prevent or treat stroke are antithrombotics--which include antiplatelet agents and anticoagulants--and thrombolytics. thrombolytic drugs, like t-pa, halt the stroke by dissolving the blood clot that is blocking blood flow to the brain. antithrombotics prevent the formation of blood clots that can become stuck in an artery of the brain and cause strokes.surgery and vascular procedures can be used to prevent stroke, treat stroke, or repair damage to the blood vessels or malformations in and around the brain. these include angioplasty, stenting, and carotid endarterectomy.',\n",
              "  'ischemic stroke (summary): summary a stroke is a medical emergency. there are two types - ischemic and hemorrhagic. ischemic stroke is the most common type. it is usually caused by a blood clot that blocks or plugs a blood vessel in the brain. this keeps blood from flowing to the brain. within minutes, brain cells begin to die. another cause is stenosis, or narrowing of the artery. this can happen because of atherosclerosis, a disease in which plaque builds up inside your arteries. transient ischemic attacks (tias) occur when the blood supply to the brain is interrupted briefly. having a tia can mean you are at risk for having a more serious stroke. symptoms of stroke are - sudden numbness or weakness of the face, arm or leg (especially on one side of the body) - sudden confusion, trouble speaking or understanding speech - sudden trouble seeing in one or both eyes - sudden trouble walking, dizziness, loss of balance or coordination - sudden severe headache with no known cause it is important to treat strokes as quickly as possible. blood thinners may be used to stop a stroke while it is happening by quickly dissolving the blood clot. post-stroke rehabilitation can help people overcome disabilities caused by stroke damage. nih: national institute of neurological disorders and stroke',\n",
              "  'stroke: a stroke occurs if the flow of oxygen-rich blood to a portion of the brain is blocked. without oxygen, brain cells start to die after a few minutes. sudden bleeding in the brain also can cause a stroke if it damages brain cells. if brain cells die or are damaged because of a stroke, symptoms occur in the parts of the body that these brain cells control. examples of stroke symptoms include sudden weakness; paralysis or numbness of the face, arms, or legs (paralysis is an inability to move); trouble speaking or understanding speech; and trouble seeing. a stroke is a serious medical condition that requires emergency care. a stroke can cause lasting brain damage, long-term disability, or even death. if you think you or someone else is having a stroke, call 9–1–1 right away. do not drive to the hospital or let someone else drive you. call an ambulance so that medical personnel can begin life-saving treatment on the way to the emergency room. during a stroke, every minute counts. overview the two main types of stroke are ischemic (is-ke-mik) and hemorrhagic (hem-ah-raj-ik). ischemic is the more common type of stroke. an ischemic stroke occurs if an artery that supplies oxygen-rich blood to the brain becomes blocked. blood clots often cause the blockages that lead to ischemic strokes. a hemorrhagic stroke occurs if an artery in the brain leaks blood or ruptures (breaks open). the pressure from the leaked blood damages brain cells. high blood pressure and aneurysms (an-u-risms) are examples of conditions that can cause hemorrhagic strokes. (aneurysms are balloon-like bulges in an artery that can stretch and burst.) another condition that’s similar to a stroke is a transient ischemic attack, also called a tia or “mini-stroke.” a tia occurs if blood flow to a portion of the brain is blocked only for a short time. thus, damage to the brain cells isn’t permanent (lasting). like ischemic strokes, tias often are caused by blood clots. although tias are not full-blown strokes, they greatly increase the risk of having a stroke. if you have a tia, it’s important for your doctor to find the cause so you can take steps to prevent a stroke. both strokes and tias require emergency care. outlook stroke is a leading cause of death in the united states. many factors can raise your risk of having a stroke. talk with your doctor about how you can control these risk factors and help prevent a stroke. if you have a stroke, prompt treatment can reduce damage to your brain and help you avoid lasting disabilities. prompt treatment also may help prevent another stroke. researchers continue to study the causes and risk factors for stroke. they’re also finding new and better treatments and new ways to help the brain repair itself after a stroke. ischemic stroke an ischemic stroke occurs if an artery that supplies oxygen-rich blood to the brain becomes blocked. blood clots often cause the blockages that lead to ischemic strokes. the two types of ischemic stroke are thrombotic (throm-bot-ik) and embolic (em-bol-ik). in a thrombotic stroke, a blood clot (thrombus) forms in an artery that supplies blood to the brain. in an embolic stroke, a blood clot or other substance (such as plaque, a fatty material) travels through the bloodstream to an artery in the brain. (a blood clot or piece of plaque that travels through the bloodstream is called an embolus.) with both types of ischemic stroke, the blood clot or plaque blocks the flow of oxygen-rich blood to a portion of the brain. ischemic stroke hemorrhagic stroke a hemorrhagic stroke occurs if an artery in the brain leaks blood or ruptures (breaks open). the pressure from the leaked blood damages brain cells. the two types of hemorrhagic stroke are intracerebral (in-trah-ser-e-bral) and subarachnoid (sub-ah-rak-noyd). in an intracerebral hemorrhage, a blood vessel inside the brain leaks blood or ruptures. in a subarachnoid hemorrhage, a blood vessel on the surface of the brain leaks blood or ruptures. when this happens, bleeding occurs between the inner and middle layers of the membranes that cover the brain. in both types of hemorrhagic stroke, the leaked blood causes swelling of the brain and increased pressure in the skull. the swelling and pressure damage cells and tissues in the brain. hemorrhagic stroke brain attack cerebrovascular accident (cva) hemorrhagic stroke (includes intracerebral hemorrhage and subarachnoid hemorrhage) ischemic stroke (includes thrombotic stroke and embolic stroke) a transient ischemic attack sometimes is called a tia or mini-stroke. a tia has the same symptoms as a stroke, and it increases your risk of having a stroke. ischemic stroke and transient ischemic attack an ischemic stroke or transient ischemic attack (tia) occurs if an artery that supplies oxygen-rich blood to the brain becomes blocked. many medical conditions can increase the risk of ischemic stroke or tia. for example, atherosclerosis (ath-er-o-skler-o-sis) is a disease in which a fatty substance called plaque builds up on the inner walls of the arteries. plaque hardens and narrows the arteries, which limits the flow of blood to tissues and organs (such as the heart and brain). plaque in an artery can crack or rupture (break open). blood platelets (plate-lets), which are disc-shaped cell fragments, stick to the site of the plaque injury and clump together to form blood clots. these clots can partly or fully block an artery. plaque can build up in any artery in the body, including arteries in the heart, brain, and neck. the two main arteries on each side of the neck are called the carotid (ka-rot-id) arteries. these arteries supply oxygen-rich blood to the brain, face, scalp, and neck. when plaque builds up in the carotid arteries, the condition is called carotid artery disease. carotid artery disease causes many of the ischemic strokes and tias that occur in the united states. an embolic stroke (a type of ischemic stroke) or tia also can occur if a blood clot or piece of plaque breaks away from the wall of an artery. the clot or plaque can travel through the bloodstream and get stuck in one of the brain’s arteries. this stops blood flow through the artery and damages brain cells. heart conditions and blood disorders also can cause blood clots that can lead to a stroke or tia. for example, atrial fibrillation (a-tre-al fi-bri-la-shun), or af, is a common cause of embolic stroke. in af, the upper chambers of the heart contract in a very fast and irregular way. as a result, some blood pools in the heart. the pooling increases the risk of blood clots forming in the heart chambers. an ischemic stroke or tia also can occur because of lesions caused by atherosclerosis. these lesions may form in the small arteries of the brain, and they can block blood flow to the brain. hemorrhagic stroke sudden bleeding in the brain can cause a hemorrhagic stroke. the bleeding causes swelling of the brain and increased pressure in the skull. the swelling and pressure damage brain cells and tissues. examples of conditions that can cause a hemorrhagic stroke include high blood pressure, aneurysms, and arteriovenous (ar-teer-e-o-ve-nus) malformations (avms). \"blood pressure\" is the force of blood pushing against the walls of the arteries as the heart pumps blood. if blood pressure rises and stays high over time, it can damage the body in many ways. aneurysms are balloon-like bulges in an artery that can stretch and burst. avms are tangles of faulty arteries and veins that can rupture within the brain. high blood pressure can increase the risk of hemorrhagic stroke in people who have aneurysms or avms. certain traits, conditions, and habits can raise your risk of having a stroke or transient ischemic attack (tia). these traits, conditions, and habits are known as risk factors. the more risk factors you have, the more likely you are to have a stroke. you can treat or control some risk factors, such as high blood pressure and smoking. other risk factors, such as age and gender, you can’t control. the major risk factors for stroke include: high blood pressure. high blood pressure is the main risk factor for stroke. blood pressure is considered high if it stays at or above 140/90 millimeters of mercury (mmhg) over time. if you have diabetes or chronic kidney disease, high blood pressure is defined as 130/80 mmhg or higher. diabetes. diabetes is a disease in which the blood sugar level is high because the body doesn’t make enough insulin or doesn’t use its insulin properly. insulin is a hormone that helps move blood sugar into cells where it’s used for energy. heart diseases. coronary heart disease, cardiomyopathy, heart failure, and atrial fibrillation can cause blood clots that can lead to a stroke. smoking. smoking can damage blood vessels and raise blood pressure. smoking also may reduce the amount of oxygen that reaches your body’s tissues. exposure to secondhand smoke also can damage the blood vessels. age and gender. your risk of stroke increases as you get older. at younger ages, men are more likely than women to have strokes. however, women are more likely to die from strokes. women who take birth control pills also are at slightly higher risk of stroke. race and ethnicity. strokes occur more often in african american, alaska native, and american indian adults than in white, hispanic, or asian american adults. personal or family history of stroke or tia. if you’ve had a stroke, you’re at higher risk for another one. your risk of having a repeat stroke is the highest right after a stroke. a tia also increases your risk of having a stroke, as does having a family history of stroke. brain aneurysms or arteriovenous malformations (avms). aneurysms are balloon-like bulges in an artery that can stretch and burst. avms are tangles of faulty arteries and veins that can rupture (break open) within the brain. avms may be present at birth, but often aren’t diagnosed until they rupture. other risk factors for stroke, many of which of you can control, include: alcohol and illegal drug use, including cocaine, amphetamines, and other drugs certain medical conditions, such as sickle cell disease, vasculitis (inflammation of the blood vessels), and bleeding disorders lack of physical activity overweight and obesity stress and depression unhealthy cholesterol levels unhealthy diet use of nonsteroidal anti-inflammatory drugs (nsaids), but not aspirin, may increase the risk of heart attack or stroke, particularly in patients who have had a heart attack or cardiac bypass surgery. the risk may increase the longer nsaids are used. common nsaids include ibuprofen and naproxen. following a heart-healthy lifestyle can lower the risk of stroke. some people also may need to take medicines to lower their risk. sometimes strokes can occur in people who don’t have any known risk factors. the signs and symptoms of a stroke often develop quickly. however, they can develop over hours or even days. the type of symptoms depends on the type of stroke and the area of the brain that’s affected. how long symptoms last and how severe they are vary among different people. signs and symptoms of a stroke may include: sudden weakness paralysis (an inability to move) or numbness of the face, arms, or legs, especially on one side of the body confusion trouble speaking or understanding speech trouble seeing in one or both eyes problems breathing dizziness, trouble walking, loss of balance or coordination, and unexplained falls loss of consciousness sudden and severe headache a transient ischemic attack (tia) has the same signs and symptoms as a stroke. however, tia symptoms usually last less than 1–2 hours (although they may last up to 24 hours). a tia may occur only once in a person’s lifetime or more often. at first, it may not be possible to tell whether someone is having a tia or stroke. all stroke-like symptoms require medical care. if you think you or someone else is having a tia or stroke, call 9–1–1 right away. do not drive to the hospital or let someone else drive you. call an ambulance so that medical personnel can begin life-saving treatment on the way to the emergency room. during a stroke, every minute counts. stroke complications after you’ve had a stroke, you may develop other complications, such as: blood clots and muscle weakness. being immobile (unable to move around) for a long time can raise your risk of developing blood clots in the deep veins of the legs. being immobile also can lead to muscle weakness and decreased muscle flexibility. problems swallowing and pneumonia. if a stroke affects the muscles used for swallowing, you may have a hard time eating or drinking. you also may be at risk of inhaling food or drink into your lungs. if this happens, you may develop pneumonia. loss of bladder control. some strokes affect the muscles used to urinate. you may need a urinary catheter (a tube placed into the bladder) until you can urinate on your own. use of these catheters can lead to urinary tract infections. loss of bowel control or constipation also may occur after a stroke. your doctor will diagnose a stroke based on your signs and symptoms, your medical history, a physical exam, and test results. your doctor will want to find out the type of stroke you’ve had, its cause, the part of the brain that\\'s affected, and whether you have bleeding in the brain. if your doctor thinks you’ve had a transient ischemic attack (tia), he or she will look for its cause to help prevent a future stroke. medical history and physical exam your doctor will ask you or a family member about your risk factors for stroke. examples of risk factors include high blood pressure, smoking, heart disease, and a personal or family history of stroke. your doctor also will ask about your signs and symptoms and when they began. during the physical exam, your doctor will check your mental alertness and your coordination and balance. he or she will check for numbness or weakness in your face, arms, and legs; confusion; and trouble speaking and seeing clearly. your doctor will look for signs of carotid artery disease, a common cause of ischemic stroke. he or she will listen to your carotid arteries with a stethoscope. a whooshing sound called a bruit (broo-e) may suggest changed or reduced blood flow due to plaque buildup in the carotid arteries. diagnostic tests and procedures your doctor may recommend one or more of the following tests to diagnose a stroke or tia. brain computed tomography a brain computed tomography (to-mog-rah-fee) scan, or brain ct scan, is a painless test that uses x rays to take clear, detailed pictures of your brain. this test often is done right after a stroke is suspected. a brain ct scan can show bleeding in the brain or damage to the brain cells from a stroke. the test also can show other brain conditions that may be causing your symptoms. magnetic resonance imaging magnetic resonance imaging (mri) uses magnets and radio waves to create pictures of the organs and structures in your body. this test can detect changes in brain tissue and damage to brain cells from a stroke. an mri may be used instead of, or in addition to, a ct scan to diagnose a stroke. computed tomography arteriogram and magnetic resonance arteriogram a ct arteriogram (cta) and magnetic resonance arteriogram (mra) can show the large blood vessels in the brain. these tests may give your doctor more information about the site of a blood clot and the flow of blood through your brain. carotid ultrasound carotid ultrasound is a painless and harmless test that uses sound waves to create pictures of the insides of your carotid arteries. these arteries supply oxygen-rich blood to your brain. carotid ultrasound shows whether plaque has narrowed or blocked your carotid arteries. your carotid ultrasound test may include a doppler ultrasound. doppler ultrasound is a special test that shows the speed and direction of blood moving through your blood vessels. carotid angiography carotid angiography (an-jee-og-ra-fee) is a test that uses dye and special x rays to show the insides of your carotid arteries. for this test, a small tube called a catheter is put into an artery, usually in the groin (upper thigh). the tube is then moved up into one of your carotid arteries. your doctor will inject a substance (called contrast dye) into the carotid artery. the dye helps make the artery visible on x-ray pictures. heart tests ekg (electrocardiogram) an ekg is a simple, painless test that records the heart\\'s electrical activity. the test shows how fast the heart is beating and its rhythm (steady or irregular). an ekg also records the strength and timing of electrical signals as they pass through each part of the heart. an ekg can help detect heart problems that may have led to a stroke. for example, the test can help diagnose atrial fibrillation or a previous heart attack. echocardiography echocardiography (ek-o-kar-de-og-ra-fee), or echo, is a painless test that uses sound waves to create pictures of your heart. the test gives information about the size and shape of your heart and how well your heart\\'s chambers and valves are working. echo can detect possible blood clots inside the heart and problems with the aorta. the aorta is the main artery that carries oxygen-rich blood from your heart to all parts of your body. blood tests your doctor also may use blood tests to help diagnose a stroke. a blood glucose test measures the amount of glucose (sugar) in your blood. low blood glucose levels may cause symptoms similar to those of a stroke. a platelet count measures the number of platelets in your blood. blood platelets are cell fragments that help your blood clot. abnormal platelet levels may be a sign of a bleeding disorder (not enough clotting) or a thrombotic disorder (too much clotting). your doctor also may recommend blood tests to measure how long it takes for your blood to clot. two tests that may be used are called pt and ptt tests. these tests show whether your blood is clotting normally. treatment for a stroke depends on whether it is ischemic or hemorrhagic. treatment for a transient ischemic attack (tia) depends on its cause, how much time has passed since symptoms began, and whether you have other medical conditions. strokes and tias are medical emergencies. if you have stroke symptoms, call 9–1–1 right away. do not drive to the hospital or let someone else drive you. call an ambulance so that medical personnel can begin lifesaving treatment on the way to the emergency room. during a stroke, every minute counts. once you receive immediate treatment, your doctor will try to treat your stroke risk factors and prevent complications by recommending heart-healthy lifestyle changes. treating an ischemic stroke or transient ischemic attack an ischemic stroke or tia occurs if an artery that supplies oxygen-rich blood to the brain becomes blocked. often, blood clots cause the blockages that lead to ischemic strokes and tias. treatment for an ischemic stroke or tia may include medicines and medical procedures. medicines if you have a stroke caused by a blood clot, you may be given a clot-dissolving, or clot-busting, medication called tissue plasminogen activator (tpa). a doctor will inject tpa into a vein in your arm. this type of medication must be given within 4 hours of symptom onset. ideally, it should be given as soon as possible. the sooner treatment begins, the better your chances of recovery. thus, it’s important to know the signs and symptoms of a stroke and to call 9–1–1 right away for emergency care. if you can’t have tpa for medical reasons, your doctor may give you antiplatelet medicine that helps stop platelets from clumping together to form blood clots or anticoagulant medicine (blood thinner) that keeps existing blood clots from getting larger. two common medicines are aspirin and clopidogrel. medical procedures if you have carotid artery disease, your doctor may recommend a carotid endarterectomy or carotid artery angioplasty. both procedures open blocked carotid arteries. researchers are testing other treatments for ischemic stroke, such as intra-arterial thrombolysis and mechanical clot removal in cerebral ischemia (merci). in intra-arterial thrombolysis, a long flexible tube called a catheter is put into your groin (upper thigh) and threaded to the tiny arteries of the brain. your doctor can deliver medicine through this catheter to break up a blood clot in the brain. merci is a device that can remove blood clots from an artery. during the procedure, a catheter is threaded through a carotid artery to the affected artery in the brain. the device is then used to pull the blood clot out through the catheter. treating a hemorrhagic stroke a hemorrhagic stroke occurs if an artery in the brain leaks blood or ruptures. the first steps in treating a hemorrhagic stroke are to find the cause of bleeding in the brain and then control it. unlike ischemic strokes, hemorrhagic strokes aren’t treated with antiplatelet medicines and blood thinners because these medicines can make bleeding worse. if you’re taking antiplatelet medicines or blood thinners and have a hemorrhagic stroke, you’ll be taken off the medicine. if high blood pressure is the cause of bleeding in the brain, your doctor may prescribe medicines to lower your blood pressure. this can help prevent further bleeding. surgery also may be needed to treat a hemorrhagic stroke. the types of surgery used include aneurysm clipping, coil embolization, and arteriovenous malformation (avm) repair. aneurysm clipping and coil embolization if an aneurysm (a balloon-like bulge in an artery) is the cause of a stroke, your doctor may recommend aneurysm clipping or coil embolization. aneurysm clipping is done to block off the aneurysm from the blood vessels in the brain. this surgery helps prevent further leaking of blood from the aneurysm. it also can help prevent the aneurysm from bursting again. during the procedure, a surgeon will make an incision (cut) in the brain and place a tiny clamp at the base of the aneurysm. you’ll be given medicine to make you sleep during the surgery. after the surgery, you’ll need to stay in the hospital’s intensive care unit for a few days. coil embolization is a less complex procedure for treating an aneurysm. the surgeon will insert a tube called a catheter into an artery in the groin. he or she will thread the tube to the site of the aneurysm. then, a tiny coil will be pushed through the tube and into the aneurysm. the coil will cause a blood clot to form, which will block blood flow through the aneurysm and prevent it from bursting again. coil embolization is done in a hospital. you’ll be given medicine to make you sleep during the surgery. arteriovenous malformation repair if an avm is the cause of a stroke, your doctor may recommend an avm repair. (an avm is a tangle of faulty arteries and veins that can rupture within the brain.) avm repair helps prevent further bleeding in the brain. doctors use several methods to repair avms. these methods include: injecting a substance into the blood vessels of the avm to block blood flow surgery to remove the avm using radiation to shrink the blood vessels of the avm treating stroke risk factors after initial treatment for a stroke or tia, your doctor will treat your risk factors. he or she may recommend heart-healthy lifestyle changes to help control your risk factors. heart-healthy lifestyle changes may include: heart-healthy eating aiming for a healthy weight managing stress physical activity quitting smoking if heart-healthy lifestyle changes aren’t enough, you may need medicine to control your risk factors.   taking action to control your risk factors can help prevent or delay a stroke. if you’ve already had a stroke. talk to your doctor about whether you may benefit from aspirin primary prevention, or using aspirin to help prevent your first stroke. the following heart-healthy lifestyle changes can help prevent your first stroke and help prevent you from having another one. be physically active. physical activity can improve your fitness level and health. talk with your doctor about what types and amounts of activity are safe for you. don’t smoke, or if you smoke or use tobacco, quit. smoking can damage and tighten blood vessels and raise your risk of stroke. talk with your doctor about programs and products that can help you quit. also, secondhand smoke can damage the blood vessels. aim for a healthy weight. if you’re overweight or obese, work with your doctor to create a reasonable weight loss plan. controlling your weight helps you control risk factors for stroke. make heart-healthy eating choices. heart-healthy eating can help lower your risk or prevent a stroke. manage stress. use techniques to lower your stress levels. if you or someone in your family has had a stroke, be sure to tell your doctor. by knowing your family history of stroke, you may be able to lower your risk factors and prevent or delay a stroke. if you’ve had a transient ischemic attack (tia), don’t ignore it. tias are warnings, and it’s important for your doctor to find the cause of the tia so you can take steps to prevent a stroke.   the time it takes to recover from a stroke varies—it can take weeks, months, or even years. some people recover fully, while others have long-term or lifelong disabilities. ongoing care, rehabilitation, and emotional support can help you recover and may even help prevent another stroke. if you’ve had a stroke, you’re at risk of having another one. know the warning signs and what to do if a stroke or transient ischemic attack (tia) occurs. call 9–1–1 as soon as symptoms start. do not drive to the hospital or let someone else drive you. by calling an ambulance, medical personnel can begin lifesaving treatment on the way to the emergency room. during a stroke, every minute counts. ongoing care heart-healthy lifestyle changes heart-healthy lifestyle changes can help you recover from a stroke and may help prevent another one. examples of these changes include heart-healthy eating, aiming for a healthy weight, managing stress, physical activity, and quitting smoking. medicines your doctor also may prescribe medicines to help you recover from a stroke or control your stroke risk factors. take all of your medicines as your doctor prescribes. don’t cut back on the dosage unless your doctor tells you to do so. if you have side effects or other problems related to your medicines, talk with your doctor. medicines called anticoagulants or blood thinners, which prevent blood clots or keep existing blood clots from getting larger, are the main treatment for people who have known carotid artery disease, which can lead to a stroke. two common medicines are aspirin and clopidogrel. you’ll likely need routine blood tests to check how well these medicines are working. the most common side effect of blood thinners is bleeding. this happens if the medicine thins your blood too much. this side effect can be life-threatening. bleeding can occur inside your body cavities (internal bleeding) or from the surface of your skin (external bleeding). know the warning signs of bleeding so you can get help right away. they include: blood in your urine, bright red blood in your stools, or black tarry stools bright red vomit or vomit that looks like coffee grounds increased menstrual flow pain in your abdomen or severe pain in your head unexplained bleeding from the gums and nose unexplained bruising or tiny red or purple dots on the skin a lot of bleeding after a fall or injury or easy bruising or bleeding also may mean that your blood is too thin. call your doctor right away if you have any of these signs. if you have severe bleeding, call 9–1–1. your doctor also may discuss beginning statin treatment. doctors recommend statin medications for many people because they help lower or control blood cholesterol levels and decrease the chance for heart attack and stroke. doctors usually prescribe statins for people who have: diabetes heart disease or have had a stroke high ldl cholesterol levels you should still follow a heart-healthy lifestyle, even if you take medicines to control your risk factors for stroke. take all medicines regularly, as your doctor prescribes. don’t change the amount of your medicine or skip a dose unless your doctor tells you to. talk with your doctor about how often you should schedule follow-up visits or tests. these visits and tests can help your doctor monitor your stroke risk factors and adjust your treatment as needed. rehabilitation after a stroke, you may need rehabilitation (rehab) to help you recover. rehab may include working with speech, physical, and occupational therapists. language, speech, and memory you may have trouble communicating after a stroke. you may not be able to find the right words, put complete sentences together, or put words together in a way that makes sense. you also may have problems with your memory and thinking clearly. these problems can be very frustrating. speech and language therapists can help you learn ways to communicate again and improve your memory. muscle and nerve problems a stroke may affect only one side of the body or part of one side. it can cause paralysis (an inability to move) or muscle weakness, which can put you at risk for falling. physical and occupational therapists can help you strengthen and stretch your muscles. they also can help you relearn how to do daily activities, such as dressing, eating, and bathing. bladder and bowel problems a stroke can affect the muscles and nerves that control the bladder and bowels. you may feel like you have to urinate often, even if your bladder isn’t full. you may not be able to get to the bathroom in time. medicines and a bladder or bowel specialist can help with these problems. swallowing and eating problems you may have trouble swallowing after a stroke. signs of this problem are coughing or choking during eating or coughing up food after eating. a speech therapist can help you with these issues. he or she may suggest changes to your diet, such as eating puréed (finely chopped) foods or drinking thick liquids. mental health care and support after a stroke, you may have changes in your behavior or judgment. for example, your mood may change quickly. because of these and other changes, you may feel scared, anxious, and depressed. recovering from a stroke can be slow and frustrating. talk about how you feel with your health care team. talking to a professional counselor also can help. if you’re very depressed, your doctor may recommend medicines or other treatments that can improve your quality of life. joining a patient support group may help you adjust to life after a stroke. you can see how other people have coped with having strokes. talk with your doctor about local support groups, or check with an area medical center. support from family and friends also can help relieve fear and anxiety. let your loved ones know how you feel and what they can do to help you.',\n",
              "  \"stroke: a stroke is serious, just like a heart attack, so it's important to know the signs of stroke and act quickly if you suspect someone is having one. stroke is the fourth leading cause of death in the united states, and causes more serious long-term disabilities than any other disease. older people are at higher risk. you can take steps to lower your chance of having a stroke.know the signs of stroke knowing the symptoms of a stroke and acting quickly could mean the difference between life and disability or death. call 911 right away if you see or have any of these symptoms: - sudden numbness or weakness in the face, arm, or leg-especially on one side of the body - sudden confusion or trouble speaking or understanding - sudden problems seeing in one eye or both eyes - sudden dizziness, loss of balance or coordination, or trouble walking - sudden severe headache with no known cause other danger signs that may occur include double vision, drowsiness, and nausea or vomiting. stroke strikes fast. you should too. call 911. never ignore the symptoms of stroke. call 911 if you have any stroke symptoms, even if they don't last long. don't ignore the signs of stroke! a stroke is serious, just like a heart attack, so it's important to know the signs of stroke and act quickly if you suspect someone is having one. stroke is the fourth leading cause of death in the united states, and causes more serious long-term disabilities than any other disease. older people are at higher risk. you can take steps to lower your chance of having a stroke.know the signs of stroke knowing the symptoms of a stroke and acting quickly could mean the difference between life and disability or death. call 911 right away if you see or have any of these symptoms: - sudden numbness or weakness in the face, arm, or leg-especially on one side of the body - sudden confusion or trouble speaking or understanding - sudden problems seeing in one eye or both eyes - sudden dizziness, loss of balance or coordination, or trouble walking - sudden severe headache with no known cause other danger signs that may occur include double vision, drowsiness, and nausea or vomiting. stroke strikes fast. you should too. call 911. never ignore the symptoms of stroke. call 911 if you have any stroke symptoms, even if they don't last long. don't ignore the signs of stroke! a stroke happens when something changes how blood flows through the brain. blood brings oxygen and nutrients to brain cells. if blood can't flow to a part of the brain, cells that do not receive enough oxygen suffer and eventually die. if brain cells are without oxygen for only a short time, they can sometimes get better. but brain cells that have died can't be brought back to life. so, someone who has had a stroke may have trouble speaking, thinking, or walking.there are two major types of stroke. the most common kind, ischemic, is caused by a blood clot or the narrowing of a blood vessel (an artery) leading to the brain. this keeps blood from flowing into other parts of the brain and keeps needed oxygen and nutrients from reaching brain cells. blockages that cause ischemic strokes stem from three conditions:- formation of a clot within a blood vessel of the brain or neck, called thrombosis - movement of a clot from another part of the body, such as from the heart to the neck or brain, called an embolism - severe narrowing of an artery (stenosis) in or leading to the brain, due to fatty deposits lining the blood vessel wallsin the second major kind of stroke, hemorrhagic, a broken blood vessel causes bleeding in the brain. this break in the vessel also stops oxygen and nutrients from reaching brain cells.sometimes the symptoms of a stroke last only a few minutes and then go away. that could be a transient ischemic attack (tia), also called a mini-stroke. a tia is a medical emergency. you should get medical help right away. if a tia is not treated quickly, it could be followed within hours or days by a major disabling stroke. some risk factors for stroke, like age, race, and family history, can't be controlled. but you can make changes to lower your risk of stroke. talk to your doctor about what you can do. even if you're in perfect health, follow these suggestions:- control your blood pressure. have your blood pressure checked often. if it is high, follow your doctor's advice to lower it. treating high blood pressure lowers the risk of both stroke and heart disease. - stop smoking. smoking increases your risk for stroke. it's never too late to quit. - control your cholesterol. if you have high cholesterol, work with your doctor to lower it. cholesterol, a type of fat in the blood, can build up on the walls of your arteries. in time, this can block blood flow and lead to a stroke. - control your diabetes. untreated diabetes can damage blood vessels and also leads to narrowed arteries and stroke. follow your doctor's suggestions for keeping diabetes under control. - eat healthy foods. eat foods that are low in cholesterol and saturated fats. include a variety of fruits and vegetables every day. - exercise regularly. try to make physical activity a part of your everyday life. do things you like; for example, take a brisk walk, ride a bicycle, or go swimming. talk with your healthcare provider if you haven't been exercising and you want to start a vigorous program or increase your physical activity. for more information on exercise and physical activity from the national institute on aging at nih, visit www.nia.nih.gov/go4life.if you have had a stroke in the past, it's important to reduce your risk of a second stroke. your brain helps you recover from a stroke by drawing on body systems that now do double duty. that means a second stroke can be twice as bad. a doctor will diagnose a stroke based on symptoms, medical history, and medical tests such as a ct scan. a ct scan is a test that lets doctors look closely at pictures of the brain.all strokes benefit from immediate medical treatment! but only people with ischemic stroke, the kind caused by a blood clot, can be helped by a drug called t-pa (tissue-plasminogen activator). this drug breaks up blood clots and can greatly lessen the damage caused by an ischemic stroke. starting treatment with t-pa within 3 hours after an ischemic stroke is important to recovery. to be evaluated and receive treatment, patients need to get to the hospital within 60 minutes. getting to a hospital right away allows time for a ct scan of the brain. this scan will show whether the clot-busting medicine is the right treatment choice.with stroke, treatment depends on the stage of the disease. there are three treatment stages for stroke: prevention, therapy immediately after stroke, and rehabilitation after stroke. stroke therapies include medications, surgery, and rehabilitation.medication or drug therapy is the most common treatment for stroke. the most popular kinds of drugs to prevent or treat stroke are antithrombotics--which include antiplatelet agents and anticoagulants--and thrombolytics. thrombolytic drugs, like t-pa, halt the stroke by dissolving the blood clot that is blocking blood flow to the brain. antithrombotics prevent the formation of blood clots that can become stuck in an artery of the brain and cause strokes.surgery and vascular procedures can be used to prevent stroke, treat stroke, or repair damage to the blood vessels or malformations in and around the brain. these include angioplasty, stenting, and carotid endarterectomy. a stroke can cause a variety of health problems. how a stroke affects a person depends on which part of the brain is damaged.someone who has had a stroke might be paralyzed or have weakness, usually on one side of the body. he or she might have trouble speaking or using words. there could be swallowing problems. there might be pain or numbness.stroke may cause problems with thinking, awareness, attention, learning, judgment, and memory. someone who has had a stroke might feel depressed or find it hard to control emotions. post-stroke depression may be more than general sadness resulting from the stroke incident. it is a serious behavioral problem that can hamper recovery and rehabilitation and may even lead to suicide.there are many different ways to help people get better after a stroke. many treatments start in the hospital and continue at home. drugs and physical therapy can help improve balance, coordination, and problems such as trouble speaking and using words. occupational therapy can make it easier to do things like taking a bath or cooking.some people make a full recovery soon after a stroke. others take months or even years. but, sometimes the damage is so serious that therapy cannot really help.learn about rehabilitation after stroke. stroke is the number one cause of serious adult disability in the united states. stroke disability is devastating to the stroke patient and family, but therapies are available to help rehabilitate patients after stroke.for most stroke patients, rehabilitation mainly involves physical therapy. the aim of physical therapy is to have the stroke patient relearn simple motor activities such as walking, sitting, standing, lying down, and the process of switching from one type of movement to another.another type of therapy to help patients relearn daily activities is occupational therapy. this type of therapy also involves exercise and training. its goal is to help the stroke patient relearn everyday activities such as eating, drinking and swallowing, dressing, bathing, cooking, reading and writing, and using the toilet. occupational therapists seek to help the patient become independent or semi-independent.speech therapy helps stroke patients relearn language and speaking skills, or learn other forms of communication. speech therapy is appropriate for patients who have no problems with cognition or thinking, but have problems understanding speech or written words, or problems forming speech. with time and patience, a stroke survivor should be able to regain some, and sometimes all, language and speaking abilities.learn more about stroke signs, treatment, and prevention from the centers for disease control and prevention. stroke is the number one cause of serious adult disability in the united states. stroke disability is devastating to the stroke patient and family, but therapies are available to help rehabilitate patients after stroke.for most stroke patients, rehabilitation mainly involves physical therapy. the aim of physical therapy is to have the stroke patient relearn simple motor activities such as walking, sitting, standing, lying down, and the process of switching from one type of movement to another.another type of therapy to help patients relearn daily activities is occupational therapy. this type of therapy also involves exercise and training. its goal is to help the stroke patient relearn everyday activities such as eating, drinking and swallowing, dressing, bathing, cooking, reading and writing, and using the toilet. occupational therapists seek to help the patient become independent or semi-independent.speech therapy helps stroke patients relearn language and speaking skills, or learn other forms of communication. speech therapy is appropriate for patients who have no problems with cognition or thinking, but have problems understanding speech or written words, or problems forming speech. with time and patience, a stroke survivor should be able to regain some, and sometimes all, language and speaking abilities.learn more about stroke signs, treatment, and prevention from the centers for disease control and prevention. stroke is the number one cause of serious adult disability in the united states. stroke disability is devastating to the stroke patient and family, but therapies are available to help rehabilitate patients after stroke.for most stroke patients, rehabilitation mainly involves physical therapy. the aim of physical therapy is to have the stroke patient relearn simple motor activities such as walking, sitting, standing, lying down, and the process of switching from one type of movement to another.another type of therapy to help patients relearn daily activities is occupational therapy. this type of therapy also involves exercise and training. its goal is to help the stroke patient relearn everyday activities such as eating, drinking and swallowing, dressing, bathing, cooking, reading and writing, and using the toilet. occupational therapists seek to help the patient become independent or semi-independent.speech therapy helps stroke patients relearn language and speaking skills, or learn other forms of communication. speech therapy is appropriate for patients who have no problems with cognition or thinking, but have problems understanding speech or written words, or problems forming speech. with time and patience, a stroke survivor should be able to regain some, and sometimes all, language and speaking abilities.learn more about stroke signs, treatment, and prevention from the centers for disease control and prevention.\",\n",
              "  'recovering after stroke (summary): a stroke happens when blood flow to any part of the brain stops. each person has a different recovery time and need for long-term care. problems with moving, thinking, and talking often improve in the first weeks or months after a stroke. some people will keep improving months or years after a stroke.'],\n",
              " ['5', '4', '1', '10', '2', '3', '9', '7', '6', '8'],\n",
              " [1, 1, 1, 0, 1, 1, 0, 1, 1, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrbouUBaSoqL"
      },
      "source": [
        "text = \"Here is the sentence I want embeddings for.\"\n",
        "text = QA[13][0]\n",
        "marked_text = \"[CLS] \" + text #+ \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37tJBtGS4UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea03b59-d771-44da-cfee-8d07f79ad58e"
      },
      "source": [
        "tokenized_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'what', 'are', 'the', 'treatments', 'of', 'stroke', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_VPdqqZS6KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b4961a103212423296653018838aaa87",
            "10eb159905cb4da881e506bea7ef3bf7",
            "1a0d610808c54752a01d8fafe188c6a5",
            "98128371afc04f1495643f1524b95c7a",
            "ff2c3058101f4d7b8ec7e6b479ab5924",
            "3a3968f8f4114cbcbd04edb27c82717e",
            "4080dd44dc56497eb9585b20104cf45a",
            "e40dd44721f5472baae808befb672eb9",
            "d8865f8d7f684edcb9c323c7b30ac7a6",
            "1f8d2fe393ea4898a5d9384974cc7e6f",
            "b97b0de7f6684d60a0744f03f63c3510",
            "e7e5210cbf89470d914f0dec74f58fc0",
            "07b7a135531e43fb8174e780bf4a54e9",
            "9c8345c9dea24483a59817527326f1ef",
            "dad2627650c6436fa21d6cf6bb1b2143",
            "85f6584af22b4a1e931aad09f7fe66b2"
          ]
        },
        "outputId": "92264023-b3d7-4d85-97c7-389960aae062"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4961a103212423296653018838aaa87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8865f8d7f684edcb9c323c7b30ac7a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTcax3jJT_vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d860bef6-0f48-4341-eed8-2b35b37f094f"
      },
      "source": [
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "print(tokenized_text)\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'what', 'are', 'the', 'treatments', 'of', 'stroke', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ1pzp84UNqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71c0e84-661b-4fec-af03-7ca80c05a55a"
      },
      "source": [
        "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "indexed_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2054, 2024, 1996, 13441, 1997, 6909, 1029]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLQX3ZpH7uNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c8fb76-d2b0-4dbd-a438-df22a0187980"
      },
      "source": [
        "segments_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU6Ewro4Ut6g"
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1hzPm4aUe9M"
      },
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePo-iN_FUpNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654b14e7-5820-40ac-dab0-7391da27e137"
      },
      "source": [
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 8, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN60nnpVVpyo"
      },
      "source": [
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhwJLwsCWQ94"
      },
      "source": [
        "def get_bert_sentence_embedding(sentence):\n",
        "    marked_text = \"[CLS] \" + sentence + \" [SEP]\"\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "    # Map the token strings to their vocabulary indeces.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "        # Evaluating the model will return a different number of objects based on \n",
        "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "        # becase we set `output_hidden_states = True`, the third item will be the \n",
        "        # hidden states from all layers. See the documentation for more details:\n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    # print(len(hidden_states.shape))\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "\n",
        "    # Calculate the average of all n token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "\n",
        "    return sentence_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQriO3btXAir"
      },
      "source": [
        "q = get_bert_sentence_embedding(QA[1][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrJWZ9znXJLg"
      },
      "source": [
        "ans = [get_bert_sentence_embedding(a[:512]) for a in QA[1][1]] # 512 is the maximum length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfVYsDUDXSHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1a596c-f0e6-4bd2-85c1-12b968bb34ef"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "K = 7 #??\n",
        "print('Label,Rank,Similarity')\n",
        "for i,a in enumerate(ans):\n",
        "    sim = 1-cosine(q, a)\n",
        "    print(QA[K][3][i], QA[K][2][i], sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label,Rank,Similarity\n",
            "1 2 0.6373712420463562\n",
            "1 1 0.6467930674552917\n",
            "0 6 0.6238508820533752\n",
            "1 3 0.6424947381019592\n",
            "0 4 0.6456063389778137\n",
            "0 8 0.6047689318656921\n",
            "0 7 0.6128425598144531\n",
            "0 9 0.6312223076820374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6GMd3aEYlmK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY0_lyO8KdWJ"
      },
      "source": [
        "## BIO-BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgmke4dJKfID",
        "outputId": "70a22e57-1244-469c-df4b-86d825a92c30"
      },
      "source": [
        "! git clone https://github.com/dmis-lab/biobert.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'biobert'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 326 (delta 26), reused 7 (delta 3), pack-reused 278\u001b[K\n",
            "Receiving objects: 100% (326/326), 507.09 KiB | 7.14 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg7mA966K20W"
      },
      "source": [
        "! cd biobert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlK1gBbVLC2j",
        "outputId": "69bfdc04-3d72-4049-8ec5-8f28756c3927"
      },
      "source": [
        "cd biobert"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/biobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xFaGFtvlLE0V",
        "outputId": "36400523-87bf-455b-f1f7-8063e996631e"
      },
      "source": [
        "# Install requirements\n",
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.0)\n",
            "Collecting pandas==0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ec/8ff0800b8594691759b78a42ccd616f81e7099ee47b167eb9bbd502c02b9/pandas-0.23.0-cp36-cp36m-manylinux1_x86_64.whl (11.7MB)\n",
            "\u001b[K     |████████████████████████████████| 11.7MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.23->-r requirements.txt (line 7)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23->-r requirements.txt (line 7)) (2.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2->-r requirements.txt (line 1)) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=167dfff8558252f15730601c1767a1308d0dd8afd9d0bb118e1384e5b85db1a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow-gpu, pandas\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 pandas-0.23.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TqXEwRdPFzl",
        "outputId": "e2b66df1-64cb-470e-a4b0-c885d571687f"
      },
      "source": [
        "# Download datasets\n",
        "! ./download.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BIOBERT_DATA not set; downloading to default path ('data').\n",
            "--2020-11-22 16:26:15--  https://docs.google.com/uc?export=download&confirm=SwVU&id=1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.113, 74.125.20.139, 74.125.20.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download [following]\n",
            "--2020-11-22 16:26:15--  https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download\n",
            "Resolving doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84\n",
            "Connecting to doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=737ovtluehqrs&continue=https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e%3Ddownload&hash=5033fqhkj7uekb95mmi8rkojjo09s0bl [following]\n",
            "--2020-11-22 16:26:15--  https://docs.google.com/nonceSigner?nonce=737ovtluehqrs&continue=https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e%3Ddownload&hash=5033fqhkj7uekb95mmi8rkojjo09s0bl\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download&nonce=737ovtluehqrs&user=08359205414467609423Z&hash=5rlt2i8cdjtkbodftq2ukdlp7i2ssena [following]\n",
            "--2020-11-22 16:26:15--  https://doc-08-bk-docs.googleusercontent.com/docs/securesc/uga5fjll8m55msqajnbmp1tthn7a8guk/6vfb0snrjac6o3rgr889j8677odh5flt/1606062375000/13799006341648886493/08359205414467609423Z/1cGqvAm9IZ_86C4Mj7Zf-w9CFilYVDl8j?e=download&nonce=737ovtluehqrs&user=08359205414467609423Z&hash=5rlt2i8cdjtkbodftq2ukdlp7i2ssena\n",
            "Connecting to doc-08-bk-docs.googleusercontent.com (doc-08-bk-docs.googleusercontent.com)|74.125.142.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘./data.tar.gz’\n",
            "\n",
            "./data.tar.gz           [  <=>               ]  28.24M  92.9MB/s    in 0.3s    \n",
            "\n",
            "2020-11-22 16:26:16 (92.9 MB/s) - ‘./data.tar.gz’ saved [29610233]\n",
            "\n",
            "datasets/\n",
            "datasets/RE/\n",
            "datasets/RE/GAD/\n",
            "datasets/RE/GAD/6/\n",
            "datasets/RE/GAD/6/test.tsv\n",
            "datasets/RE/GAD/6/dev.tsv\n",
            "datasets/RE/GAD/6/train.tsv\n",
            "datasets/RE/GAD/7/\n",
            "datasets/RE/GAD/7/test.tsv\n",
            "datasets/RE/GAD/7/dev.tsv\n",
            "datasets/RE/GAD/7/train.tsv\n",
            "datasets/RE/GAD/5/\n",
            "datasets/RE/GAD/5/test.tsv\n",
            "datasets/RE/GAD/5/dev.tsv\n",
            "datasets/RE/GAD/5/train.tsv\n",
            "datasets/RE/GAD/8/\n",
            "datasets/RE/GAD/8/test.tsv\n",
            "datasets/RE/GAD/8/dev.tsv\n",
            "datasets/RE/GAD/8/train.tsv\n",
            "datasets/RE/GAD/4/\n",
            "datasets/RE/GAD/4/test.tsv\n",
            "datasets/RE/GAD/4/dev.tsv\n",
            "datasets/RE/GAD/4/train.tsv\n",
            "datasets/RE/GAD/1/\n",
            "datasets/RE/GAD/1/test.tsv\n",
            "datasets/RE/GAD/1/dev.tsv\n",
            "datasets/RE/GAD/1/train.tsv\n",
            "datasets/RE/GAD/2/\n",
            "datasets/RE/GAD/2/test.tsv\n",
            "datasets/RE/GAD/2/dev.tsv\n",
            "datasets/RE/GAD/2/train.tsv\n",
            "datasets/RE/GAD/3/\n",
            "datasets/RE/GAD/3/test.tsv\n",
            "datasets/RE/GAD/3/dev.tsv\n",
            "datasets/RE/GAD/3/train.tsv\n",
            "datasets/RE/GAD/9/\n",
            "datasets/RE/GAD/9/test.tsv\n",
            "datasets/RE/GAD/9/dev.tsv\n",
            "datasets/RE/GAD/9/train.tsv\n",
            "datasets/RE/GAD/10/\n",
            "datasets/RE/GAD/10/test.tsv\n",
            "datasets/RE/GAD/10/dev.tsv\n",
            "datasets/RE/GAD/10/train.tsv\n",
            "datasets/RE/euadr/\n",
            "datasets/RE/euadr/6/\n",
            "datasets/RE/euadr/6/test.tsv\n",
            "datasets/RE/euadr/6/dev.tsv\n",
            "datasets/RE/euadr/6/train.tsv\n",
            "datasets/RE/euadr/7/\n",
            "datasets/RE/euadr/7/test.tsv\n",
            "datasets/RE/euadr/7/dev.tsv\n",
            "datasets/RE/euadr/7/train.tsv\n",
            "datasets/RE/euadr/5/\n",
            "datasets/RE/euadr/5/test.tsv\n",
            "datasets/RE/euadr/5/dev.tsv\n",
            "datasets/RE/euadr/5/train.tsv\n",
            "datasets/RE/euadr/8/\n",
            "datasets/RE/euadr/8/test.tsv\n",
            "datasets/RE/euadr/8/dev.tsv\n",
            "datasets/RE/euadr/8/train.tsv\n",
            "datasets/RE/euadr/4/\n",
            "datasets/RE/euadr/4/test.tsv\n",
            "datasets/RE/euadr/4/dev.tsv\n",
            "datasets/RE/euadr/4/train.tsv\n",
            "datasets/RE/euadr/1/\n",
            "datasets/RE/euadr/1/test.tsv\n",
            "datasets/RE/euadr/1/dev.tsv\n",
            "datasets/RE/euadr/1/train.tsv\n",
            "datasets/RE/euadr/2/\n",
            "datasets/RE/euadr/2/test.tsv\n",
            "datasets/RE/euadr/2/dev.tsv\n",
            "datasets/RE/euadr/2/train.tsv\n",
            "datasets/RE/euadr/3/\n",
            "datasets/RE/euadr/3/test.tsv\n",
            "datasets/RE/euadr/3/dev.tsv\n",
            "datasets/RE/euadr/3/train.tsv\n",
            "datasets/RE/euadr/9/\n",
            "datasets/RE/euadr/9/test.tsv\n",
            "datasets/RE/euadr/9/dev.tsv\n",
            "datasets/RE/euadr/9/train.tsv\n",
            "datasets/RE/euadr/10/\n",
            "datasets/RE/euadr/10/test.tsv\n",
            "datasets/RE/euadr/10/dev.tsv\n",
            "datasets/RE/euadr/10/train.tsv\n",
            "datasets/QA/\n",
            "datasets/QA/BioASQ/\n",
            "datasets/QA/BioASQ/6B1_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-4.json\n",
            "datasets/QA/BioASQ/5B3_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-2.json\n",
            "datasets/QA/BioASQ/4B1_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-train-yesno-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-5.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-2.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-2.json\n",
            "datasets/QA/BioASQ/4B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-3.json\n",
            "datasets/QA/BioASQ/6B3_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-3.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-5.json\n",
            "datasets/QA/BioASQ/BioASQ-test-yesno-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-1.json\n",
            "datasets/QA/BioASQ/6B5_golden.json\n",
            "datasets/QA/BioASQ/5B1_golden.json\n",
            "datasets/QA/BioASQ/4B5_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-3.json\n",
            "datasets/QA/BioASQ/7B_golden.json\n",
            "datasets/QA/BioASQ/5B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-6b.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-7b.json\n",
            "datasets/QA/BioASQ/SHA1.txt\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-5b.json\n",
            "datasets/QA/BioASQ/5B2_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-4.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-1.json\n",
            "datasets/QA/BioASQ/4B3_golden.json\n",
            "datasets/QA/BioASQ/6B2_golden.json\n",
            "datasets/QA/BioASQ/4B2_golden.json\n",
            "datasets/QA/BioASQ/6B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-5.json\n",
            "datasets/QA/BioASQ/5B5_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-4.json\n",
            "datasets/NER/\n",
            "datasets/NER/linnaeus/\n",
            "datasets/NER/linnaeus/devel.tsv\n",
            "datasets/NER/linnaeus/test.tsv\n",
            "datasets/NER/linnaeus/train_dev.tsv\n",
            "datasets/NER/linnaeus/train.tsv\n",
            "datasets/NER/BC2GM/\n",
            "datasets/NER/BC2GM/devel.tsv\n",
            "datasets/NER/BC2GM/test.tsv\n",
            "datasets/NER/BC2GM/train_dev.tsv\n",
            "datasets/NER/BC2GM/train.tsv\n",
            "datasets/NER/BC5CDR-disease/\n",
            "datasets/NER/BC5CDR-disease/devel.tsv\n",
            "datasets/NER/BC5CDR-disease/test.tsv\n",
            "datasets/NER/BC5CDR-disease/train_dev.tsv\n",
            "datasets/NER/BC5CDR-disease/train.tsv\n",
            "datasets/NER/NCBI-disease/\n",
            "datasets/NER/NCBI-disease/devel.tsv\n",
            "datasets/NER/NCBI-disease/test.tsv\n",
            "datasets/NER/NCBI-disease/train_dev.tsv\n",
            "datasets/NER/NCBI-disease/train.tsv\n",
            "datasets/NER/s800/\n",
            "datasets/NER/s800/devel.tsv\n",
            "datasets/NER/s800/test.tsv\n",
            "datasets/NER/s800/train_dev.tsv\n",
            "datasets/NER/s800/train.tsv\n",
            "datasets/NER/BC5CDR-chem/\n",
            "datasets/NER/BC5CDR-chem/devel.tsv\n",
            "datasets/NER/BC5CDR-chem/test.tsv\n",
            "datasets/NER/BC5CDR-chem/train_dev.tsv\n",
            "datasets/NER/BC5CDR-chem/train.tsv\n",
            "datasets/NER/JNLPBA/\n",
            "datasets/NER/JNLPBA/devel.tsv\n",
            "datasets/NER/JNLPBA/test.tsv\n",
            "datasets/NER/JNLPBA/train_dev.tsv\n",
            "datasets/NER/JNLPBA/train.tsv\n",
            "datasets/NER/BC4CHEMD/\n",
            "datasets/NER/BC4CHEMD/devel.tsv\n",
            "datasets/NER/BC4CHEMD/test.tsv\n",
            "datasets/NER/BC4CHEMD/train_dev.tsv\n",
            "datasets/NER/BC4CHEMD/train.tsv\n",
            "BioBERT dataset download done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPLNLI1SLIj1",
        "outputId": "37662559-8ad1-41a3-f24d-f0f7afbb2cf9"
      },
      "source": [
        "# Download biobert_v1.1_pubmed and save int into the Colab Content\n",
        "! export BIOBERT_DIR=./biobert_v1.1_pubmed\n",
        "! echo $BIOBERT_DIR\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKiPXyNRMbnK",
        "outputId": "e6c2db59-f93f-4028-9238-8831e72cb2e7"
      },
      "source": [
        "! ls -ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 313\n",
            " 4 drwx------ 2 root root  4096 Nov 21 17:42 biocodes\n",
            "15 -rw------- 1 root root 15237 Nov 21 17:42 create_pretraining_data.py\n",
            " 1 -rw------- 1 root root   903 Nov 21 17:42 download.sh\n",
            "14 -rw------- 1 root root 13898 Nov 21 17:42 extract_features.py\n",
            " 4 drwx------ 2 root root  4096 Nov 21 17:42 figs\n",
            " 1 -rw------- 1 root root   562 Nov 21 17:42 __init__.py\n",
            "12 -rw------- 1 root root 12060 Nov 21 17:42 LICENSE\n",
            "38 -rw------- 1 root root 38084 Nov 21 17:42 modeling.py\n",
            " 9 -rw------- 1 root root  9191 Nov 21 17:42 modeling_test.py\n",
            " 7 -rw------- 1 root root  6258 Nov 21 17:42 optimization.py\n",
            " 2 -rw------- 1 root root  1721 Nov 21 17:42 optimization_test.py\n",
            "13 -rw------- 1 root root 13150 Nov 21 17:42 README.md\n",
            " 1 -rw------- 1 root root   294 Nov 21 17:42 requirements.txt\n",
            "34 -rw------- 1 root root 34783 Nov 21 17:42 run_classifier.py\n",
            "27 -rw------- 1 root root 26953 Nov 21 17:42 run_ner.py\n",
            "19 -rw------- 1 root root 18667 Nov 21 17:42 run_pretraining.py\n",
            "46 -rw------- 1 root root 46789 Nov 21 17:42 run_qa.py\n",
            "39 -rw------- 1 root root 39145 Nov 21 17:42 run_re.py\n",
            " 5 -rw------- 1 root root  4394 Nov 21 17:42 sample_text.txt\n",
            " 9 -rw------- 1 root root  8402 Nov 21 17:42 tf_metrics.py\n",
            "12 -rw------- 1 root root 12257 Nov 21 17:42 tokenization.py\n",
            " 5 -rw------- 1 root root  4527 Nov 21 17:42 tokenization_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu5wVbn8Mqq3",
        "outputId": "b29e8878-2b8c-489e-c363-00df7d16be05"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BioASQ\t\t\t    modeling.py\t\t  run_pretraining.py\n",
            "biocodes\t\t    modeling_test.py\t  run_qa.py\n",
            "create_pretraining_data.py  optimization.py\t  run_re.py\n",
            "download.sh\t\t    optimization_test.py  sample_text.txt\n",
            "extract_features.py\t    README.md\t\t  tf_metrics.py\n",
            "figs\t\t\t    requirements.txt\t  tokenization.py\n",
            "__init__.py\t\t    run_classifier.py\t  tokenization_test.py\n",
            "LICENSE\t\t\t    run_ner.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPI7ku1BMsDa"
      },
      "source": [
        "! export QA_DIR=./BioASQ/\n",
        "! export OUTPUT_DIR=./qa_outputs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIAveURfOROs",
        "outputId": "05e677a1-162a-4538-c10e-1c326b699037"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/biobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crh-8eR6MxZ1",
        "outputId": "c79585ad-2c31-4dfa-fd11-2198661285a2"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/biobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGfqZ4h-M0vj"
      },
      "source": [
        "! export OUTPUT_DIR=./qa_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asRwK7FkM6XT",
        "outputId": "3300ed96-4ef9-4ec5-ea8a-718de3abc958"
      },
      "source": [
        "! mkdir -p $OUTPUT_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: missing operand\n",
            "Try 'mkdir --help' for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg6f5hYJM92S",
        "outputId": "0c1336e2-0106-4805-a106-9b458333c374"
      },
      "source": [
        "! python run_qa.py --do_train=True --do_predict=True --vocab_file=$BIOBERT_DIR/vocab.txt --bert_config_file=$BIOBERT_DIR/bert_config.json --init_checkpoint=$BIOBERT_DIR/model.ckpt-1000000 --max_seq_length=384 --train_batch_size=12 --learning_rate=5e-6 --doc_stride=128 --num_train_epochs=5.0 --do_lower_case=False --train_file=$QA_DIR/BioASQ-train-factoid-4b.json --predict_file=$QA_DIR/BioASQ-test-factoid-4b-1.json --output_dir=$OUTPUT_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/biobert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From run_qa.py:1290: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From run_qa.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1121 09:50:52.776824 140584916920192 module_wrapper.py:139] From run_qa.py:1134: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From run_qa.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1121 09:50:52.777034 140584916920192 module_wrapper.py:139] From run_qa.py:1134: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1121 09:50:52.777210 140584916920192 module_wrapper.py:139] From /content/biobert/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_qa.py\", line 1290, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"run_qa.py\", line 1136, in main\n",
            "    bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\n",
            "  File \"/content/biobert/modeling.py\", line 93, in from_json_file\n",
            "    text = reader.read()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\n",
            "    compat.as_bytes(self.__name), 1024 * 512)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /bert_config.json; No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSxdmEv9NJME"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC9ni1UU-Jp0"
      },
      "source": [
        "# Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icNdSd-e-JAa"
      },
      "source": [
        "def mean_reciprocal_rank(rs):\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qQ1VttH_AfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "a9469750-2acb-428a-d38e-2f8d110a5c3d"
      },
      "source": [
        "# rank, entail = QA[0][2:]\n",
        "reference_ranks = [np.array(q[2]) for q in QA2]\n",
        "system_ranks = [np.array(q[3]) for q in QA2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-809cb368f981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# rank, entail = QA[0][2:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreference_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQA2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msystem_ranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mQA2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_ranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'QA2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp5BylFXOX7a"
      },
      "source": [
        "predicted = []\n",
        "for a, b in zip(reference_ranks, system_ranks):\n",
        "    res = np.array(a)[np.argsort(b)]\n",
        "    predicted.append([int(i==min(res)) for i in res])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tWYVvwfB8c5",
        "outputId": "515f1318-ce13-46f8-e8b4-f9867b78ff60"
      },
      "source": [
        "mean_reciprocal_rank(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5924920634920635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHykldLG-6_l"
      },
      "source": [
        "def calc_hit_rank(prediction, reference):\n",
        "    for i, p in enumerate(prediction):\n",
        "        if reference[p-1] == 1:\n",
        "            return i+1\n",
        "    print(prediction)\n",
        "    print(reference)\n",
        "    raise ValueError('No reference!')\n",
        "\n",
        "def mean_reciprocal_rank(predictions, references):\n",
        "    assert len(predictions) == len(references)\n",
        "    ranks = []\n",
        "    for p, c in zip(predictions, references):\n",
        "        rank = calc_hit_rank(p, c)\n",
        "        ranks.append(1.0 / rank)\n",
        "    return sum(ranks) * 1.0 / len(ranks) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NukjYbbHP4kx",
        "outputId": "d78d92df-09de-4a99-cb7b-bcec0f8b1fe9"
      },
      "source": [
        "reference_ranks2 = [(np.array(arr) == 1).astype(np.int64) for arr in reference_ranks]\n",
        "system_ranks2 = [(np.array(arr) == 1).astype(np.int64) for arr in system_ranks]\n",
        "mean_reciprocal_rank(system_ranks, reference_ranks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5924920634920635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bCHtijXBvdt"
      },
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "def mean_spearmanr(predictions, references):\n",
        "    count = 0\n",
        "    for i in range(len(predictions)):\n",
        "        count += spearmanr(predictions[i], references[i])[0]\n",
        "\n",
        "    return count/len(system_ranks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "uF0dvFdJSapo",
        "outputId": "de89796e-d3b0-4dc7-d9d6-72b12813b499"
      },
      "source": [
        "i = 0\n",
        "indx2id = []\n",
        "QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
        "for filename in os.listdir('./'):\n",
        "    # i += 1\n",
        "    print(filename)\n",
        "    if not filename.endswith('.xml') or 'Labels' not in filename: continue\n",
        "    fullname = os.path.join('data/Test', filename)\n",
        "    tree = parse(filename)\n",
        "    questions = tree.getElementsByTagName('Question')\n",
        "    for question in questions:\n",
        "        qelem = question.getElementsByTagName('QuestionText')\n",
        "        q, qid = preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
        "        # print(q) # --> questions\n",
        "        answers = question.getElementsByTagName('Answer')\n",
        "        answers_list, rank, system, labels = get_answers(answers)\n",
        "        QA.append([q,answers_list, rank, labels])\n",
        "        QA2.append([q,answers_list, rank, system, labels])\n",
        "        indx2id.append(qid); i+=1;\n",
        "        # break\n",
        "len(QA2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7fa07ee02b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindx2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# QA2 has also system ranks from ChiQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# i += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEZNTT2NUHOr"
      },
      "source": [
        "reference_ranks = [np.array(q[2]) for q in QA2]\n",
        "system_ranks = [np.array(q[3]) for q in QA2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9nTkdt4W0n1",
        "outputId": "e4758a1d-d3cc-4839-dca0-8dbe37fa8352"
      },
      "source": [
        "mean_spearmanr(system_ranks, reference_ranks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3631053391053391"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrbbI8krXBVv"
      },
      "source": [
        "predicted = []\n",
        "for a, b in zip(reference_ranks, system_ranks):\n",
        "    res = np.array(a)[np.argsort(b)]\n",
        "    predicted.append([int(i==min(res)) for i in res])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFyZJXqaXGbv",
        "outputId": "89499d2c-295e-4b53-8ed6-ed27b8812553"
      },
      "source": [
        "def mean_reciprocal_rank(rs):\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "mean_reciprocal_rank(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6025846560846562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LHTsbizHboQ"
      },
      "source": [
        "from scipy.stats import spearmanr\n",
        "from sklearn.metrics import accuracy_score\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "class Question(object):\n",
        "    def __init__(self, q_id, q, a_ids, a, r, s, l):\n",
        "        self.question_id = q_id\n",
        "        self.question = q\n",
        "        self.answer_ids = a_ids\n",
        "        self.answers = a\n",
        "        self.reference_rank = r\n",
        "        self.system_rank = s\n",
        "        self.labels = l\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"{self.question}\\n  {self.answers}\\n  {self.reference_rank}\\n  {self.system_rank}\\n  {self.labels}\"\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return str(self)\n",
        "\n",
        "class QuestionsAndAnswers(list):\n",
        "    def __init__(self, dataset='Train'):\n",
        "        ''' dataset = {Train,Test,Validation} '''\n",
        "        list.__init__(self)\n",
        "        p = self.read_dataset(dataset)\n",
        "        self.extend(self.read_dataset(dataset))\n",
        "        self.references = [np.array(q.reference_rank) for q in self]\n",
        "        self.labels = [np.array(q.labels) for q in self]\n",
        "\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        s = unicodedata.normalize(\"NFKD\", text.lower())\n",
        "        return re.sub(r'\\[\\d\\]', '', s)\n",
        "\n",
        "    def get_answers(self, answers):\n",
        "        # return np.array((map(lambda ans: preprocess_text(ans.getElementsByTagName('AnswerText')[0].firstChild.nodeValue), answers)))\n",
        "        answs, answs_ids, rank, chiqa, y = [], [], [], [], []\n",
        "        for answer in answers:\n",
        "            ans = self.preprocess_text(answer.getElementsByTagName('AnswerText')[0].firstChild.nodeValue)\n",
        "            a_id = answer.getAttribute('AID')\n",
        "            reference = int(answer.getAttribute('ReferenceRank'))\n",
        "            system = int(answer.getAttribute('SystemRank'))\n",
        "            label = answer.getAttribute('ReferenceScore')\n",
        "            answs.append(ans); answs_ids.append(a_id); rank.append(reference); chiqa.append(system); y.append(int(label in ['3','4']))\n",
        "        return answs, answs_ids, rank, chiqa, y\n",
        "\n",
        "    def read_dataset(self, dataset='Train'):\n",
        "        i = 0\n",
        "        indx2id = []\n",
        "        QA, QA2 = [], []  # QA2 has also system ranks from ChiQA\n",
        "        if dataset == 'Test': dataset = 'TestSet-wLabels'\n",
        "        for filename in os.listdir('./'):\n",
        "            if not filename.endswith('.xml') or dataset not in filename: continue\n",
        "            tree = parse(filename)\n",
        "            questions = tree.getElementsByTagName('Question')\n",
        "            for question in questions:\n",
        "                qelem = question.getElementsByTagName('QuestionText')\n",
        "                q, q_id = self.preprocess_text(qelem[0].firstChild.nodeValue), question.getAttribute('QID')\n",
        "                # print(q) # --> questions\n",
        "                answers = question.getElementsByTagName('Answer')\n",
        "                answers_list, a_ids, rank, system, labels = self.get_answers(answers)\n",
        "                QA.append([q,answers_list, rank, labels])\n",
        "                question = Question(q_id=q_id, q=q, a_ids=a_ids, a=answers_list, r=rank, s=system, l=labels)\n",
        "                # QA2.append([q,answers_list, rank, system, labels])\n",
        "                QA2.append(question)\n",
        "                indx2id.append(q_id); i+=1;\n",
        "                # break\n",
        "        return QA2\n",
        "\n",
        "    def output_predictions(self, predictions, labels):\n",
        "        assert len(predictions) == len(self)\n",
        "        print('question_id,answer_id,label')\n",
        "        for i, p in enumerate(predictions):\n",
        "            q_id = QA[i].question_id\n",
        "            answers = QA[i].answer_ids\n",
        "            # order = np.array(a)[np.argsort(p)]\n",
        "            order = np.array(answers)[np.array(p)-1]\n",
        "            lab = labels[i]\n",
        "            for a_id, l in zip(order,lab):\n",
        "                print(f\"{q_id},{a_id},{int(l)}\")\n",
        "            \n",
        "    def normalize_sequence(self, seq):\n",
        "        seq = np.array(seq)\n",
        "        a = np.argsort(seq)\n",
        "        seq[a] = list(range(1,len(seq)+1))\n",
        "        return seq\n",
        "\n",
        "    def accuracy(self, predictions):\n",
        "        preds = np.concatenate(predictions)\n",
        "        true  = np.concatenate(self.labels) \n",
        "        assert len(preds) == len(true), f\"{len(preds)}, {len(true)}\"\n",
        "        return accuracy_score(true, preds)\n",
        "\n",
        "    def precision(self, predictions):\n",
        "        precisions = []\n",
        "        num_answers = []\n",
        "        for i in range(len(predictions)):\n",
        "            labels = self.labels[i]\n",
        "            p = self.normalize_sequence([x for j,x in enumerate(predictions[i]) if labels[j]==1])\n",
        "            r = self.normalize_sequence([x for j,x in enumerate(self.references[i]) if labels[j]==1])\n",
        "            if len(p) == 0:\n",
        "                print(predictions[i])\n",
        "            correct = sum([a == b for a,b in zip(p, r)])\n",
        "            # for a,b in zip(p, r)\n",
        "            # num_answers.append(len(p))\n",
        "            precisions.append(correct/len(p))\n",
        "        return np.mean(precisions)\n",
        "        # return np.average(np.array(precisions), weights=num_answers)\n",
        "\n",
        "    def mean_spearmanr(self, predictions):\n",
        "        assert len(predictions) == len(self.references)\n",
        "        count, total = 0, 0\n",
        "        preds, refs = [], []\n",
        "        for i in range(len(predictions)):\n",
        "            labels = self.labels[i]\n",
        "            assert len(predictions[i]) == len(labels), f\"{predictions}, {labels}\"\n",
        "            p = [x for j,x in enumerate(predictions[i]) if labels[j]==1]\n",
        "            r = [x for j,x in enumerate(self.references[i]) if labels[j]==1]\n",
        "            preds += p; refs += r\n",
        "            if len(r) == 1:\n",
        "                total += 1\n",
        "                count += 1\n",
        "            elif len(r) == 0:\n",
        "                continue\n",
        "            else:\n",
        "                total += 1\n",
        "                count += spearmanr(p, r)[0]\n",
        "        return spearmanr(preds, refs)[0]\n",
        "        # return count/total\n",
        "\n",
        "    def mean_reciprocal_rank(self, predicted):\n",
        "        rs = []\n",
        "        for k, (a, b) in enumerate(zip(predicted, self.references)):\n",
        "            res = np.array(a)[np.argsort(b)]\n",
        "            labels = QA[k].labels\n",
        "            res = [r if labels[i]==1 else 100 for i,r in enumerate(res)]\n",
        "            rs.append([int(i==min(res)) for i in res])  # sets 1 in first ranked answer\n",
        "        rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "        return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqqvI5WoQA-5",
        "outputId": "dd4a2536-1e05-48ce-eb94-3097f3ca1f06"
      },
      "source": [
        "def normalize_sequence(seq):\n",
        "    seq = np.array(seq)\n",
        "    a = np.argsort(seq)\n",
        "    seq[a] = list(range(1,len(seq)+1))\n",
        "    return seq\n",
        "normalize_sequence([55, 55,2,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz4_hw-UJ4N8"
      },
      "source": [
        "QA = QuestionsAndAnswers(dataset = 'Test') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lfed9fHGLRlk",
        "outputId": "d2186749-f21a-4685-da5f-64172e40aad6"
      },
      "source": [
        "QA[0].question_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JIitEluGgwa"
      },
      "source": [
        "system_ranks = [q.system_rank for q in QA]\n",
        "reference_ranks = [q.reference_rank for q in QA]\n",
        "labels = [q.labels for q in QA]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIePqfZfdUj8",
        "outputId": "74b4c294-5a70-448c-8f28-314057b98eba"
      },
      "source": [
        "spearmanr(np.concatenate(system_ranks), np.concatenate(reference_ranks))\n",
        "spearmanr([7, 9, 1], [2, 3, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpearmanrResult(correlation=1.0, pvalue=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZsOJp1deKg",
        "outputId": "904672f6-90e1-4507-b568-963e5451dfd2"
      },
      "source": [
        "QA.mean_reciprocal_rank(system_ranks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6258891293891294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yw7uWfRdx3Y",
        "outputId": "98e00d94-95d5-4ef0-c260-0a004ebfd510"
      },
      "source": [
        "QA.mean_spearmanr(system_ranks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4492904692300491"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HCLPkI3ONfg",
        "outputId": "ca4b0f90-8e3c-403e-aeff-e6177f401ce6"
      },
      "source": [
        "system_labels = [np.ones(len(l)) for l in labels]\n",
        "QA.accuracy(system_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5167118337850045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFo7-rcbRUzB",
        "outputId": "10be0f54-9220-46e4-a30e-9d050d5d6e18"
      },
      "source": [
        "QA.precision(system_ranks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4866481481481482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k51sU7zuS0nO",
        "outputId": "d7e003c8-c32d-472a-8154-ac5e1e39fb76"
      },
      "source": [
        "QA.output_predictions(reference_ranks, system_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question_id,answer_id,label\n",
            "1,1_Answer6,1\n",
            "1,1_Answer8,1\n",
            "1,1_Answer7,1\n",
            "1,1_Answer2,1\n",
            "1,1_Answer4,1\n",
            "1,1_Answer3,1\n",
            "1,1_Answer1,1\n",
            "2,2_Answer1,1\n",
            "2,2_Answer2,1\n",
            "2,2_Answer4,1\n",
            "2,2_Answer3,1\n",
            "3,3_Answer5,1\n",
            "3,3_Answer2,1\n",
            "3,3_Answer3,1\n",
            "3,3_Answer6,1\n",
            "3,3_Answer4,1\n",
            "3,3_Answer7,1\n",
            "3,3_Answer8,1\n",
            "3,3_Answer10,1\n",
            "3,3_Answer11,1\n",
            "3,3_Answer9,1\n",
            "5,5_Answer6,1\n",
            "5,5_Answer4,1\n",
            "5,5_Answer5,1\n",
            "5,5_Answer7,1\n",
            "5,5_Answer1,1\n",
            "5,5_Answer2,1\n",
            "5,5_Answer9,1\n",
            "6,6_Answer8,1\n",
            "6,6_Answer9,1\n",
            "6,6_Answer2,1\n",
            "6,6_Answer5,1\n",
            "6,6_Answer6,1\n",
            "6,6_Answer4,1\n",
            "6,6_Answer3,1\n",
            "6,6_Answer7,1\n",
            "6,6_Answer1,1\n",
            "7,7_Answer2,1\n",
            "7,7_Answer1,1\n",
            "7,7_Answer4,1\n",
            "7,7_Answer3,1\n",
            "7,7_Answer6,1\n",
            "7,7_Answer5,1\n",
            "7,7_Answer7,1\n",
            "8,8_Answer1,1\n",
            "8,8_Answer2,1\n",
            "8,8_Answer3,1\n",
            "10,10_Answer2,1\n",
            "10,10_Answer8,1\n",
            "10,10_Answer1,1\n",
            "10,10_Answer7,1\n",
            "10,10_Answer6,1\n",
            "10,10_Answer4,1\n",
            "10,10_Answer5,1\n",
            "10,10_Answer3,1\n",
            "12,12_Answer5,1\n",
            "12,12_Answer1,1\n",
            "12,12_Answer2,1\n",
            "12,12_Answer3,1\n",
            "12,12_Answer4,1\n",
            "13,13_Answer1,1\n",
            "13,13_Answer2,1\n",
            "13,13_Answer4,1\n",
            "13,13_Answer3,1\n",
            "14,14_Answer2,1\n",
            "14,14_Answer1,1\n",
            "15,15_Answer3,1\n",
            "15,15_Answer9,1\n",
            "15,15_Answer4,1\n",
            "15,15_Answer1,1\n",
            "15,15_Answer6,1\n",
            "15,15_Answer7,1\n",
            "15,15_Answer5,1\n",
            "15,15_Answer8,1\n",
            "15,15_Answer2,1\n",
            "16,16_Answer1,1\n",
            "16,16_Answer5,1\n",
            "16,16_Answer3,1\n",
            "16,16_Answer4,1\n",
            "16,16_Answer2,1\n",
            "17,17_Answer3,1\n",
            "17,17_Answer4,1\n",
            "17,17_Answer1,1\n",
            "17,17_Answer5,1\n",
            "18,18_Answer1,1\n",
            "18,18_Answer5,1\n",
            "18,18_Answer2,1\n",
            "18,18_Answer3,1\n",
            "18,18_Answer4,1\n",
            "19,19_Answer7,1\n",
            "19,19_Answer6,1\n",
            "19,19_Answer3,1\n",
            "19,19_Answer1,1\n",
            "19,19_Answer2,1\n",
            "19,19_Answer4,1\n",
            "21,21_Answer2,1\n",
            "21,21_Answer3,1\n",
            "21,21_Answer9,1\n",
            "21,21_Answer4,1\n",
            "21,21_Answer5,1\n",
            "21,21_Answer6,1\n",
            "21,21_Answer8,1\n",
            "21,21_Answer1,1\n",
            "21,21_Answer7,1\n",
            "22,22_Answer1,1\n",
            "22,22_Answer4,1\n",
            "22,22_Answer2,1\n",
            "22,22_Answer3,1\n",
            "23,23_Answer1,1\n",
            "23,23_Answer4,1\n",
            "23,23_Answer2,1\n",
            "23,23_Answer5,1\n",
            "24,24_Answer1,1\n",
            "24,24_Answer3,1\n",
            "24,24_Answer2,1\n",
            "25,25_Answer1,1\n",
            "25,25_Answer3,1\n",
            "25,25_Answer2,1\n",
            "25,25_Answer4,1\n",
            "25,25_Answer5,1\n",
            "25,25_Answer6,1\n",
            "27,27_Answer1,1\n",
            "27,27_Answer3,1\n",
            "27,27_Answer5,1\n",
            "27,27_Answer2,1\n",
            "27,27_Answer4,1\n",
            "28,28_Answer2,1\n",
            "28,28_Answer1,1\n",
            "28,28_Answer5,1\n",
            "28,28_Answer3,1\n",
            "28,28_Answer4,1\n",
            "29,29_Answer1,1\n",
            "29,29_Answer7,1\n",
            "29,29_Answer2,1\n",
            "29,29_Answer5,1\n",
            "29,29_Answer6,1\n",
            "29,29_Answer3,1\n",
            "29,29_Answer4,1\n",
            "30,30_Answer2,1\n",
            "30,30_Answer8,1\n",
            "30,30_Answer1,1\n",
            "30,30_Answer9,1\n",
            "30,30_Answer6,1\n",
            "30,30_Answer3,1\n",
            "30,30_Answer4,1\n",
            "30,30_Answer5,1\n",
            "30,30_Answer7,1\n",
            "31,31_Answer1,1\n",
            "31,31_Answer2,1\n",
            "31,31_Answer4,1\n",
            "31,31_Answer3,1\n",
            "31,31_Answer6,1\n",
            "32,32_Answer2,1\n",
            "32,32_Answer6,1\n",
            "32,32_Answer1,1\n",
            "32,32_Answer5,1\n",
            "32,32_Answer4,1\n",
            "32,32_Answer7,1\n",
            "32,32_Answer8,1\n",
            "32,32_Answer3,1\n",
            "33,33_Answer2,1\n",
            "33,33_Answer10,1\n",
            "33,33_Answer5,1\n",
            "33,33_Answer6,1\n",
            "33,33_Answer1,1\n",
            "33,33_Answer7,1\n",
            "33,33_Answer8,1\n",
            "33,33_Answer9,1\n",
            "33,33_Answer3,1\n",
            "36,36_Answer3,1\n",
            "36,36_Answer2,1\n",
            "36,36_Answer1,1\n",
            "36,36_Answer10,1\n",
            "36,36_Answer4,1\n",
            "36,36_Answer11,1\n",
            "36,36_Answer7,1\n",
            "36,36_Answer9,1\n",
            "36,36_Answer5,1\n",
            "36,36_Answer6,1\n",
            "38,38_Answer7,1\n",
            "38,38_Answer10,1\n",
            "38,38_Answer8,1\n",
            "38,38_Answer1,1\n",
            "38,38_Answer6,1\n",
            "38,38_Answer2,1\n",
            "38,38_Answer9,1\n",
            "38,38_Answer4,1\n",
            "38,38_Answer3,1\n",
            "38,38_Answer5,1\n",
            "39,39_Answer1,1\n",
            "39,39_Answer3,1\n",
            "39,39_Answer2,1\n",
            "39,39_Answer4,1\n",
            "39,39_Answer5,1\n",
            "39,39_Answer6,1\n",
            "40,40_Answer1,1\n",
            "40,40_Answer2,1\n",
            "40,40_Answer6,1\n",
            "40,40_Answer9,1\n",
            "40,40_Answer7,1\n",
            "40,40_Answer3,1\n",
            "40,40_Answer8,1\n",
            "40,40_Answer4,1\n",
            "40,40_Answer5,1\n",
            "41,41_Answer3,1\n",
            "41,41_Answer9,1\n",
            "41,41_Answer1,1\n",
            "41,41_Answer10,1\n",
            "41,41_Answer2,1\n",
            "41,41_Answer5,1\n",
            "41,41_Answer6,1\n",
            "41,41_Answer7,1\n",
            "41,41_Answer4,1\n",
            "41,41_Answer8,1\n",
            "42,42_Answer3,1\n",
            "42,42_Answer5,1\n",
            "42,42_Answer1,1\n",
            "42,42_Answer2,1\n",
            "42,42_Answer4,1\n",
            "43,43_Answer2,1\n",
            "43,43_Answer5,1\n",
            "43,43_Answer11,1\n",
            "43,43_Answer4,1\n",
            "43,43_Answer3,1\n",
            "43,43_Answer6,1\n",
            "43,43_Answer1,1\n",
            "43,43_Answer7,1\n",
            "43,43_Answer10,1\n",
            "43,43_Answer8,1\n",
            "43,43_Answer9,1\n",
            "45,45_Answer2,1\n",
            "45,45_Answer1,1\n",
            "45,45_Answer3,1\n",
            "45,45_Answer4,1\n",
            "45,45_Answer5,1\n",
            "45,45_Answer6,1\n",
            "45,45_Answer7,1\n",
            "46,46_Answer1,1\n",
            "46,46_Answer8,1\n",
            "46,46_Answer4,1\n",
            "46,46_Answer9,1\n",
            "46,46_Answer5,1\n",
            "46,46_Answer6,1\n",
            "46,46_Answer2,1\n",
            "46,46_Answer3,1\n",
            "46,46_Answer10,1\n",
            "46,46_Answer7,1\n",
            "47,47_Answer3,1\n",
            "47,47_Answer5,1\n",
            "47,47_Answer2,1\n",
            "47,47_Answer1,1\n",
            "47,47_Answer4,1\n",
            "47,47_Answer6,1\n",
            "47,47_Answer8,1\n",
            "47,47_Answer7,1\n",
            "49,49_Answer1,1\n",
            "49,49_Answer5,1\n",
            "49,49_Answer2,1\n",
            "49,49_Answer3,1\n",
            "49,49_Answer4,1\n",
            "49,49_Answer6,1\n",
            "54,54_Answer2,1\n",
            "54,54_Answer8,1\n",
            "54,54_Answer5,1\n",
            "54,54_Answer6,1\n",
            "54,54_Answer3,1\n",
            "54,54_Answer4,1\n",
            "54,54_Answer7,1\n",
            "54,54_Answer1,1\n",
            "54,54_Answer9,1\n",
            "54,54_Answer10,1\n",
            "55,55_Answer6,1\n",
            "55,55_Answer3,1\n",
            "55,55_Answer1,1\n",
            "55,55_Answer2,1\n",
            "55,55_Answer4,1\n",
            "56,56_Answer1,1\n",
            "56,56_Answer3,1\n",
            "56,56_Answer5,1\n",
            "56,56_Answer4,1\n",
            "57,57_Answer2,1\n",
            "57,57_Answer3,1\n",
            "57,57_Answer1,1\n",
            "58,58_Answer2,1\n",
            "58,58_Answer1,1\n",
            "58,58_Answer5,1\n",
            "58,58_Answer4,1\n",
            "58,58_Answer6,1\n",
            "58,58_Answer7,1\n",
            "58,58_Answer3,1\n",
            "59,59_Answer2,1\n",
            "59,59_Answer5,1\n",
            "59,59_Answer1,1\n",
            "59,59_Answer6,1\n",
            "59,59_Answer4,1\n",
            "59,59_Answer7,1\n",
            "59,59_Answer3,1\n",
            "60,60_Answer1,1\n",
            "60,60_Answer8,1\n",
            "60,60_Answer3,1\n",
            "60,60_Answer5,1\n",
            "60,60_Answer6,1\n",
            "60,60_Answer4,1\n",
            "60,60_Answer2,1\n",
            "61,61_Answer1,1\n",
            "61,61_Answer5,1\n",
            "61,61_Answer4,1\n",
            "61,61_Answer3,1\n",
            "61,61_Answer2,1\n",
            "62,62_Answer2,1\n",
            "62,62_Answer1,1\n",
            "62,62_Answer3,1\n",
            "62,62_Answer4,1\n",
            "62,62_Answer5,1\n",
            "62,62_Answer6,1\n",
            "62,62_Answer7,1\n",
            "64,64_Answer1,1\n",
            "64,64_Answer2,1\n",
            "64,64_Answer4,1\n",
            "64,64_Answer3,1\n",
            "66,66_Answer1,1\n",
            "66,66_Answer2,1\n",
            "66,66_Answer4,1\n",
            "66,66_Answer5,1\n",
            "66,66_Answer6,1\n",
            "66,66_Answer7,1\n",
            "66,66_Answer8,1\n",
            "66,66_Answer3,1\n",
            "66,66_Answer9,1\n",
            "67,67_Answer1,1\n",
            "67,67_Answer5,1\n",
            "67,67_Answer6,1\n",
            "67,67_Answer2,1\n",
            "67,67_Answer3,1\n",
            "67,67_Answer7,1\n",
            "67,67_Answer4,1\n",
            "68,68_Answer3,1\n",
            "68,68_Answer7,1\n",
            "68,68_Answer1,1\n",
            "68,68_Answer6,1\n",
            "68,68_Answer8,1\n",
            "68,68_Answer5,1\n",
            "68,68_Answer2,1\n",
            "68,68_Answer4,1\n",
            "70,70_Answer1,1\n",
            "70,70_Answer2,1\n",
            "70,70_Answer5,1\n",
            "70,70_Answer6,1\n",
            "70,70_Answer7,1\n",
            "70,70_Answer4,1\n",
            "71,71_Answer1,1\n",
            "71,71_Answer2,1\n",
            "71,71_Answer5,1\n",
            "71,71_Answer4,1\n",
            "71,71_Answer3,1\n",
            "72,72_Answer1,1\n",
            "72,72_Answer3,1\n",
            "72,72_Answer2,1\n",
            "72,72_Answer6,1\n",
            "72,72_Answer4,1\n",
            "72,72_Answer8,1\n",
            "72,72_Answer5,1\n",
            "72,72_Answer7,1\n",
            "72,72_Answer9,1\n",
            "73,73_Answer1,1\n",
            "73,73_Answer4,1\n",
            "73,73_Answer2,1\n",
            "73,73_Answer3,1\n",
            "74,74_Answer11,1\n",
            "74,74_Answer10,1\n",
            "74,74_Answer2,1\n",
            "74,74_Answer9,1\n",
            "74,74_Answer5,1\n",
            "74,74_Answer1,1\n",
            "74,74_Answer8,1\n",
            "74,74_Answer3,1\n",
            "74,74_Answer6,1\n",
            "74,74_Answer4,1\n",
            "74,74_Answer7,1\n",
            "75,75_Answer2,1\n",
            "75,75_Answer1,1\n",
            "75,75_Answer4,1\n",
            "75,75_Answer3,1\n",
            "75,75_Answer7,1\n",
            "75,75_Answer6,1\n",
            "75,75_Answer5,1\n",
            "76,76_Answer2,1\n",
            "76,76_Answer4,1\n",
            "76,76_Answer3,1\n",
            "76,76_Answer5,1\n",
            "76,76_Answer1,1\n",
            "76,76_Answer6,1\n",
            "76,76_Answer10,1\n",
            "76,76_Answer8,1\n",
            "76,76_Answer9,1\n",
            "76,76_Answer7,1\n",
            "76,76_Answer11,1\n",
            "78,78_Answer8,1\n",
            "78,78_Answer9,1\n",
            "78,78_Answer4,1\n",
            "78,78_Answer7,1\n",
            "78,78_Answer3,1\n",
            "78,78_Answer5,1\n",
            "78,78_Answer6,1\n",
            "78,78_Answer2,1\n",
            "78,78_Answer1,1\n",
            "79,79_Answer4,1\n",
            "79,79_Answer3,1\n",
            "79,79_Answer2,1\n",
            "79,79_Answer6,1\n",
            "79,79_Answer1,1\n",
            "79,79_Answer5,1\n",
            "79,79_Answer7,1\n",
            "81,81_Answer1,1\n",
            "81,81_Answer3,1\n",
            "81,81_Answer2,1\n",
            "81,81_Answer4,1\n",
            "81,81_Answer5,1\n",
            "81,81_Answer7,1\n",
            "81,81_Answer6,1\n",
            "82,82_Answer1,1\n",
            "82,82_Answer4,1\n",
            "82,82_Answer3,1\n",
            "82,82_Answer2,1\n",
            "84,84_Answer1,1\n",
            "84,84_Answer3,1\n",
            "84,84_Answer2,1\n",
            "84,84_Answer4,1\n",
            "84,84_Answer9,1\n",
            "84,84_Answer5,1\n",
            "84,84_Answer6,1\n",
            "84,84_Answer8,1\n",
            "85,85_Answer1,1\n",
            "85,85_Answer2,1\n",
            "85,85_Answer3,1\n",
            "85,85_Answer6,1\n",
            "85,85_Answer4,1\n",
            "85,85_Answer7,1\n",
            "85,85_Answer8,1\n",
            "85,85_Answer5,1\n",
            "86,86_Answer9,1\n",
            "86,86_Answer1,1\n",
            "86,86_Answer4,1\n",
            "86,86_Answer3,1\n",
            "86,86_Answer7,1\n",
            "86,86_Answer6,1\n",
            "86,86_Answer2,1\n",
            "86,86_Answer5,1\n",
            "86,86_Answer8,1\n",
            "90,90_Answer1,1\n",
            "90,90_Answer2,1\n",
            "91,91_Answer2,1\n",
            "91,91_Answer1,1\n",
            "92,92_Answer2,1\n",
            "92,92_Answer1,1\n",
            "92,92_Answer3,1\n",
            "92,92_Answer6,1\n",
            "92,92_Answer4,1\n",
            "92,92_Answer8,1\n",
            "92,92_Answer7,1\n",
            "92,92_Answer5,1\n",
            "92,92_Answer9,1\n",
            "93,93_Answer1,1\n",
            "93,93_Answer4,1\n",
            "93,93_Answer3,1\n",
            "93,93_Answer8,1\n",
            "93,93_Answer5,1\n",
            "93,93_Answer7,1\n",
            "93,93_Answer6,1\n",
            "93,93_Answer9,1\n",
            "93,93_Answer10,1\n",
            "93,93_Answer11,1\n",
            "95,95_Answer5,1\n",
            "95,95_Answer4,1\n",
            "95,95_Answer3,1\n",
            "95,95_Answer9,1\n",
            "95,95_Answer2,1\n",
            "95,95_Answer8,1\n",
            "95,95_Answer7,1\n",
            "95,95_Answer6,1\n",
            "95,95_Answer1,1\n",
            "97,97_Answer1,1\n",
            "97,97_Answer8,1\n",
            "97,97_Answer3,1\n",
            "97,97_Answer7,1\n",
            "97,97_Answer4,1\n",
            "97,97_Answer5,1\n",
            "97,97_Answer2,1\n",
            "97,97_Answer6,1\n",
            "98,98_Answer1,1\n",
            "98,98_Answer4,1\n",
            "98,98_Answer2,1\n",
            "98,98_Answer3,1\n",
            "99,99_Answer1,1\n",
            "99,99_Answer2,1\n",
            "99,99_Answer3,1\n",
            "99,99_Answer6,1\n",
            "99,99_Answer5,1\n",
            "101,101_Answer5,1\n",
            "101,101_Answer6,1\n",
            "101,101_Answer2,1\n",
            "101,101_Answer1,1\n",
            "101,101_Answer3,1\n",
            "101,101_Answer4,1\n",
            "101,101_Answer7,1\n",
            "101,101_Answer8,1\n",
            "103,103_Answer1,1\n",
            "103,103_Answer2,1\n",
            "103,103_Answer6,1\n",
            "103,103_Answer3,1\n",
            "103,103_Answer4,1\n",
            "103,103_Answer5,1\n",
            "105,105_Answer1,1\n",
            "105,105_Answer6,1\n",
            "105,105_Answer7,1\n",
            "105,105_Answer2,1\n",
            "105,105_Answer4,1\n",
            "105,105_Answer3,1\n",
            "105,105_Answer5,1\n",
            "105,105_Answer8,1\n",
            "106,106_Answer2,1\n",
            "106,106_Answer1,1\n",
            "106,106_Answer7,1\n",
            "106,106_Answer4,1\n",
            "106,106_Answer8,1\n",
            "106,106_Answer6,1\n",
            "106,106_Answer3,1\n",
            "106,106_Answer5,1\n",
            "107,107_Answer8,1\n",
            "107,107_Answer4,1\n",
            "107,107_Answer6,1\n",
            "107,107_Answer1,1\n",
            "107,107_Answer2,1\n",
            "107,107_Answer3,1\n",
            "107,107_Answer7,1\n",
            "108,108_Answer4,1\n",
            "108,108_Answer5,1\n",
            "108,108_Answer2,1\n",
            "108,108_Answer1,1\n",
            "108,108_Answer6,1\n",
            "108,108_Answer3,1\n",
            "108,108_Answer8,1\n",
            "108,108_Answer7,1\n",
            "108,108_Answer9,1\n",
            "109,109_Answer2,1\n",
            "109,109_Answer1,1\n",
            "109,109_Answer6,1\n",
            "109,109_Answer7,1\n",
            "109,109_Answer8,1\n",
            "109,109_Answer9,1\n",
            "109,109_Answer4,1\n",
            "109,109_Answer3,1\n",
            "109,109_Answer5,1\n",
            "110,110_Answer5,1\n",
            "110,110_Answer4,1\n",
            "110,110_Answer2,1\n",
            "110,110_Answer1,1\n",
            "110,110_Answer3,1\n",
            "110,110_Answer6,1\n",
            "111,111_Answer5,1\n",
            "111,111_Answer1,1\n",
            "111,111_Answer3,1\n",
            "111,111_Answer4,1\n",
            "111,111_Answer7,1\n",
            "111,111_Answer6,1\n",
            "111,111_Answer2,1\n",
            "112,112_Answer1,1\n",
            "112,112_Answer8,1\n",
            "112,112_Answer2,1\n",
            "112,112_Answer4,1\n",
            "112,112_Answer3,1\n",
            "112,112_Answer5,1\n",
            "112,112_Answer6,1\n",
            "112,112_Answer7,1\n",
            "112,112_Answer9,1\n",
            "113,113_Answer3,1\n",
            "113,113_Answer7,1\n",
            "113,113_Answer4,1\n",
            "113,113_Answer6,1\n",
            "113,113_Answer2,1\n",
            "113,113_Answer8,1\n",
            "113,113_Answer9,1\n",
            "113,113_Answer1,1\n",
            "113,113_Answer5,1\n",
            "115,115_Answer1,1\n",
            "115,115_Answer4,1\n",
            "115,115_Answer3,1\n",
            "115,115_Answer9,1\n",
            "115,115_Answer7,1\n",
            "115,115_Answer10,1\n",
            "115,115_Answer2,1\n",
            "115,115_Answer6,1\n",
            "115,115_Answer8,1\n",
            "116,116_Answer2,1\n",
            "116,116_Answer4,1\n",
            "116,116_Answer8,1\n",
            "116,116_Answer7,1\n",
            "116,116_Answer6,1\n",
            "116,116_Answer3,1\n",
            "116,116_Answer5,1\n",
            "116,116_Answer1,1\n",
            "117,117_Answer1,1\n",
            "117,117_Answer2,1\n",
            "117,117_Answer3,1\n",
            "117,117_Answer5,1\n",
            "117,117_Answer6,1\n",
            "117,117_Answer4,1\n",
            "118,118_Answer2,1\n",
            "118,118_Answer1,1\n",
            "118,118_Answer5,1\n",
            "118,118_Answer4,1\n",
            "118,118_Answer6,1\n",
            "118,118_Answer3,1\n",
            "118,118_Answer7,1\n",
            "119,119_Answer1,1\n",
            "119,119_Answer8,1\n",
            "119,119_Answer9,1\n",
            "119,119_Answer7,1\n",
            "119,119_Answer2,1\n",
            "119,119_Answer3,1\n",
            "119,119_Answer4,1\n",
            "119,119_Answer5,1\n",
            "119,119_Answer6,1\n",
            "121,121_Answer1,1\n",
            "121,121_Answer9,1\n",
            "121,121_Answer3,1\n",
            "121,121_Answer10,1\n",
            "121,121_Answer2,1\n",
            "121,121_Answer11,1\n",
            "121,121_Answer4,1\n",
            "121,121_Answer5,1\n",
            "121,121_Answer8,1\n",
            "121,121_Answer6,1\n",
            "122,122_Answer1,1\n",
            "122,122_Answer4,1\n",
            "122,122_Answer3,1\n",
            "122,122_Answer7,1\n",
            "122,122_Answer6,1\n",
            "122,122_Answer5,1\n",
            "122,122_Answer2,1\n",
            "123,123_Answer5,1\n",
            "123,123_Answer6,1\n",
            "123,123_Answer7,1\n",
            "123,123_Answer2,1\n",
            "123,123_Answer1,1\n",
            "123,123_Answer4,1\n",
            "123,123_Answer3,1\n",
            "123,123_Answer8,1\n",
            "123,123_Answer9,1\n",
            "124,124_Answer3,1\n",
            "124,124_Answer5,1\n",
            "124,124_Answer2,1\n",
            "124,124_Answer4,1\n",
            "124,124_Answer1,1\n",
            "127,127_Answer7,1\n",
            "127,127_Answer4,1\n",
            "127,127_Answer8,1\n",
            "127,127_Answer3,1\n",
            "127,127_Answer2,1\n",
            "127,127_Answer5,1\n",
            "127,127_Answer1,1\n",
            "127,127_Answer9,1\n",
            "127,127_Answer6,1\n",
            "129,129_Answer1,1\n",
            "129,129_Answer9,1\n",
            "129,129_Answer3,1\n",
            "129,129_Answer10,1\n",
            "129,129_Answer2,1\n",
            "129,129_Answer11,1\n",
            "129,129_Answer4,1\n",
            "129,129_Answer5,1\n",
            "129,129_Answer6,1\n",
            "129,129_Answer8,1\n",
            "130,130_Answer4,1\n",
            "130,130_Answer6,1\n",
            "130,130_Answer7,1\n",
            "130,130_Answer2,1\n",
            "130,130_Answer3,1\n",
            "130,130_Answer1,1\n",
            "130,130_Answer8,1\n",
            "130,130_Answer9,1\n",
            "130,130_Answer5,1\n",
            "130,130_Answer10,1\n",
            "131,131_Answer2,1\n",
            "131,131_Answer4,1\n",
            "131,131_Answer5,1\n",
            "131,131_Answer7,1\n",
            "131,131_Answer1,1\n",
            "131,131_Answer8,1\n",
            "131,131_Answer3,1\n",
            "131,131_Answer6,1\n",
            "131,131_Answer9,1\n",
            "132,132_Answer2,1\n",
            "132,132_Answer1,1\n",
            "132,132_Answer9,1\n",
            "132,132_Answer7,1\n",
            "132,132_Answer4,1\n",
            "132,132_Answer8,1\n",
            "132,132_Answer3,1\n",
            "132,132_Answer5,1\n",
            "132,132_Answer6,1\n",
            "133,133_Answer4,1\n",
            "133,133_Answer1,1\n",
            "133,133_Answer2,1\n",
            "133,133_Answer6,1\n",
            "133,133_Answer5,1\n",
            "133,133_Answer7,1\n",
            "133,133_Answer10,1\n",
            "133,133_Answer8,1\n",
            "133,133_Answer3,1\n",
            "133,133_Answer9,1\n",
            "134,134_Answer1,1\n",
            "134,134_Answer3,1\n",
            "134,134_Answer7,1\n",
            "134,134_Answer6,1\n",
            "134,134_Answer4,1\n",
            "134,134_Answer2,1\n",
            "134,134_Answer5,1\n",
            "135,135_Answer2,1\n",
            "135,135_Answer9,1\n",
            "135,135_Answer6,1\n",
            "135,135_Answer8,1\n",
            "135,135_Answer5,1\n",
            "135,135_Answer7,1\n",
            "135,135_Answer3,1\n",
            "135,135_Answer4,1\n",
            "135,135_Answer1,1\n",
            "137,137_Answer7,1\n",
            "137,137_Answer6,1\n",
            "137,137_Answer2,1\n",
            "137,137_Answer3,1\n",
            "137,137_Answer1,1\n",
            "137,137_Answer5,1\n",
            "137,137_Answer4,1\n",
            "138,138_Answer2,1\n",
            "138,138_Answer3,1\n",
            "138,138_Answer1,1\n",
            "138,138_Answer6,1\n",
            "138,138_Answer5,1\n",
            "138,138_Answer4,1\n",
            "138,138_Answer7,1\n",
            "139,139_Answer1,1\n",
            "139,139_Answer4,1\n",
            "139,139_Answer2,1\n",
            "139,139_Answer3,1\n",
            "140,140_Answer1,1\n",
            "140,140_Answer6,1\n",
            "140,140_Answer5,1\n",
            "140,140_Answer9,1\n",
            "140,140_Answer10,1\n",
            "140,140_Answer2,1\n",
            "140,140_Answer4,1\n",
            "140,140_Answer3,1\n",
            "140,140_Answer8,1\n",
            "140,140_Answer7,1\n",
            "142,142_Answer3,1\n",
            "142,142_Answer4,1\n",
            "142,142_Answer2,1\n",
            "142,142_Answer1,1\n",
            "143,143_Answer1,1\n",
            "143,143_Answer2,1\n",
            "143,143_Answer4,1\n",
            "143,143_Answer3,1\n",
            "143,143_Answer7,1\n",
            "143,143_Answer6,1\n",
            "143,143_Answer9,1\n",
            "143,143_Answer8,1\n",
            "143,143_Answer5,1\n",
            "144,144_Answer3,1\n",
            "144,144_Answer2,1\n",
            "144,144_Answer5,1\n",
            "144,144_Answer6,1\n",
            "144,144_Answer1,1\n",
            "144,144_Answer4,1\n",
            "144,144_Answer7,1\n",
            "144,144_Answer8,1\n",
            "144,144_Answer9,1\n",
            "144,144_Answer10,1\n",
            "145,145_Answer2,1\n",
            "145,145_Answer3,1\n",
            "145,145_Answer4,1\n",
            "145,145_Answer9,1\n",
            "145,145_Answer10,1\n",
            "145,145_Answer11,1\n",
            "145,145_Answer1,1\n",
            "145,145_Answer8,1\n",
            "145,145_Answer5,1\n",
            "145,145_Answer6,1\n",
            "145,145_Answer7,1\n",
            "147,147_Answer1,1\n",
            "147,147_Answer3,1\n",
            "147,147_Answer4,1\n",
            "147,147_Answer2,1\n",
            "147,147_Answer5,1\n",
            "148,148_Answer1,1\n",
            "148,148_Answer4,1\n",
            "148,148_Answer2,1\n",
            "148,148_Answer7,1\n",
            "148,148_Answer5,1\n",
            "148,148_Answer8,1\n",
            "148,148_Answer9,1\n",
            "148,148_Answer3,1\n",
            "148,148_Answer6,1\n",
            "150,150_Answer2,1\n",
            "150,150_Answer1,1\n",
            "150,150_Answer6,1\n",
            "150,150_Answer3,1\n",
            "150,150_Answer5,1\n",
            "150,150_Answer4,1\n",
            "150,150_Answer7,1\n",
            "152,152_Answer1,1\n",
            "152,152_Answer5,1\n",
            "152,152_Answer3,1\n",
            "152,152_Answer4,1\n",
            "152,152_Answer2,1\n",
            "152,152_Answer6,1\n",
            "152,152_Answer7,1\n",
            "153,153_Answer3,1\n",
            "153,153_Answer4,1\n",
            "153,153_Answer2,1\n",
            "153,153_Answer6,1\n",
            "153,153_Answer1,1\n",
            "153,153_Answer8,1\n",
            "153,153_Answer10,1\n",
            "153,153_Answer5,1\n",
            "153,153_Answer7,1\n",
            "153,153_Answer9,1\n",
            "154,154_Answer2,1\n",
            "154,154_Answer8,1\n",
            "154,154_Answer1,1\n",
            "154,154_Answer5,1\n",
            "154,154_Answer6,1\n",
            "154,154_Answer9,1\n",
            "154,154_Answer4,1\n",
            "154,154_Answer10,1\n",
            "154,154_Answer3,1\n",
            "154,154_Answer11,1\n",
            "154,154_Answer7,1\n",
            "155,155_Answer3,1\n",
            "155,155_Answer1,1\n",
            "155,155_Answer2,1\n",
            "155,155_Answer7,1\n",
            "155,155_Answer4,1\n",
            "155,155_Answer5,1\n",
            "155,155_Answer9,1\n",
            "155,155_Answer10,1\n",
            "155,155_Answer6,1\n",
            "155,155_Answer8,1\n",
            "156,156_Answer1,1\n",
            "156,156_Answer3,1\n",
            "156,156_Answer2,1\n",
            "156,156_Answer4,1\n",
            "156,156_Answer5,1\n",
            "157,157_Answer3,1\n",
            "157,157_Answer2,1\n",
            "157,157_Answer5,1\n",
            "157,157_Answer6,1\n",
            "157,157_Answer4,1\n",
            "157,157_Answer1,1\n",
            "158,158_Answer6,1\n",
            "158,158_Answer3,1\n",
            "158,158_Answer1,1\n",
            "158,158_Answer5,1\n",
            "158,158_Answer10,1\n",
            "158,158_Answer7,1\n",
            "158,158_Answer8,1\n",
            "158,158_Answer2,1\n",
            "158,158_Answer9,1\n",
            "158,158_Answer4,1\n",
            "159,159_Answer3,1\n",
            "159,159_Answer8,1\n",
            "159,159_Answer9,1\n",
            "159,159_Answer1,1\n",
            "159,159_Answer5,1\n",
            "159,159_Answer7,1\n",
            "159,159_Answer6,1\n",
            "159,159_Answer2,1\n",
            "159,159_Answer4,1\n",
            "160,160_Answer2,1\n",
            "160,160_Answer4,1\n",
            "160,160_Answer1,1\n",
            "160,160_Answer6,1\n",
            "160,160_Answer7,1\n",
            "160,160_Answer5,1\n",
            "160,160_Answer3,1\n",
            "161,161_Answer1,1\n",
            "161,161_Answer4,1\n",
            "161,161_Answer5,1\n",
            "161,161_Answer2,1\n",
            "161,161_Answer6,1\n",
            "161,161_Answer3,1\n",
            "161,161_Answer7,1\n",
            "162,162_Answer2,1\n",
            "162,162_Answer1,1\n",
            "162,162_Answer7,1\n",
            "162,162_Answer3,1\n",
            "162,162_Answer4,1\n",
            "162,162_Answer5,1\n",
            "162,162_Answer6,1\n",
            "163,163_Answer2,1\n",
            "163,163_Answer7,1\n",
            "163,163_Answer3,1\n",
            "163,163_Answer5,1\n",
            "163,163_Answer6,1\n",
            "163,163_Answer4,1\n",
            "165,165_Answer4,1\n",
            "165,165_Answer3,1\n",
            "165,165_Answer5,1\n",
            "165,165_Answer6,1\n",
            "165,165_Answer2,1\n",
            "165,165_Answer1,1\n",
            "165,165_Answer8,1\n",
            "165,165_Answer10,1\n",
            "165,165_Answer7,1\n",
            "165,165_Answer9,1\n",
            "166,166_Answer2,1\n",
            "166,166_Answer8,1\n",
            "166,166_Answer9,1\n",
            "166,166_Answer7,1\n",
            "166,166_Answer4,1\n",
            "166,166_Answer6,1\n",
            "166,166_Answer5,1\n",
            "166,166_Answer1,1\n",
            "166,166_Answer3,1\n",
            "167,167_Answer1,1\n",
            "167,167_Answer2,1\n",
            "167,167_Answer3,1\n",
            "167,167_Answer4,1\n",
            "167,167_Answer5,1\n",
            "168,168_Answer7,1\n",
            "168,168_Answer6,1\n",
            "168,168_Answer3,1\n",
            "168,168_Answer1,1\n",
            "168,168_Answer2,1\n",
            "168,168_Answer5,1\n",
            "168,168_Answer4,1\n",
            "169,169_Answer3,1\n",
            "169,169_Answer4,1\n",
            "169,169_Answer2,1\n",
            "169,169_Answer5,1\n",
            "169,169_Answer1,1\n",
            "169,169_Answer8,1\n",
            "169,169_Answer10,1\n",
            "169,169_Answer6,1\n",
            "169,169_Answer7,1\n",
            "169,169_Answer9,1\n",
            "170,170_Answer1,1\n",
            "170,170_Answer2,1\n",
            "170,170_Answer5,1\n",
            "170,170_Answer4,1\n",
            "170,170_Answer6,1\n",
            "170,170_Answer7,1\n",
            "170,170_Answer8,1\n",
            "170,170_Answer3,1\n",
            "170,170_Answer9,1\n",
            "171,171_Answer3,1\n",
            "171,171_Answer6,1\n",
            "171,171_Answer4,1\n",
            "171,171_Answer5,1\n",
            "171,171_Answer7,1\n",
            "171,171_Answer2,1\n",
            "171,171_Answer1,1\n",
            "171,171_Answer8,1\n",
            "171,171_Answer9,1\n",
            "171,171_Answer10,1\n",
            "174,174_Answer5,1\n",
            "174,174_Answer1,1\n",
            "174,174_Answer3,1\n",
            "174,174_Answer2,1\n",
            "174,174_Answer7,1\n",
            "174,174_Answer8,1\n",
            "174,174_Answer9,1\n",
            "174,174_Answer6,1\n",
            "176,176_Answer1,1\n",
            "176,176_Answer4,1\n",
            "176,176_Answer2,1\n",
            "176,176_Answer3,1\n",
            "176,176_Answer5,1\n",
            "177,177_Answer1,1\n",
            "177,177_Answer4,1\n",
            "177,177_Answer2,1\n",
            "177,177_Answer5,1\n",
            "177,177_Answer9,1\n",
            "177,177_Answer6,1\n",
            "177,177_Answer3,1\n",
            "177,177_Answer7,1\n",
            "177,177_Answer8,1\n",
            "177,177_Answer11,1\n",
            "177,177_Answer10,1\n",
            "179,179_Answer1,1\n",
            "179,179_Answer2,1\n",
            "179,179_Answer10,1\n",
            "179,179_Answer4,1\n",
            "179,179_Answer3,1\n",
            "179,179_Answer5,1\n",
            "179,179_Answer6,1\n",
            "179,179_Answer7,1\n",
            "179,179_Answer8,1\n",
            "179,179_Answer9,1\n",
            "180,180_Answer1,1\n",
            "180,180_Answer3,1\n",
            "180,180_Answer4,1\n",
            "180,180_Answer2,1\n",
            "181,181_Answer4,1\n",
            "181,181_Answer1,1\n",
            "181,181_Answer2,1\n",
            "181,181_Answer7,1\n",
            "181,181_Answer3,1\n",
            "181,181_Answer8,1\n",
            "181,181_Answer5,1\n",
            "181,181_Answer6,1\n",
            "181,181_Answer9,1\n",
            "182,182_Answer8,1\n",
            "182,182_Answer1,1\n",
            "182,182_Answer5,1\n",
            "182,182_Answer3,1\n",
            "182,182_Answer2,1\n",
            "182,182_Answer4,1\n",
            "182,182_Answer6,1\n",
            "183,183_Answer2,1\n",
            "183,183_Answer1,1\n",
            "183,183_Answer3,1\n",
            "183,183_Answer4,1\n",
            "183,183_Answer5,1\n",
            "183,183_Answer7,1\n",
            "183,183_Answer6,1\n",
            "184,184_Answer1,1\n",
            "184,184_Answer3,1\n",
            "184,184_Answer2,1\n",
            "185,185_Answer2,1\n",
            "185,185_Answer3,1\n",
            "185,185_Answer9,1\n",
            "185,185_Answer4,1\n",
            "185,185_Answer5,1\n",
            "185,185_Answer6,1\n",
            "185,185_Answer1,1\n",
            "185,185_Answer7,1\n",
            "185,185_Answer8,1\n",
            "186,186_Answer1,1\n",
            "186,186_Answer4,1\n",
            "186,186_Answer2,1\n",
            "186,186_Answer5,1\n",
            "186,186_Answer7,1\n",
            "186,186_Answer3,1\n",
            "186,186_Answer9,1\n",
            "186,186_Answer8,1\n",
            "186,186_Answer6,1\n",
            "187,187_Answer4,1\n",
            "187,187_Answer3,1\n",
            "187,187_Answer7,1\n",
            "187,187_Answer9,1\n",
            "187,187_Answer1,1\n",
            "187,187_Answer5,1\n",
            "187,187_Answer8,1\n",
            "187,187_Answer2,1\n",
            "187,187_Answer6,1\n",
            "188,188_Answer2,1\n",
            "188,188_Answer1,1\n",
            "188,188_Answer5,1\n",
            "188,188_Answer3,1\n",
            "188,188_Answer6,1\n",
            "188,188_Answer7,1\n",
            "188,188_Answer4,1\n",
            "188,188_Answer8,1\n",
            "189,189_Answer1,1\n",
            "189,189_Answer4,1\n",
            "189,189_Answer5,1\n",
            "189,189_Answer6,1\n",
            "189,189_Answer7,1\n",
            "189,189_Answer8,1\n",
            "189,189_Answer2,1\n",
            "189,189_Answer3,1\n",
            "189,189_Answer9,1\n",
            "190,190_Answer1,1\n",
            "190,190_Answer4,1\n",
            "190,190_Answer5,1\n",
            "190,190_Answer2,1\n",
            "190,190_Answer6,1\n",
            "190,190_Answer7,1\n",
            "190,190_Answer3,1\n",
            "191,191_Answer3,1\n",
            "191,191_Answer9,1\n",
            "191,191_Answer2,1\n",
            "191,191_Answer4,1\n",
            "191,191_Answer5,1\n",
            "191,191_Answer6,1\n",
            "191,191_Answer7,1\n",
            "191,191_Answer8,1\n",
            "191,191_Answer1,1\n",
            "193,193_Answer2,1\n",
            "193,193_Answer3,1\n",
            "193,193_Answer8,1\n",
            "193,193_Answer7,1\n",
            "193,193_Answer1,1\n",
            "193,193_Answer5,1\n",
            "193,193_Answer6,1\n",
            "193,193_Answer4,1\n",
            "195,195_Answer4,1\n",
            "195,195_Answer3,1\n",
            "195,195_Answer1,1\n",
            "195,195_Answer2,1\n",
            "195,195_Answer9,1\n",
            "195,195_Answer6,1\n",
            "195,195_Answer5,1\n",
            "195,195_Answer7,1\n",
            "195,195_Answer8,1\n",
            "195,195_Answer10,1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdPcaI-8Awa0"
      },
      "source": [
        "lengths = []\n",
        "for q in QA:\n",
        "    for a in q.answers:\n",
        "        lengths.append(len(a))\n",
        "        print(len(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcRtWLKNS8ze"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXEHExavZtdE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7daxnXJZtZi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIfyXiblZtU-",
        "outputId": "bea87d86-7e0f-4a7f-cdeb-ac9cc3e5e53b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import scipy.stats\n",
        "\n",
        "class MediqaEvaluator:\n",
        "    def __init__(self, answer_file_path, task=1, round=1):\n",
        "        \"\"\"\n",
        "        `round` : Holds the round for which the evaluation is being done.\n",
        "        can be 1, 2...upto the number of rounds the challenge has.\n",
        "        Different rounds will mostly have different ground truth files.\n",
        "        \"\"\"\n",
        "        self.answer_file_path = answer_file_path\n",
        "        self.round = round\n",
        "        self.task = task\n",
        "\n",
        "    def _evaluate(self, client_payload, _context={}):\n",
        "        if self.task == 1:\n",
        "            return self._evaluate_task_1(client_payload, _context)\n",
        "        elif self.task == 2:\n",
        "            return self._evaluate_task_2(client_payload, _context)\n",
        "        elif self.task == 3:\n",
        "            return self._evaluate_task_3(client_payload, _context)\n",
        "\n",
        "\n",
        "    def _evaluate_task_1(self, client_payload, _context={}):\n",
        "        \"\"\"\n",
        "        `client_payload` will be a dict with (atleast) the following keys :\n",
        "          - submission_file_path : local file path of the submitted file\n",
        "          - aicrowd_submission_id : A unique id representing the submission\n",
        "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
        "        \"\"\"\n",
        "        submission_file_path = client_payload[\"submission_file_path\"]\n",
        "\n",
        "        # Result file format: pair_id,label (csv file)\n",
        "\n",
        "        col_names = ['pair_id', 'label']\n",
        "\n",
        "        submission = pd.read_csv(submission_file_path, header=None, names=col_names)\n",
        "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names)\n",
        "\n",
        "        # Drop duplicates except for the first occurrence.\n",
        "        submission = submission.drop_duplicates(['pair_id'])\n",
        "\n",
        "        submission.label = submission.label.astype(str)\n",
        "        gold_truth.label = gold_truth.label.astype(str)\n",
        "\n",
        "        submission['entry'] = submission.apply(lambda x: '_'.join(x), axis=1)\n",
        "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(x), axis=1)\n",
        "\n",
        "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
        "\n",
        "        accuracy = s1.size / gold_truth.size\n",
        "\n",
        "        _result_object = {\n",
        "            \"score\": accuracy,\n",
        "            \"score_secondary\" : 0.0\n",
        "        }\n",
        "        return _result_object\n",
        "\n",
        "    def _evaluate_task_2(self, client_payload, _context={}):\n",
        "        \"\"\"\n",
        "        `client_payload` will be a dict with (atleast) the following keys :\n",
        "          - submission_file_path : local file path of the submitted file\n",
        "          - aicrowd_submission_id : A unique id representing the submission\n",
        "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
        "        \"\"\"\n",
        "        submission_file_path = client_payload[\"submission_file_path\"]\n",
        "\n",
        "        # Result file format: pair_id,label (csv file)\n",
        "\n",
        "        col_names = ['pair_id', 'label']\n",
        "\n",
        "        submission = pd.read_csv(submission_file_path, header=None, names=col_names, dtype={'pair_id': str, \"label\": str})\n",
        "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names, dtype={'pair_id': str, \"label\": str})\n",
        "\n",
        "        # Drop duplicates except for the first occurrence.\n",
        "        submission = submission.drop_duplicates(['pair_id'])\n",
        "\n",
        "        submission.label = submission.label.astype(str)\n",
        "        gold_truth.label = gold_truth.label.astype(str)\n",
        "\n",
        "        submission['entry'] = submission.apply(lambda x: '_'.join(x), axis=1)\n",
        "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(x), axis=1)\n",
        "\n",
        "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
        "\n",
        "        accuracy = s1.size / gold_truth.size\n",
        "\n",
        "        _result_object = {\n",
        "            \"score\": accuracy,\n",
        "            \"score_secondary\" : 0.0\n",
        "        }\n",
        "\n",
        "        return _result_object\n",
        "\n",
        "    def _evaluate_task_3(self, client_payload, _context={}):\n",
        "        \"\"\"\n",
        "        `client_payload` will be a dict with (atleast) the following keys :\n",
        "          - submission_file_path : local file path of the submitted file\n",
        "          - aicrowd_submission_id : A unique id representing the submission\n",
        "          - aicrowd_participant_id : A unique id for participant/team submitting (if enabled)\n",
        "        \"\"\"\n",
        "        submission_file_path = client_payload[\"submission_file_path\"]\n",
        "\n",
        "        # Result file format: q_id,a_id,label{0/1}\n",
        "\n",
        "        col_names = ['question_id','answer_id', 'label']\n",
        "\n",
        "        submission = pd.read_csv(submission_file_path, header=None, names=col_names)\n",
        "        gold_truth = pd.read_csv(self.answer_file_path, header=None, names=col_names)\n",
        "\n",
        "        # Drop duplicates except for the first occurrence.\n",
        "        submission = submission.drop_duplicates(['question_id', 'answer_id'])\n",
        "\n",
        "        submission.label = submission.label.astype(str)\n",
        "        gold_truth.label = gold_truth.label.astype(str)\n",
        "\n",
        "        submission['entry'] = submission.apply(lambda x: '_'.join(map(str,x)), axis=1)\n",
        "        gold_truth['entry'] = gold_truth.apply(lambda x: '_'.join(map(str,x)), axis=1)\n",
        "\n",
        "        s1 = submission[submission['entry'].isin(gold_truth['entry'])]\n",
        "\n",
        "        accuracy = s1.size / gold_truth.size\n",
        "\n",
        "        question_ids = []\n",
        "        correct_answers = {}\n",
        "        for index, row in gold_truth.iterrows():\n",
        "            qid = row['question_id']\n",
        "\n",
        "            if qid not in question_ids:\n",
        "                question_ids.append(qid)\n",
        "\n",
        "            if row['label'] == '1':\n",
        "                if qid not in correct_answers:\n",
        "                    correct_answers[qid] = []\n",
        "\n",
        "                correct_answers[qid].append(row['answer_id'])\n",
        "\n",
        "        Pr = 0.\n",
        "        spearman = 0.\n",
        "        pv = 0.\n",
        "        predictedPositive = 0.\n",
        "        correctPredictedPositive = 0.\n",
        "        mrr = 0.\n",
        "        sp_nan_ignoredQs = 0\n",
        "\n",
        "        for qid in question_ids:\n",
        "            submitted_correct_answers = []\n",
        "            index = 1\n",
        "            first = True\n",
        "            for _, row in submission[submission['question_id']==qid].iterrows():\n",
        "                aid = row['answer_id']\n",
        "                if row['label'] == '1':\n",
        "                    predictedPositive += 1\n",
        "                    if aid in correct_answers[qid]:\n",
        "                        correctPredictedPositive += 1\n",
        "                        submitted_correct_answers.append(aid)\n",
        "                        if first:\n",
        "                            mrr += 1. / index\n",
        "                            first=False\n",
        "\n",
        "                index += 1\n",
        "            matched_gold_subset = []\n",
        "\n",
        "            for x in correct_answers[qid]:\n",
        "                if x in submitted_correct_answers:\n",
        "                    matched_gold_subset.append(x)\n",
        "\n",
        "            rho, p_value = scipy.stats.spearmanr(submitted_correct_answers, matched_gold_subset)\n",
        "            if np.isnan(rho):\n",
        "                rho = 0.0\n",
        "                sp_nan_ignoredQs += 1\n",
        "            spearman += rho\n",
        "            pv += p_value\n",
        "\n",
        "        question_nb = len(question_ids)\n",
        "        q_nb_spearman = question_nb - sp_nan_ignoredQs\n",
        "        spearman = spearman / q_nb_spearman\n",
        "        Pr = correctPredictedPositive / predictedPositive\n",
        "        mrr = mrr / question_nb\n",
        "\n",
        "        if np.isnan(spearman):\n",
        "            spearman = 0.0\n",
        "\n",
        "        _result_object = {\n",
        "            \"score\": accuracy,\n",
        "            \"score_secondary\": spearman,\n",
        "            \"meta\" : {\n",
        "                \"MRR\": mrr,\n",
        "                \"Precision\": Pr\n",
        "            }\n",
        "        }\n",
        "        return _result_object\n",
        "\n",
        "\n",
        "# Test Tasks 1,2,3\n",
        "for task in []:\n",
        "    print(\"Testing Task (Round-1) : {}\".format(task))\n",
        "    answer_file_path = \"data/task{}/ground_truth_round_2.csv\".format(task)\n",
        "    _client_payload = {}\n",
        "    _client_payload[\"submission_file_path\"] = \"data/task{}/sample_submission_round_2.csv\".format(task)\n",
        "\n",
        "    # Instaiate a dummy context\n",
        "    _context = {}\n",
        "    # Instantiate an evaluator\n",
        "    aicrowd_evaluator = MediqaEvaluator(answer_file_path, task=task)\n",
        "    # Evaluate\n",
        "    result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
        "    print(result)\n",
        "\n",
        "# Test Tasks 1,2,3 - Round -2\n",
        "for task in [3]:\n",
        "    print(\"Testing Task (Round-2) : {}\".format(task))\n",
        "    answer_file_path = \"data/task{}/ground_truth_round_2.csv\".format(task)\n",
        "    _client_payload = {}\n",
        "    _client_payload[\"submission_file_path\"] = \"data/task{}/sample_submission_round_2.csv\".format(task)\n",
        "\n",
        "    # Instaiate a dummy context\n",
        "    _context = {}\n",
        "    # Instantiate an evaluator\n",
        "    aicrowd_evaluator = MediqaEvaluator(answer_file_path, task=task, round=2)\n",
        "    # Evaluate\n",
        "    result = aicrowd_evaluator._evaluate(_client_payload, _context)\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Task (Round-2) : 3\n",
            "{'score': 0.5167118337850045, 'score_secondary': 0.4854188390684743, 'meta': {'MRR': 0.8785714285714286, 'Precision': 0.5167118337850045}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzyudPpuZ1B8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ4pEiGlvhuY"
      },
      "source": [
        "### **BioELMo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My_O_qOBvitB",
        "outputId": "e4802eeb-264b-4af8-d0e1-1e89ab015ee6"
      },
      "source": [
        "! pip install tensorflow-gpu==1.2 h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/4d/c9c4da41c6d7b9a4949cb9e53c7032d7d9b7da0410f1226f7455209dd962/tensorflow_gpu-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (89.5MB)\n",
            "\u001b[K     |████████████████████████████████| 89.5MB 33kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Collecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (3.12.4)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.2) (0.35.1)\n",
            "Collecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow-gpu==1.2) (50.3.2)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136279 sha256=c0c95af1c9f2dc84d3ffa183b0ef07f4efb77e59886ca9426d9dd1102e8936d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=6ee8ab4e295e152a39b2ea351e4722a7c6fb812164f57fe24987e1c3eb2776a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mERROR: tensorboard 2.3.0 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: markdown, html5lib, backports.weakref, bleach, tensorflow-gpu\n",
            "  Found existing installation: Markdown 3.3.3\n",
            "    Uninstalling Markdown-3.3.3:\n",
            "      Successfully uninstalled Markdown-3.3.3\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.2.1\n",
            "    Uninstalling bleach-3.2.1:\n",
            "      Successfully uninstalled bleach-3.2.1\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-gpu-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAVbKJx1xmxi",
        "outputId": "2cf1a20f-026e-494c-8f13-75b34f74fc02"
      },
      "source": [
        "! python setup.py install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSwGZ1XZyAnx",
        "outputId": "ff047260-60b5-4999-81b4-963946903cfe"
      },
      "source": [
        "! git clone https://github.com/allenai/bilm-tf.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bilm-tf'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Total 292 (delta 0), reused 0 (delta 0), pack-reused 292\u001b[K\n",
            "Receiving objects: 100% (292/292), 588.40 KiB | 782.00 KiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk64Bgrt1rOc"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoEtla-r5AxU",
        "outputId": "e2960e18-7c6e-432f-8b74-2d3e8c096cf9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbilm-tf\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwSoJh8m4xi4",
        "outputId": "cd079aff-0eca-4b15-c861-7cfc752d85c2"
      },
      "source": [
        "data_train = pd.read_csv('/content/bilm-tf/vocabulary.txt', sep=\" \", header=None)\n",
        "print(\"Shape of training data = \", data_train.shape)\n",
        "data_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of training data =  (1000003, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       <S>\n",
              "1                      </S>\n",
              "2                     <UNK>\n",
              "3                        of\n",
              "4                       the\n",
              "                 ...       \n",
              "999998                SgcE6\n",
              "999999     cubilin-mediated\n",
              "1000000       syndrome/drug\n",
              "1000001              11,214\n",
              "1000002       artery.RESULT\n",
              "Name: 0, Length: 1000003, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "H1-z9EUr5GqG",
        "outputId": "a2e7ebce-0021-46be-99e3-972d20272d5d"
      },
      "source": [
        "if not os.path.exists(\"/content/bilm-tf/train\"):\n",
        "    os.makedirs(\"/content/bilm-tf/train\")\n",
        " \n",
        "for i in range(0,data_train.shape[0],6):\n",
        "    text = \"\\n\".join(data_train[0][i:i+6].tolist())\n",
        "    fp = open(\"/content/bilm-tf/train/\"+str(i)+\".txt\",\"w\")\n",
        "    fp.write(text)\n",
        "    fp.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2c55fd6318f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/bilm-tf/train/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sequence item 4: expected str instance, float found"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWpBMbxl5qjy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}